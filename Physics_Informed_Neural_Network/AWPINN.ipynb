{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networks\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# seed = 1234\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "# np.random.seed(seed)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling\n",
    "Here in our case, the system is European Call Option PDE and the physical information about the system consists of Boundary Value conditions, final Value conditions and the PDE itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "r = 0.035\n",
    "sigma = 0.2\n",
    "T = 1\n",
    "S_range = [0, int(5*K)]\n",
    "t_range = [0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0)\n",
    "M = 100\n",
    "N = 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
       "    (1-7): 7 x Linear(in_features=50, out_features=50, bias=True)\n",
       "  )\n",
       "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = networks.FeedforwardNeuralNetwork(2, 50, 1, 8) #  Network initialization\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "lossFunction = nn.MSELoss()\n",
    "lr = 3e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "x_f_s = torch.tensor(np.log(1.0)).float().to(device).requires_grad_(True)\n",
    "x_label_s = torch.tensor(np.log(1.0)).float().to(device).requires_grad_(True)\n",
    "x_data_s = torch.tensor(np.log(1.0)).float().to(device).requires_grad_(True)\n",
    "w_lr = 3e-7\n",
    "optimizer_adam_weight = optim.Adam([x_f_s] + [x_label_s] + [x_data_s], lr=w_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical loss samples\n",
    "samples = {\"pde\": 5000, \"bc\":500, \"fc\":500}\n",
    "\n",
    "# sample data generated by finite difference method\n",
    "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = utils.fdm_data(S_range[-1], T, M, N, \"500000sample.csv\", device)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5000 PDE Loss: 0.00000, BC Loss: 676.24292, data loss: 425.44766, total loss: 1101.69055, minimum loss: 1101.69055\n",
      "the weight is 1.00000, 1.00000. 1.00000, the parameter is -0.00000, 0.00000, 0.00000\n",
      "500/5000 PDE Loss: 0.01691, BC Loss: 146.57896, data loss: 79.39012, total loss: 225.98599, minimum loss: 225.98599\n",
      "the weight is 1.00015, 0.99987. 0.99987, the parameter is -0.00015, 0.00013, 0.00013\n",
      "1000/5000 PDE Loss: 1.04168, BC Loss: 3.06250, data loss: 6.72915, total loss: 10.83332, minimum loss: 10.83332\n",
      "the weight is 1.00024, 0.99986. 0.99986, the parameter is -0.00024, 0.00014, 0.00014\n",
      "1500/5000 PDE Loss: 0.72667, BC Loss: 0.12501, data loss: 0.39300, total loss: 1.24469, minimum loss: 1.24469\n",
      "the weight is 1.00018, 0.99986. 0.99986, the parameter is -0.00018, 0.00014, 0.00014\n",
      "2000/5000 PDE Loss: 0.00398, BC Loss: 0.00150, data loss: 0.00183, total loss: 0.00730, minimum loss: 0.00730\n",
      "the weight is 1.00037, 0.99986. 0.99986, the parameter is -0.00037, 0.00014, 0.00014\n",
      "2500/5000 PDE Loss: 0.00004, BC Loss: 0.00130, data loss: 0.00156, total loss: 0.00290, minimum loss: 0.00290\n",
      "the weight is 1.00056, 0.99986. 0.99986, the parameter is -0.00056, 0.00014, 0.00014\n",
      "3000/5000 PDE Loss: 0.00004, BC Loss: 0.00121, data loss: 0.00153, total loss: 0.00278, minimum loss: 0.00278\n",
      "the weight is 1.00073, 0.99986. 0.99986, the parameter is -0.00073, 0.00014, 0.00014\n",
      "3500/5000 PDE Loss: 0.00004, BC Loss: 0.00114, data loss: 0.00152, total loss: 0.00270, minimum loss: 0.00270\n",
      "the weight is 1.00089, 0.99987. 0.99987, the parameter is -0.00089, 0.00013, 0.00013\n",
      "4000/5000 PDE Loss: 0.00004, BC Loss: 0.00108, data loss: 0.00152, total loss: 0.00264, minimum loss: 0.00264\n",
      "the weight is 1.00104, 0.99987. 0.99987, the parameter is -0.00104, 0.00013, 0.00013\n",
      "4500/5000 PDE Loss: 0.00004, BC Loss: 0.00102, data loss: 0.00154, total loss: 0.00259, minimum loss: 0.00259\n",
      "the weight is 1.00120, 0.99987. 0.99987, the parameter is -0.00120, 0.00013, 0.00013\n",
      "run time: 100.10825228691101\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "x_f_s_hist = []\n",
    "x_label_s_hist = []\n",
    "x_data_s_hist = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "    utils.trainingData(K, r, sigma, T, S_range[-1], S_range, t_range, gs, \n",
    "                       samples['bc'], \n",
    "                       samples['fc'], \n",
    "                       samples['pde'], \n",
    "                       RNG_key=123)\n",
    "    \n",
    "    # save training data points to tensor and send to device\n",
    "    n_st_train = torch.from_numpy(n_st_train).float().requires_grad_().to(device)\n",
    "    n_v_train = torch.from_numpy(n_v_train).float().to(device)\n",
    "    \n",
    "    bc_st_train = torch.from_numpy(bc_st_train).float().to(device)\n",
    "    bc_v_train = torch.from_numpy(bc_v_train).float().to(device)   \n",
    "    \n",
    "    # pde residual loss\n",
    "    y1_hat = net(n_st_train)\n",
    "    grads = tgrad.grad(y1_hat, n_st_train, grad_outputs=torch.ones(y1_hat.shape).cuda(), \n",
    "                retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), \n",
    "                    create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*y1_hat)\n",
    "    \n",
    "    # boudary condition loss\n",
    "    y2_hat = net(bc_st_train)\n",
    "    bc_loss = lossFunction(bc_v_train, y2_hat)\n",
    "    \n",
    "    # sample training data loss\n",
    "    y3_hat = net(X_train_tensor)\n",
    "    data_loss = lossFunction(y_train_tensor, y3_hat)\n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    optimizer.zero_grad()\n",
    "    combined_loss = torch.exp(-x_f_s.detach()) * pde_loss + torch.exp(-x_label_s.detach()) * bc_loss + torch.exp(-x_data_s.detach()) * data_loss + x_data_s + x_label_s + x_f_s\n",
    "    combined_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # update the weight\n",
    "    optimizer_adam_weight.zero_grad()\n",
    "    loss = torch.exp(-x_f_s) * pde_loss.detach() + torch.exp(-x_label_s) * bc_loss.detach() + torch.exp(-x_data_s) * data_loss.detach() + x_data_s + x_label_s + x_f_s\n",
    "    loss.backward()\n",
    "    optimizer_adam_weight.step()\n",
    "    \n",
    "    # record the loss\n",
    "    mse_loss = pde_loss + bc_loss + data_loss\n",
    "    loss_hist.append(mse_loss.item())\n",
    "    x_f_s_hist.append(torch.exp(-x_f_s).item())\n",
    "    x_label_s_hist.append(torch.exp(-x_label_s).item())\n",
    "    x_data_s_hist.append(torch.exp(-x_data_s).item())\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'{epoch}/{n_epochs} PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}, data loss: {data_loss.item():.5f}, total loss: {mse_loss.item():.5f}, minimum loss: {min(loss_hist):.5f}')\n",
    "        print(f'the weight is {torch.exp(-x_f_s.detach()).item():.5f}, {torch.exp(-x_label_s.detach()).item():.5f}. {torch.exp(-x_data_s.detach()).item():.5f}, the parameter is {x_f_s.item():.5f}, {x_label_s.item():.5f}, {x_data_s.item():.5f}')\n",
    "    pass\n",
    "end_time = time.time()\n",
    "print('run time:', end_time - start_time)\n",
    "\n",
    "loss_weights_hist = pd.DataFrame({\n",
    "        'PDE_Weight': x_f_s_hist,\n",
    "        'BC_Weight': x_label_s_hist,\n",
    "        'Data_Weight': x_data_s_hist\n",
    "    })\n",
    "loss_weights_hist.to_csv(f'weights/{w_lr}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = net(X_test_tensor)\n",
    "    test_loss = lossFunction(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101.6905517578125\n",
      "225.98599243164062\n",
      "10.833324432373047\n",
      "1.2446893453598022\n",
      "0.007300898432731628\n",
      "0.0029041250236332417\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000):\n",
    "    if i % 500 == 0:\n",
    "        print(loss_hist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlr = 3e-5\\nlr = lr\\n1099.8822021484375\\n54.46702575683594\\n10.79588794708252\\n0.26179707050323486\\n0.06549832224845886\\n0.04295624420046806\\nv2\\n1091.264404296875\\n175.3550567626953\\n9.200620651245117\\n0.021437039598822594\\n0.011154992505908012\\n0.00615318538621068\\nv3\\n1096.0784912109375\\n145.78138732910156\\n11.065857887268066\\n1.195802927017212\\n0.007282810285687447\\n0.005661157425493002\\nv4\\n1099.22607421875\\n414.196533203125\\n9.993719100952148\\n1.4779069423675537\\n0.00975001323968172\\n0.0027645404916256666\\nv5\\n1101.3546142578125\\n117.58456420898438\\n10.586881637573242\\n0.4234362244606018\\n0.16712422668933868\\n0.08312012255191803\\n\\nlr = lr*0.1\\n1108.269287109375\\n458.4380187988281\\n18.00096893310547\\n10.638126373291016\\n2.3813610076904297\\n0.04458016902208328\\nv2\\n1098.9173583984375\\n498.7457275390625\\n8.37392520904541\\n0.04848393797874451\\n0.01035694032907486\\n0.006585360039025545\\nv3\\n1106.7056884765625\\n199.62017822265625\\n20.819793701171875\\n11.254127502441406\\n2.2797794342041016\\n0.03742136433720589\\nv4\\n1107.873291015625\\n74.37163543701172\\n14.879474639892578\\n3.1905810832977295\\n0.045051589608192444\\n0.008426403626799583\\nv5\\n1110.307373046875\\n28.044471740722656\\n16.48096466064453\\n5.725974082946777\\n0.373512327671051\\n0.007787228096276522\\nv6\\n1093.041748046875\\n88.30891418457031\\n4.8466057777404785\\n0.030280468985438347\\n0.003480653278529644\\n0.003087927121669054\\n\\nlr = lr*0.01\\n1108.57177734375\\n32.370243072509766\\n19.039159774780273\\n6.253387451171875\\n0.04844483360648155\\n0.009771297685801983\\nv2\\n1097.6781005859375\\n354.0700378417969\\n11.808877944946289\\n0.6618903875350952\\n0.017533782869577408\\n0.008471298031508923\\nv3\\n1092.56689453125\\n155.4998779296875\\n15.183956146240234\\n1.3004826307296753\\n0.13293592631816864\\n0.06324443966150284\\nv4\\n1097.779052734375\\n259.1787109375\\n4.381502151489258\\n0.03809420019388199\\n0.0030492269434034824\\n0.003581415396183729\\n\\n\\nlr = lr*0.001\\n1102.8289794921875\\n70.73458862304688\\n20.345287322998047\\n11.07504653930664\\n2.21193265914917\\n0.020034609362483025\\nv2\\n1100.103271484375\\n29.110830307006836\\n13.54207992553711\\n2.2702531814575195\\n0.03685794398188591\\n0.005187606438994408\\nv3\\n1101.7392578125\\n39.58943557739258\\n9.618980407714844\\n1.3002090454101562\\n0.0525912344455719\\n0.028041506186127663\\nv4\\n1106.5574951171875\\n54.07958984375\\n11.572875022888184\\n3.614226818084717\\n0.036611057817935944\\n0.007018315140157938\\n\\n\\nlr = lr*0.0001\\n1108.546875\\n64.16551208496094\\n19.342121124267578\\n11.909713745117188\\n2.2722582817077637\\n0.028394339606165886\\nv1\\n1097.0103759765625\\n641.002685546875\\n6.1454362869262695\\n0.028341539204120636\\n0.019869372248649597\\n0.015094837173819542\\nv2\\n1099.1807861328125\\n74.23635864257812\\n5.6405744552612305\\n0.03148069232702255\\n0.01238433551043272\\n0.008084086701273918\\n\\nlr = lr*0.00001\\n1095.9866943359375\\n49.48216247558594\\n13.448659896850586\\n1.1453372240066528\\n0.0064399996772408485\\n0.004670318216085434\\nv1\\n1108.866943359375\\n298.6302795410156\\n20.8073787689209\\n11.087276458740234\\n2.8229360580444336\\n0.1352125108242035\\nv2\\n1089.82958984375\\n53.824317932128906\\n11.834549903869629\\n1.6474502086639404\\n0.027329374104738235\\n0.011542053893208504\\n\\n\\nlr = lr*0.0000001\\n\\n\\nlr = lr*0.000000001\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lr = 3e-5\n",
    "lr = lr\n",
    "1099.8822021484375\n",
    "54.46702575683594\n",
    "10.79588794708252\n",
    "0.26179707050323486\n",
    "0.06549832224845886\n",
    "0.04295624420046806\n",
    "v2\n",
    "1091.264404296875\n",
    "175.3550567626953\n",
    "9.200620651245117\n",
    "0.021437039598822594\n",
    "0.011154992505908012\n",
    "0.00615318538621068\n",
    "v3\n",
    "1096.0784912109375\n",
    "145.78138732910156\n",
    "11.065857887268066\n",
    "1.195802927017212\n",
    "0.007282810285687447\n",
    "0.005661157425493002\n",
    "v4\n",
    "1099.22607421875\n",
    "414.196533203125\n",
    "9.993719100952148\n",
    "1.4779069423675537\n",
    "0.00975001323968172\n",
    "0.0027645404916256666\n",
    "v5\n",
    "1101.3546142578125\n",
    "117.58456420898438\n",
    "10.586881637573242\n",
    "0.4234362244606018\n",
    "0.16712422668933868\n",
    "0.08312012255191803\n",
    "\n",
    "lr = lr*0.1\n",
    "1108.269287109375\n",
    "458.4380187988281\n",
    "18.00096893310547\n",
    "10.638126373291016\n",
    "2.3813610076904297\n",
    "0.04458016902208328\n",
    "v2\n",
    "1098.9173583984375\n",
    "498.7457275390625\n",
    "8.37392520904541\n",
    "0.04848393797874451\n",
    "0.01035694032907486\n",
    "0.006585360039025545\n",
    "v3\n",
    "1106.7056884765625\n",
    "199.62017822265625\n",
    "20.819793701171875\n",
    "11.254127502441406\n",
    "2.2797794342041016\n",
    "0.03742136433720589\n",
    "v4\n",
    "1107.873291015625\n",
    "74.37163543701172\n",
    "14.879474639892578\n",
    "3.1905810832977295\n",
    "0.045051589608192444\n",
    "0.008426403626799583\n",
    "v5\n",
    "1110.307373046875\n",
    "28.044471740722656\n",
    "16.48096466064453\n",
    "5.725974082946777\n",
    "0.373512327671051\n",
    "0.007787228096276522\n",
    "v6\n",
    "1093.041748046875\n",
    "88.30891418457031\n",
    "4.8466057777404785\n",
    "0.030280468985438347\n",
    "0.003480653278529644\n",
    "0.003087927121669054\n",
    "\n",
    "lr = lr*0.01\n",
    "1108.57177734375\n",
    "32.370243072509766\n",
    "19.039159774780273\n",
    "6.253387451171875\n",
    "0.04844483360648155\n",
    "0.009771297685801983\n",
    "v2\n",
    "1097.6781005859375\n",
    "354.0700378417969\n",
    "11.808877944946289\n",
    "0.6618903875350952\n",
    "0.017533782869577408\n",
    "0.008471298031508923\n",
    "v3\n",
    "1092.56689453125\n",
    "155.4998779296875\n",
    "15.183956146240234\n",
    "1.3004826307296753\n",
    "0.13293592631816864\n",
    "0.06324443966150284\n",
    "v4\n",
    "1097.779052734375\n",
    "259.1787109375\n",
    "4.381502151489258\n",
    "0.03809420019388199\n",
    "0.0030492269434034824\n",
    "0.003581415396183729\n",
    "\n",
    "\n",
    "lr = lr*0.001\n",
    "1102.8289794921875\n",
    "70.73458862304688\n",
    "20.345287322998047\n",
    "11.07504653930664\n",
    "2.21193265914917\n",
    "0.020034609362483025\n",
    "v2\n",
    "1100.103271484375\n",
    "29.110830307006836\n",
    "13.54207992553711\n",
    "2.2702531814575195\n",
    "0.03685794398188591\n",
    "0.005187606438994408\n",
    "v3\n",
    "1101.7392578125\n",
    "39.58943557739258\n",
    "9.618980407714844\n",
    "1.3002090454101562\n",
    "0.0525912344455719\n",
    "0.028041506186127663\n",
    "v4\n",
    "1106.5574951171875\n",
    "54.07958984375\n",
    "11.572875022888184\n",
    "3.614226818084717\n",
    "0.036611057817935944\n",
    "0.007018315140157938\n",
    "\n",
    "\n",
    "lr = lr*0.0001\n",
    "1108.546875\n",
    "64.16551208496094\n",
    "19.342121124267578\n",
    "11.909713745117188\n",
    "2.2722582817077637\n",
    "0.028394339606165886\n",
    "v1\n",
    "1097.0103759765625\n",
    "641.002685546875\n",
    "6.1454362869262695\n",
    "0.028341539204120636\n",
    "0.019869372248649597\n",
    "0.015094837173819542\n",
    "v2\n",
    "1099.1807861328125\n",
    "74.23635864257812\n",
    "5.6405744552612305\n",
    "0.03148069232702255\n",
    "0.01238433551043272\n",
    "0.008084086701273918\n",
    "\n",
    "lr = lr*0.00001\n",
    "1095.9866943359375\n",
    "49.48216247558594\n",
    "13.448659896850586\n",
    "1.1453372240066528\n",
    "0.0064399996772408485\n",
    "0.004670318216085434\n",
    "v1\n",
    "1108.866943359375\n",
    "298.6302795410156\n",
    "20.8073787689209\n",
    "11.087276458740234\n",
    "2.8229360580444336\n",
    "0.1352125108242035\n",
    "v2\n",
    "1089.82958984375\n",
    "53.824317932128906\n",
    "11.834549903869629\n",
    "1.6474502086639404\n",
    "0.027329374104738235\n",
    "0.011542053893208504\n",
    "\n",
    "\n",
    "lr = lr*0.0000001\n",
    "\n",
    "\n",
    "lr = lr*0.000000001\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
