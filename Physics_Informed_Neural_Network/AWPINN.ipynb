{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networks\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# seed = 1234\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "# np.random.seed(seed)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling\n",
    "Here in our case, the system is European Call Option PDE and the physical information about the system consists of Boundary Value conditions, final Value conditions and the PDE itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "r = 0.035\n",
    "sigma = 0.2\n",
    "T = 1\n",
    "S_range = [0, int(5*K)]\n",
    "t_range = [0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0)\n",
    "M = 100\n",
    "N = 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
       "    (1-7): 7 x Linear(in_features=50, out_features=50, bias=True)\n",
       "  )\n",
       "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = networks.FeedforwardNeuralNetwork(2, 50, 1, 8) #  Network initialization\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "lossFunction = nn.MSELoss()\n",
    "lr = 3e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "x_f_s = torch.tensor(-np.log(1)).float().to(device).requires_grad_(True)\n",
    "x_label_s = torch.tensor(-np.log(1)).float().to(device).requires_grad_(True)\n",
    "x_data_s = torch.tensor(-np.log(1)).float().to(device).requires_grad_(True)\n",
    "w_lr = 3e-7\n",
    "optimizer_adam_weight = optim.Adam([x_f_s] + [x_label_s] + [x_data_s], lr=w_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical loss samples\n",
    "samples = {\"pde\": 5000, \"bc\":500, \"fc\":500}\n",
    "\n",
    "# sample data generated by finite difference method\n",
    "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = utils.fdm_data(S_range[-1], T, M, N, \"500000sample.csv\", device)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5000 PDE Loss: 0.00002, BC Loss: 678.91718, data loss: 427.80948, total loss: 1106.72668, minimum loss: 1106.72668\n",
      "the weight is 1.00000, 1.00000. 1.00000, the parameter is -0.00000, 0.00000, 0.00000\n",
      "500/5000 PDE Loss: 0.04684, BC Loss: 75.47854, data loss: 39.38233, total loss: 114.90771, minimum loss: 114.90771\n",
      "the weight is 1.00015, 0.99987. 0.99987, the parameter is -0.00015, 0.00013, 0.00013\n",
      "1000/5000 PDE Loss: 0.19190, BC Loss: 6.17277, data loss: 12.17223, total loss: 18.53690, minimum loss: 18.53690\n",
      "the weight is 1.00029, 0.99987. 0.99986, the parameter is -0.00029, 0.00013, 0.00014\n",
      "1500/5000 PDE Loss: 0.37032, BC Loss: 1.27118, data loss: 2.68719, total loss: 4.32869, minimum loss: 4.32869\n",
      "the weight is 1.00040, 0.99986. 0.99986, the parameter is -0.00040, 0.00014, 0.00014\n",
      "2000/5000 PDE Loss: 0.00037, BC Loss: 0.00131, data loss: 0.00211, total loss: 0.00380, minimum loss: 0.00380\n",
      "the weight is 1.00057, 0.99986. 0.99986, the parameter is -0.00057, 0.00014, 0.00014\n",
      "2500/5000 PDE Loss: 0.00008, BC Loss: 0.00099, data loss: 0.00158, total loss: 0.00265, minimum loss: 0.00265\n",
      "the weight is 1.00074, 0.99987. 0.99986, the parameter is -0.00074, 0.00013, 0.00014\n",
      "3000/5000 PDE Loss: 0.00011, BC Loss: 0.00109, data loss: 0.00158, total loss: 0.00277, minimum loss: 0.00259\n",
      "the weight is 1.00090, 0.99987. 0.99986, the parameter is -0.00090, 0.00013, 0.00014\n",
      "3500/5000 PDE Loss: 0.00017, BC Loss: 0.00094, data loss: 0.00145, total loss: 0.00256, minimum loss: 0.00254\n",
      "the weight is 1.00105, 0.99987. 0.99986, the parameter is -0.00105, 0.00013, 0.00014\n",
      "4000/5000 PDE Loss: 0.00016, BC Loss: 0.00091, data loss: 0.00145, total loss: 0.00253, minimum loss: 0.00251\n",
      "the weight is 1.00121, 0.99987. 0.99987, the parameter is -0.00121, 0.00013, 0.00013\n",
      "4500/5000 PDE Loss: 0.00018, BC Loss: 0.00092, data loss: 0.00145, total loss: 0.00255, minimum loss: 0.00249\n",
      "the weight is 1.00136, 0.99987. 0.99987, the parameter is -0.00136, 0.00013, 0.00013\n",
      "run time: 84.53428506851196\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "x_f_s_hist = []\n",
    "x_label_s_hist = []\n",
    "x_data_s_hist = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "    utils.trainingData(K, r, sigma, T, S_range[-1], S_range, t_range, gs, \n",
    "                       samples['bc'], \n",
    "                       samples['fc'], \n",
    "                       samples['pde'], \n",
    "                       RNG_key=123)\n",
    "    \n",
    "    # save training data points to tensor and send to device\n",
    "    n_st_train = torch.from_numpy(n_st_train).float().requires_grad_().to(device)\n",
    "    n_v_train = torch.from_numpy(n_v_train).float().to(device)\n",
    "    \n",
    "    bc_st_train = torch.from_numpy(bc_st_train).float().to(device)\n",
    "    bc_v_train = torch.from_numpy(bc_v_train).float().to(device)   \n",
    "    \n",
    "    # pde residual loss\n",
    "    y1_hat = net(n_st_train)\n",
    "    grads = tgrad.grad(y1_hat, n_st_train, grad_outputs=torch.ones(y1_hat.shape).cuda(), \n",
    "                retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), \n",
    "                    create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*y1_hat)\n",
    "    \n",
    "    # boudary condition loss\n",
    "    y2_hat = net(bc_st_train)\n",
    "    bc_loss = lossFunction(bc_v_train, y2_hat)\n",
    "    \n",
    "    # sample training data loss\n",
    "    y3_hat = net(X_train_tensor)\n",
    "    data_loss = lossFunction(y_train_tensor, y3_hat)\n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    optimizer.zero_grad()\n",
    "    combined_loss = torch.exp(-x_f_s.detach()) * pde_loss + torch.exp(-x_label_s.detach()) * bc_loss + torch.exp(-x_data_s.detach()) * data_loss + x_data_s + x_label_s + x_f_s\n",
    "    combined_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # update the weight\n",
    "    optimizer_adam_weight.zero_grad()\n",
    "    loss = torch.exp(-x_f_s) * pde_loss.detach() + torch.exp(-x_label_s) * bc_loss.detach() + torch.exp(-x_data_s) * data_loss.detach() + x_data_s + x_label_s + x_f_s\n",
    "    loss.backward()\n",
    "    optimizer_adam_weight.step()\n",
    "    \n",
    "    # record the loss\n",
    "    mse_loss = pde_loss + bc_loss + data_loss\n",
    "    loss_hist.append(mse_loss.item())\n",
    "    x_f_s_hist.append(torch.exp(-x_f_s).item())\n",
    "    x_label_s_hist.append(torch.exp(-x_label_s).item())\n",
    "    x_data_s_hist.append(torch.exp(-x_data_s).item())\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'{epoch}/{n_epochs} PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}, data loss: {data_loss.item():.5f}, total loss: {mse_loss.item():.5f}, minimum loss: {min(loss_hist):.5f}')\n",
    "        print(f'the weight is {torch.exp(-x_f_s.detach()).item():.5f}, {torch.exp(-x_label_s.detach()).item():.5f}. {torch.exp(-x_data_s.detach()).item():.5f}, the parameter is {x_f_s.item():.5f}, {x_label_s.item():.5f}, {x_data_s.item():.5f}')\n",
    "    pass\n",
    "end_time = time.time()\n",
    "print('run time:', end_time - start_time)\n",
    "\n",
    "loss_weights_hist = pd.DataFrame({\n",
    "        'PDE_Weight': x_f_s_hist,\n",
    "        'BC_Weight': x_label_s_hist,\n",
    "        'Data_Weight': x_data_s_hist\n",
    "    })\n",
    "# loss_weights_hist.to_csv(f'weights/{w_lr}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = net(X_test_tensor)\n",
    "    test_loss = lossFunction(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106.7266845703125\n",
      "114.90770721435547\n",
      "18.536903381347656\n",
      "4.328686237335205\n",
      "0.0037982212379574776\n",
      "0.002647324465215206\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000):\n",
    "    if i % 500 == 0:\n",
    "        print(loss_hist[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
