{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import errno\n",
    "\n",
    "import CGDs\n",
    "import importlib\n",
    "importlib.reload(CGDs)\n",
    "\n",
    "\n",
    "from pyDOE import lhs\n",
    "from torch import from_numpy\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 25756696576, reserved: 0, free: 0\n"
     ]
    }
   ],
   "source": [
    "def printMemory():\n",
    "  t = torch.cuda.get_device_properties(0).total_memory\n",
    "  r = torch.cuda.memory_reserved(0)\n",
    "  a = torch.cuda.memory_allocated(0)\n",
    "  f = r-a  # free inside reserved\n",
    "  print(f\"total: {t}, reserved: {r}, free: {f}\")\n",
    "  \n",
    "printMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNeuralNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import networks\n",
    "from networks import *\n",
    "layers = np.array([2, 50, 50, 50, 1])\n",
    "#(self, layers, x_test, y_test, u_test, x_bc, y_bc, u_bc, fxy, x_inside_train, y_inside_train):\n",
    "# Create the model\n",
    "PINNBCGD = networks.FeedforwardNeuralNetwork(layers[0], layers[1], layers[-1], len(layers)-1)\n",
    "PINNBCGD.to(device)\n",
    "print(PINNBCGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGMCell(\n",
      "  (sig_act): Tanh()\n",
      "  (Sw): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Uz): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsz): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Ug): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsg): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Ur): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsr): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Uh): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsh): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Wf): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DGM = networks.DGMCell(layers[0], layers[1], layers[-1], len(layers)-1)\n",
    "DGM.to(device)\n",
    "print(DGM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (map): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D_BCGD = Discriminator(2, 25 ,2)\n",
    "D_BCGD.to(device)\n",
    "D_BCGD.load_state_dict(D_BCGD.state_dict()) # copy weights and stuff\n",
    "print(D_BCGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "\n",
    "samples = {\"pde\": 50000, \"bc\":5000, \"fc\":5000}\n",
    "\n",
    "K = 40.0\n",
    "r = 0.05\n",
    "sigma = 0.25\n",
    "T = 1.0\n",
    "S_range = [0.0, 130.0]\n",
    "t_range = [0.0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_st_train, bc_st_train, bc_v_train, n_st_train, n_v_train = utils.trainingData(K, \n",
    "                                                                                  r, \n",
    "                                                                                  sigma, \n",
    "                                                                                  T, \n",
    "                                                                                  S_range[-1], \n",
    "                                                                                  S_range, \n",
    "                                                                                  t_range, \n",
    "                                                                                  gs, \n",
    "                                                                                  samples['bc'], \n",
    "                                                                                  samples['fc'], \n",
    "                                                                                  samples['pde'], \n",
    "                                                                                  RNG_key=123\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.scatter([sublist[0] for sublist in n_st_train], [sublist[1] for sublist in n_st_train], marker='.',alpha=0.3)\n",
    "plt.scatter([sublist[0] for sublist in bc_st_train], [sublist[1] for sublist in bc_st_train], marker='X')\n",
    "plt.xlabel('Time t')\n",
    "plt.ylabel('Option Price s')\n",
    "\n",
    "plt.title('Positions of collocation points and boundary data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 60001\n",
    "graphPer = 0\n",
    "iter_recordBCGD = 200\n",
    "\n",
    "savePer = 60001\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = CGDs.BCGD(max_params=D_BCGD.parameters(), min_params= PINNBCGD.parameters(), device = device,\n",
    "                 lr_max=0.02, lr_min=0.02, tol=1e-10, collect_info=True)\n",
    "lossFunction = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/60001 PDE Loss: 0.00002, BC Loss: 3554.15723\n",
      "500/60001 PDE Loss: 0.02350, BC Loss: 177.92744\n",
      "1000/60001 PDE Loss: 0.00721, BC Loss: 70.76904\n",
      "1500/60001 PDE Loss: 0.00240, BC Loss: 16.56581\n",
      "2000/60001 PDE Loss: 0.00386, BC Loss: 3.85839\n",
      "2500/60001 PDE Loss: 0.00277, BC Loss: 2.56632\n",
      "3000/60001 PDE Loss: 0.00113, BC Loss: 2.51576\n",
      "3500/60001 PDE Loss: 0.00109, BC Loss: 2.14276\n",
      "4000/60001 PDE Loss: 0.00102, BC Loss: 1.73494\n",
      "4500/60001 PDE Loss: 0.00101, BC Loss: 1.26895\n",
      "5000/60001 PDE Loss: 0.00102, BC Loss: 0.96875\n",
      "5500/60001 PDE Loss: 0.00104, BC Loss: 0.75168\n",
      "6000/60001 PDE Loss: 0.00104, BC Loss: 0.58077\n",
      "6500/60001 PDE Loss: 0.00103, BC Loss: 0.44575\n",
      "7000/60001 PDE Loss: 0.00102, BC Loss: 0.35396\n",
      "7500/60001 PDE Loss: 0.00101, BC Loss: 0.29038\n",
      "8000/60001 PDE Loss: 0.00103, BC Loss: 0.25266\n",
      "8500/60001 PDE Loss: 0.00100, BC Loss: 0.23310\n",
      "9000/60001 PDE Loss: 0.00099, BC Loss: 0.22474\n",
      "9500/60001 PDE Loss: 0.00097, BC Loss: 0.22033\n",
      "10000/60001 PDE Loss: 0.00095, BC Loss: 0.21764\n",
      "10500/60001 PDE Loss: 0.00094, BC Loss: 0.21711\n",
      "11000/60001 PDE Loss: 0.00093, BC Loss: 0.21936\n",
      "11500/60001 PDE Loss: 0.00090, BC Loss: 0.22365\n",
      "12000/60001 PDE Loss: 0.00089, BC Loss: 0.22941\n",
      "12500/60001 PDE Loss: 0.00087, BC Loss: 0.23621\n",
      "13000/60001 PDE Loss: 0.00086, BC Loss: 0.24466\n",
      "13500/60001 PDE Loss: 0.00085, BC Loss: 0.25306\n",
      "14000/60001 PDE Loss: 0.00084, BC Loss: 0.26097\n",
      "14500/60001 PDE Loss: 0.00083, BC Loss: 0.27018\n",
      "15000/60001 PDE Loss: 0.00082, BC Loss: 0.26953\n",
      "15500/60001 PDE Loss: 0.00082, BC Loss: 0.26634\n",
      "16000/60001 PDE Loss: 0.00082, BC Loss: 0.26120\n",
      "16500/60001 PDE Loss: 0.00082, BC Loss: 0.25770\n",
      "17000/60001 PDE Loss: 0.00081, BC Loss: 0.25494\n",
      "17500/60001 PDE Loss: 0.00081, BC Loss: 0.25657\n",
      "18000/60001 PDE Loss: 0.00080, BC Loss: 0.25899\n",
      "18500/60001 PDE Loss: 0.00113, BC Loss: 0.26289\n",
      "19000/60001 PDE Loss: 0.00097, BC Loss: 0.26601\n",
      "19500/60001 PDE Loss: 0.00084, BC Loss: 0.26872\n",
      "20000/60001 PDE Loss: 0.00083, BC Loss: 0.27165\n",
      "20500/60001 PDE Loss: 0.00081, BC Loss: 0.27468\n",
      "21000/60001 PDE Loss: 0.00079, BC Loss: 0.27752\n",
      "21500/60001 PDE Loss: 0.00078, BC Loss: 0.28009\n",
      "22000/60001 PDE Loss: 0.00077, BC Loss: 0.28274\n",
      "22500/60001 PDE Loss: 0.00076, BC Loss: 0.28525\n",
      "23000/60001 PDE Loss: 0.00076, BC Loss: 0.28745\n",
      "23500/60001 PDE Loss: 0.00075, BC Loss: 0.28956\n",
      "24000/60001 PDE Loss: 0.00075, BC Loss: 0.29163\n",
      "24500/60001 PDE Loss: 0.00075, BC Loss: 0.29365\n",
      "25000/60001 PDE Loss: 0.00075, BC Loss: 0.29564\n",
      "25500/60001 PDE Loss: 0.00074, BC Loss: 0.29760\n",
      "26000/60001 PDE Loss: 0.00074, BC Loss: 0.29953\n",
      "26500/60001 PDE Loss: 0.00074, BC Loss: 0.30143\n",
      "27000/60001 PDE Loss: 0.00074, BC Loss: 0.30328\n",
      "27500/60001 PDE Loss: 0.00074, BC Loss: 0.30515\n",
      "28000/60001 PDE Loss: 0.00074, BC Loss: 0.30701\n",
      "28500/60001 PDE Loss: 0.00074, BC Loss: 0.30887\n",
      "29000/60001 PDE Loss: 0.00074, BC Loss: 0.31073\n",
      "29500/60001 PDE Loss: 0.00074, BC Loss: 0.31261\n",
      "30000/60001 PDE Loss: 0.00074, BC Loss: 0.31446\n",
      "30500/60001 PDE Loss: 0.00074, BC Loss: 0.31631\n",
      "31000/60001 PDE Loss: 0.00074, BC Loss: 0.31815\n",
      "31500/60001 PDE Loss: 0.00073, BC Loss: 0.31999\n",
      "32000/60001 PDE Loss: 0.00073, BC Loss: 0.32183\n",
      "32500/60001 PDE Loss: 0.00073, BC Loss: 0.32365\n",
      "33000/60001 PDE Loss: 0.00073, BC Loss: 0.32547\n",
      "33500/60001 PDE Loss: 0.00073, BC Loss: 0.32730\n",
      "34000/60001 PDE Loss: 0.00073, BC Loss: 0.32911\n",
      "34500/60001 PDE Loss: 0.00073, BC Loss: 0.33093\n",
      "35000/60001 PDE Loss: 0.00073, BC Loss: 0.33275\n",
      "35500/60001 PDE Loss: 0.00073, BC Loss: 0.33457\n",
      "36000/60001 PDE Loss: 0.00072, BC Loss: 0.33640\n",
      "36500/60001 PDE Loss: 0.00072, BC Loss: 0.33819\n",
      "37000/60001 PDE Loss: 0.00072, BC Loss: 0.34008\n",
      "37500/60001 PDE Loss: 0.00072, BC Loss: 0.34205\n",
      "38000/60001 PDE Loss: 0.00074, BC Loss: 0.34407\n",
      "38500/60001 PDE Loss: 0.00074, BC Loss: 0.34629\n",
      "39000/60001 PDE Loss: 0.00074, BC Loss: 0.34803\n",
      "39500/60001 PDE Loss: 0.00074, BC Loss: 0.34995\n",
      "40000/60001 PDE Loss: 0.00074, BC Loss: 0.35203\n",
      "40500/60001 PDE Loss: 0.00074, BC Loss: 0.35417\n",
      "41000/60001 PDE Loss: 0.00074, BC Loss: 0.35630\n",
      "41500/60001 PDE Loss: 0.00074, BC Loss: 0.35849\n",
      "42000/60001 PDE Loss: 0.00074, BC Loss: 0.36056\n",
      "42500/60001 PDE Loss: 0.00073, BC Loss: 0.36252\n",
      "43000/60001 PDE Loss: 0.00073, BC Loss: 0.36453\n",
      "43500/60001 PDE Loss: 0.00073, BC Loss: 0.36664\n",
      "44000/60001 PDE Loss: 0.00073, BC Loss: 0.36878\n",
      "44500/60001 PDE Loss: 0.00073, BC Loss: 0.37128\n",
      "45000/60001 PDE Loss: 0.00074, BC Loss: 0.37351\n",
      "45500/60001 PDE Loss: 0.00073, BC Loss: 0.37565\n",
      "46000/60001 PDE Loss: 0.00073, BC Loss: 0.37780\n",
      "46500/60001 PDE Loss: 0.00073, BC Loss: 0.37998\n",
      "47000/60001 PDE Loss: 0.00073, BC Loss: 0.38221\n",
      "47500/60001 PDE Loss: 0.00073, BC Loss: 0.38446\n",
      "48000/60001 PDE Loss: 0.00073, BC Loss: 0.38673\n",
      "48500/60001 PDE Loss: 0.00073, BC Loss: 0.38902\n",
      "49000/60001 PDE Loss: 0.00073, BC Loss: 0.39129\n",
      "49500/60001 PDE Loss: 0.00073, BC Loss: 0.39355\n",
      "50000/60001 PDE Loss: 0.00073, BC Loss: 0.39585\n",
      "50500/60001 PDE Loss: 0.00073, BC Loss: 0.39815\n",
      "51000/60001 PDE Loss: 0.00073, BC Loss: 0.40051\n",
      "51500/60001 PDE Loss: 0.00073, BC Loss: 0.40295\n",
      "52000/60001 PDE Loss: 0.00073, BC Loss: 0.40572\n",
      "52500/60001 PDE Loss: 0.00073, BC Loss: 0.40846\n",
      "53000/60001 PDE Loss: 0.00073, BC Loss: 0.41114\n",
      "53500/60001 PDE Loss: 0.00073, BC Loss: 0.41389\n",
      "54000/60001 PDE Loss: 0.00073, BC Loss: 0.41659\n",
      "54500/60001 PDE Loss: 0.00073, BC Loss: 0.41932\n",
      "55000/60001 PDE Loss: 0.00073, BC Loss: 0.42196\n",
      "55500/60001 PDE Loss: 0.00073, BC Loss: 0.42464\n",
      "56000/60001 PDE Loss: 0.00073, BC Loss: 0.42733\n",
      "56500/60001 PDE Loss: 0.00073, BC Loss: 0.43003\n",
      "57000/60001 PDE Loss: 0.00073, BC Loss: 0.43271\n",
      "57500/60001 PDE Loss: 0.00072, BC Loss: 0.43537\n",
      "58000/60001 PDE Loss: 0.00072, BC Loss: 0.43804\n",
      "58500/60001 PDE Loss: 0.00072, BC Loss: 0.44070\n",
      "59000/60001 PDE Loss: 0.00072, BC Loss: 0.44333\n",
      "59500/60001 PDE Loss: 0.00073, BC Loss: 0.44595\n",
      "60000/60001 PDE Loss: 0.00073, BC Loss: 0.44867\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(max_iter):\n",
    "    \n",
    "    all_st_train, bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "    utils.trainingData(K, \n",
    "                       r, \n",
    "                       sigma, \n",
    "                       T, \n",
    "                       S_range[-1], \n",
    "                       S_range, \n",
    "                       t_range, \n",
    "                       gs, \n",
    "                       samples['bc'], \n",
    "                       samples['fc'], \n",
    "                       samples['pde'], \n",
    "                       RNG_key=123)\n",
    "    \n",
    "    \n",
    "    # save training data points to tensor and send to device\n",
    "    all_st_train = torch.from_numpy(all_st_train).float().to(device) \n",
    "    \n",
    "    n_st_train = torch.from_numpy(n_st_train).float().requires_grad_().to(device)\n",
    "    n_v_train = torch.from_numpy(n_v_train).float().to(device)\n",
    "    \n",
    "    bc_st_train = torch.from_numpy(bc_st_train).float().to(device)\n",
    "    bc_v_train = torch.from_numpy(bc_v_train).float().to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # normal loss\n",
    "    # print(n_st_train)\n",
    "    # print(PINNBCGD.output.weight.dtype)\n",
    "    v1_hat = PINNBCGD(n_st_train)\n",
    "    \n",
    "    grads = tgrad.grad(v1_hat, n_st_train, grad_outputs=torch.ones(v1_hat.shape).cuda(), \n",
    "                       retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), create_graph=True, only_inputs=True)[0]\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*v1_hat)\n",
    "    \n",
    "    D_output1 = D_BCGD(n_st_train[:, [0]], n_st_train[:, [1]])\n",
    "    loss1 = D_output1[:,[0]] * pde_loss\n",
    "    \n",
    "    \n",
    "    # boundary condition loss\n",
    "    bc_hat = PINNBCGD(bc_st_train)\n",
    "    bc_loss = lossFunction(bc_v_train, bc_hat)\n",
    "    \n",
    "    loss2 = D_BCGD(bc_st_train[:, [0]], bc_st_train[:, [0]])[:,[1]] * (PINNBCGD(bc_st_train) - bc_v_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    combined_loss = loss1.mean() + loss2.mean()\n",
    "    # combined_loss.backward()\n",
    "    optimizer.step(combined_loss)\n",
    "    \n",
    "    loss_hist.append(combined_loss.item())\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'{epoch}/{max_iter} PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}')\n",
    "        pass\n",
    "        \n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
