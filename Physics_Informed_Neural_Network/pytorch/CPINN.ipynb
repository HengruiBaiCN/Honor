{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import errno\n",
    "\n",
    "import CGDs\n",
    "import importlib\n",
    "importlib.reload(CGDs)\n",
    "\n",
    "\n",
    "from pyDOE import lhs\n",
    "from torch import from_numpy\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 25756696576, reserved: 0, free: 0\n"
     ]
    }
   ],
   "source": [
    "def printMemory():\n",
    "  t = torch.cuda.get_device_properties(0).total_memory\n",
    "  r = torch.cuda.memory_reserved(0)\n",
    "  a = torch.cuda.memory_allocated(0)\n",
    "  f = r-a  # free inside reserved\n",
    "  print(f\"total: {t}, reserved: {r}, free: {f}\")\n",
    "  \n",
    "printMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNeuralNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import networks\n",
    "from networks import *\n",
    "layers = np.array([2, 50, 50, 50, 1])\n",
    "#(self, layers, x_test, y_test, u_test, x_bc, y_bc, u_bc, fxy, x_inside_train, y_inside_train):\n",
    "# Create the model\n",
    "PINNBCGD = networks.FeedforwardNeuralNetwork(layers[0], layers[1], layers[-1], len(layers)-1)\n",
    "PINNBCGD.to(device)\n",
    "print(PINNBCGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGMCell(\n",
      "  (sig_act): Tanh()\n",
      "  (Sw): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (Uz): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (Wsz): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (Ug): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (Wsg): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (Ur): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (Wsr): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (Uh): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (Wsh): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (Wf): Linear(in_features=1, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = DGMCell(layers[0], layers[-1], layers[1], len(layers)-2)\n",
    "model2.to(device)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (map): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D_BCGD = Discriminator(2, 25 ,2)\n",
    "D_BCGD.to(device)\n",
    "D_BCGD.load_state_dict(D_BCGD.state_dict()) # copy weights and stuff\n",
    "print(D_BCGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "\n",
    "samples = {\"pde\": 50000, \"bc\":5000, \"fc\":5000}\n",
    "\n",
    "K = 40.0\n",
    "r = 0.05\n",
    "sigma = 0.25\n",
    "T = 1.0\n",
    "S_range = [0.0, 130.0]\n",
    "t_range = [0.0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_st_train, bc_st_train, bc_v_train, n_st_train, n_v_train = utils.trainingData(K, \n",
    "                                                                                  r, \n",
    "                                                                                  sigma, \n",
    "                                                                                  T, \n",
    "                                                                                  S_range[-1], \n",
    "                                                                                  S_range, \n",
    "                                                                                  t_range, \n",
    "                                                                                  gs, \n",
    "                                                                                  samples['bc'], \n",
    "                                                                                  samples['fc'], \n",
    "                                                                                  samples['pde'], \n",
    "                                                                                  RNG_key=123\n",
    "                                                                                  )\n",
    "\n",
    "# a1, a2 = get_diff_data(samples['pde'])\n",
    "# b1, b2, c1, c2 = get_bvp_data(samples['bvp'])\n",
    "# d1, d2 = get_fvp_data(samples['fvp'])\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.scatter([sublist[0] for sublist in a1], [sublist[1] for sublist in a1], marker='.',alpha=0.3)\n",
    "# plt.scatter([sublist[0] for sublist in b1], [sublist[1] for sublist in b1], marker='X')\n",
    "# plt.scatter([sublist[0] for sublist in c1], [sublist[1] for sublist in c1], marker='X')\n",
    "# plt.scatter([sublist[0] for sublist in d1], [sublist[1] for sublist in d1], marker='X')\n",
    "# plt.xlabel('Time t')\n",
    "# plt.ylabel('Option Price s')\n",
    "\n",
    "# plt.title('Positions of collocation points and boundary data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 60001\n",
    "graphPer = 0\n",
    "iter_recordBCGD = 200\n",
    "\n",
    "savePer = 60001\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = CGDs.BCGD(max_params=D_BCGD.parameters(), min_params= PINNBCGD.parameters(), device = device,\n",
    "                 lr_max=0.02, lr_min=0.02, tol=1e-10, collect_info=True)\n",
    "lossFunction = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/60001 PDE Loss: 0.00721, BVP1 Loss: 634.05426\n",
      "0\n",
      "500/60001 PDE Loss: 0.01246, BVP1 Loss: 15.96776\n",
      "1000/60001 PDE Loss: 0.00115, BVP1 Loss: 0.92679\n",
      "1500/60001 PDE Loss: 0.01806, BVP1 Loss: 0.20812\n",
      "2000/60001 PDE Loss: 0.01016, BVP1 Loss: 0.05958\n",
      "2500/60001 PDE Loss: 0.00059, BVP1 Loss: 0.07297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m combined_loss \u001b[39m=\u001b[39m loss1\u001b[39m.\u001b[39mmean() \u001b[39m+\u001b[39m loss2\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     49\u001b[0m \u001b[39m# combined_loss.backward()\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep(combined_loss)\n\u001b[0;32m     52\u001b[0m loss_hist\u001b[39m.\u001b[39mappend(combined_loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\cgd.py:127\u001b[0m, in \u001b[0;36mBCGD.step\u001b[1;34m(self, loss)\u001b[0m\n\u001b[0;32m    125\u001b[0m     cg_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39madd(grad_x_vec_d, \u001b[39m-\u001b[39m lr_min \u001b[39m*\u001b[39m hcg)\n\u001b[0;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     cg_x, iter_num \u001b[39m=\u001b[39m conjugate_gradient(grad_x\u001b[39m=\u001b[39;49mgrad_x_vec,\n\u001b[0;32m    128\u001b[0m                                         grad_y\u001b[39m=\u001b[39;49mgrad_y_vec,\n\u001b[0;32m    129\u001b[0m                                         x_params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_params,\n\u001b[0;32m    130\u001b[0m                                         y_params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_params,\n\u001b[0;32m    131\u001b[0m                                         b\u001b[39m=\u001b[39;49mp_x, x\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate[\u001b[39m'\u001b[39;49m\u001b[39mold_max\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    132\u001b[0m                                         lr_x\u001b[39m=\u001b[39;49mlr_max, lr_y\u001b[39m=\u001b[39;49mlr_min,\n\u001b[0;32m    133\u001b[0m                                         tol\u001b[39m=\u001b[39;49mtol, atol\u001b[39m=\u001b[39;49matol,\n\u001b[0;32m    134\u001b[0m                                         device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    135\u001b[0m     hcg \u001b[39m=\u001b[39m Hvp_vec(grad_x_vec, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_params, cg_x\u001b[39m.\u001b[39mdetach_())\u001b[39m.\u001b[39mdetach_()\n\u001b[0;32m    136\u001b[0m     cg_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39madd(grad_y_vec_d, lr_max \u001b[39m*\u001b[39m hcg)\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\cgd_utils.py:65\u001b[0m, in \u001b[0;36mconjugate_gradient\u001b[1;34m(grad_x, grad_y, x_params, y_params, b, x, nsteps, tol, atol, lr_x, lr_y, device)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nsteps):\n\u001b[0;32m     63\u001b[0m     \u001b[39m# To compute Avp\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     h_1 \u001b[39m=\u001b[39m Hvp_vec(grad_vec\u001b[39m=\u001b[39mgrad_x, params\u001b[39m=\u001b[39my_params, vec\u001b[39m=\u001b[39mp, retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdetach_()\u001b[39m.\u001b[39mmul(lr_y)\n\u001b[1;32m---> 65\u001b[0m     h_2 \u001b[39m=\u001b[39m Hvp_vec(grad_vec\u001b[39m=\u001b[39;49mgrad_y, params\u001b[39m=\u001b[39;49mx_params, vec\u001b[39m=\u001b[39;49mh_1, retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mdetach_()\u001b[39m.\u001b[39mmul(lr_x)\n\u001b[0;32m     66\u001b[0m     Avp_ \u001b[39m=\u001b[39m p \u001b[39m+\u001b[39m h_2\n\u001b[0;32m     68\u001b[0m     alpha \u001b[39m=\u001b[39m rdotr \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mdot(p, Avp_)\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\cgd_utils.py:113\u001b[0m, in \u001b[0;36mHvp_vec\u001b[1;34m(grad_vec, params, vec, retain_graph, trigger, reducer, rebuild)\u001b[0m\n\u001b[0;32m    109\u001b[0m autograd\u001b[39m.\u001b[39mbackward(grad_vec \u001b[39m+\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39m*\u001b[39m trigger, grad_tensors\u001b[39m=\u001b[39mvec,\n\u001b[0;32m    110\u001b[0m                   inputs\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    111\u001b[0m                   retain_graph\u001b[39m=\u001b[39mretain_graph)\n\u001b[0;32m    112\u001b[0m hvp \u001b[39m=\u001b[39m vectorize_grad(params)\n\u001b[1;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39misnan(hvp)\u001b[39m.\u001b[39many():\n\u001b[0;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mhvp Nan\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m hvp\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(max_iter):\n",
    "    \n",
    "    all_st_train, bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "    utils.trainingData(K, \n",
    "                       r, \n",
    "                       sigma, \n",
    "                       T, \n",
    "                       S_range[-1], \n",
    "                       S_range, \n",
    "                       t_range, \n",
    "                       gs, \n",
    "                       samples['bc'], \n",
    "                       samples['fc'], \n",
    "                       samples['pde'], \n",
    "                       RNG_key=123)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # normal loss\n",
    "    # print(n_st_train)\n",
    "    # print(PINNBCGD.output.weight.dtype)\n",
    "    v1_hat = PINNBCGD(n_st_train)\n",
    "    \n",
    "    grads = tgrad.grad(v1_hat, n_st_train, grad_outputs=torch.ones(v1_hat.shape).cuda(), \n",
    "                       retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), create_graph=True, only_inputs=True)[0]\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*v1_hat)\n",
    "    \n",
    "    D_output1 = D_BCGD(n_st_train[:, [0]], n_st_train[:, [1]])\n",
    "    loss1 = D_output1[:,[0]] * pde_loss\n",
    "    \n",
    "    \n",
    "    # boundary condition loss\n",
    "    bc_hat = PINNBCGD(bc_st_train)\n",
    "    bc_loss = lossFunction(bc_v_train, bc_hat)\n",
    "    \n",
    "    loss2 = D_BCGD(bc_st_train[:, [0]], bc_st_train[:, [0]])[:,[1]] * (PINNBCGD(bc_st_train) - bc_v_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    combined_loss = loss1.mean() + loss2.mean()\n",
    "    # combined_loss.backward()\n",
    "    optimizer.step(combined_loss)\n",
    "    \n",
    "    loss_hist.append(combined_loss.item())\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'{epoch}/{max_iter} PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}')\n",
    "        pass\n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
