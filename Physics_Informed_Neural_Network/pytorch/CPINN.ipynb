{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import errno\n",
    "\n",
    "import CGDs\n",
    "import importlib\n",
    "importlib.reload(CGDs)\n",
    "\n",
    "\n",
    "from pyDOE import lhs\n",
    "from torch import from_numpy\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 25756696576, reserved: 0, free: 0\n"
     ]
    }
   ],
   "source": [
    "def printMemory():\n",
    "  t = torch.cuda.get_device_properties(0).total_memory\n",
    "  r = torch.cuda.memory_reserved(0)\n",
    "  a = torch.cuda.memory_allocated(0)\n",
    "  f = r-a  # free inside reserved\n",
    "  print(f\"total: {t}, reserved: {r}, free: {f}\")\n",
    "  \n",
    "printMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNeuralNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import networks\n",
    "from networks import *\n",
    "layers = np.array([2, 50, 50, 50, 1])\n",
    "#(self, layers, x_test, y_test, u_test, x_bc, y_bc, u_bc, fxy, x_inside_train, y_inside_train):\n",
    "# Create the model\n",
    "PINNBCGD = networks.FeedforwardNeuralNetwork(layers[0], layers[1], layers[-1], len(layers)-1)\n",
    "PINNBCGD.to(device)\n",
    "print(PINNBCGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGMCell(\n",
      "  (sig_act): Tanh()\n",
      "  (Sw): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Uz): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsz): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Ug): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsg): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Ur): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsr): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Uh): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (Wsh): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Wf): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DGM = networks.DGMCell(layers[0], layers[1], layers[-1], len(layers)-1)\n",
    "DGM.to(device)\n",
    "print(DGM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (map): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D_BCGD = Discriminator(2, 25 ,2)\n",
    "D_BCGD.to(device)\n",
    "D_BCGD.load_state_dict(D_BCGD.state_dict()) # copy weights and stuff\n",
    "print(D_BCGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "\n",
    "samples = {\"pde\": 50000, \"bc\":5000, \"fc\":5000}\n",
    "\n",
    "K = 40.0\n",
    "r = 0.05\n",
    "sigma = 0.25\n",
    "T = 1.0\n",
    "S_range = [0.0, 130.0]\n",
    "t_range = [0.0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_st_train, bc_st_train, bc_v_train, n_st_train, n_v_train = utils.trainingData(K, \n",
    "                                                                                  r, \n",
    "                                                                                  sigma, \n",
    "                                                                                  T, \n",
    "                                                                                  S_range[-1], \n",
    "                                                                                  S_range, \n",
    "                                                                                  t_range, \n",
    "                                                                                  gs, \n",
    "                                                                                  samples['bc'], \n",
    "                                                                                  samples['fc'], \n",
    "                                                                                  samples['pde'], \n",
    "                                                                                  RNG_key=123\n",
    "                                                                                  )\n",
    "\n",
    "# a1, a2 = get_diff_data(samples['pde'])\n",
    "# b1, b2, c1, c2 = get_bvp_data(samples['bvp'])\n",
    "# d1, d2 = get_fvp_data(samples['fvp'])\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.scatter([sublist[0] for sublist in a1], [sublist[1] for sublist in a1], marker='.',alpha=0.3)\n",
    "# plt.scatter([sublist[0] for sublist in b1], [sublist[1] for sublist in b1], marker='X')\n",
    "# plt.scatter([sublist[0] for sublist in c1], [sublist[1] for sublist in c1], marker='X')\n",
    "# plt.scatter([sublist[0] for sublist in d1], [sublist[1] for sublist in d1], marker='X')\n",
    "# plt.xlabel('Time t')\n",
    "# plt.ylabel('Option Price s')\n",
    "\n",
    "# plt.title('Positions of collocation points and boundary data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 60001\n",
    "graphPer = 0\n",
    "iter_recordBCGD = 200\n",
    "\n",
    "savePer = 60001\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = CGDs.BCGD(max_params=D_BCGD.parameters(), min_params= PINNBCGD.parameters(), device = device,\n",
    "                 lr_max=0.02, lr_min=0.02, tol=1e-10, collect_info=True)\n",
    "lossFunction = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/60001 PDE Loss: 0.00003, BC Loss: 3454.94995\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(max_iter):\n",
    "    \n",
    "    all_st_train, bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "    utils.trainingData(K, \n",
    "                       r, \n",
    "                       sigma, \n",
    "                       T, \n",
    "                       S_range[-1], \n",
    "                       S_range, \n",
    "                       t_range, \n",
    "                       gs, \n",
    "                       samples['bc'], \n",
    "                       samples['fc'], \n",
    "                       samples['pde'], \n",
    "                       RNG_key=123)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # normal loss\n",
    "    # print(n_st_train)\n",
    "    # print(PINNBCGD.output.weight.dtype)\n",
    "    v1_hat = PINNBCGD(n_st_train)\n",
    "    \n",
    "    grads = tgrad.grad(v1_hat, n_st_train, grad_outputs=torch.ones(v1_hat.shape).cuda(), \n",
    "                       retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), create_graph=True, only_inputs=True)[0]\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*v1_hat)\n",
    "    \n",
    "    D_output1 = D_BCGD(n_st_train[:, [0]], n_st_train[:, [1]])\n",
    "    loss1 = D_output1[:,[0]] * pde_loss\n",
    "    \n",
    "    \n",
    "    # boundary condition loss\n",
    "    bc_hat = PINNBCGD(bc_st_train)\n",
    "    bc_loss = lossFunction(bc_v_train, bc_hat)\n",
    "    \n",
    "    loss2 = D_BCGD(bc_st_train[:, [0]], bc_st_train[:, [0]])[:,[1]] * (PINNBCGD(bc_st_train) - bc_v_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    combined_loss = loss1.mean() + loss2.mean()\n",
    "    # combined_loss.backward()\n",
    "    optimizer.step(combined_loss)\n",
    "    \n",
    "    loss_hist.append(combined_loss.item())\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'{epoch}/{max_iter} PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}')\n",
    "        pass\n",
    "        \n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
