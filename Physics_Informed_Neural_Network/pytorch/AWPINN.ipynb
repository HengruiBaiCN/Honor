{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networks\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "seed = 1234\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling\n",
    "Here in our case, the system is European Call Option PDE and the physical information about the system consists of Boundary Value conditions, final Value conditions and the PDE itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 50\n",
    "r = 0.035\n",
    "sigma = 0.2\n",
    "T = 1\n",
    "S_range = [0, int(5*K)]\n",
    "t_range = [0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, hidden_size)])\n",
    "        self.layers.extend([nn.Linear(hidden_size, hidden_size) for _ in range(n_layers - 1)])\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = self.relu(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# layers = [2, 50, 50, 50, 50, 50, 50, 50, 50, 1] # Network structure\n",
    "net = Net(2, 50,1,3).to(device) #  Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30000\n",
    "lossFunction = nn.MSELoss()\n",
    "\n",
    "from torchimize.functions import lsq_lma\n",
    "# coeffs_list = lsq_lma(fnn.parameters(), function=lossFunction)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00003)\n",
    "\n",
    "x_f_s = torch.tensor(0.).float().to(device).requires_grad_(True)\n",
    "x_label_s = torch.tensor(0.).float().to(device).requires_grad_(True)\n",
    "optimizer_adam_weight = torch.optim.Adam([x_f_s] + [x_label_s], lr=0.0003)\n",
    "\n",
    "\n",
    "samples = {\"pde\": 5000, \"bc\":500, \"fc\":500}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/30000 PDE Loss: 0.00038, BC Loss: 16734.41797, nn_loss: 16734.417969, total loss: 16734.41797, minimum loss: 16734.41797\n",
      "the weight is 1.00030, 1.00030\n",
      "500/30000 PDE Loss: 0.00055, BC Loss: 9564.14648, nn_loss: 10890.958984, total loss: 9564.14746, minimum loss: 9564.14746\n",
      "the weight is 1.16218, 1.13899\n",
      "1000/30000 PDE Loss: 0.00688, BC Loss: 1142.82397, nn_loss: 1380.223999, total loss: 1142.83081, minimum loss: 1142.83081\n",
      "the weight is 1.35037, 1.20819\n",
      "1500/30000 PDE Loss: 0.17600, BC Loss: 159.70251, nn_loss: 193.798584, total loss: 159.87852, minimum loss: 159.87852\n",
      "the weight is 1.57356, 1.21583\n",
      "2000/30000 PDE Loss: 0.45613, BC Loss: 151.86432, nn_loss: 185.377991, total loss: 152.32045, minimum loss: 152.32045\n",
      "the weight is 1.84281, 1.22049\n",
      "2500/30000 PDE Loss: 0.96433, BC Loss: 144.62543, nn_loss: 178.486710, total loss: 145.58975, minimum loss: 145.58975\n",
      "the weight is 2.16894, 1.22645\n",
      "3000/30000 PDE Loss: 1.77401, BC Loss: 136.07768, nn_loss: 171.296997, total loss: 137.85168, minimum loss: 137.85168\n",
      "the weight is 2.56595, 1.23386\n",
      "3500/30000 PDE Loss: 2.69092, BC Loss: 126.77285, nn_loss: 164.416641, total loss: 129.46378, minimum loss: 129.46378\n",
      "the weight is 3.04229, 1.24289\n",
      "4000/30000 PDE Loss: 3.06552, BC Loss: 117.86520, nn_loss: 157.263763, total loss: 120.93072, minimum loss: 120.93072\n",
      "the weight is 3.58727, 1.25377\n",
      "4500/30000 PDE Loss: 2.58957, BC Loss: 109.24206, nn_loss: 147.532898, total loss: 111.83163, minimum loss: 111.83163\n",
      "the weight is 4.17573, 1.26683\n",
      "5000/30000 PDE Loss: 1.79144, BC Loss: 99.23463, nn_loss: 134.029907, total loss: 101.02607, minimum loss: 101.02607\n",
      "the weight is 4.80340, 1.28230\n",
      "5500/30000 PDE Loss: 1.07985, BC Loss: 86.99856, nn_loss: 117.065468, total loss: 88.07841, minimum loss: 88.07841\n",
      "the weight is 5.49063, 1.30010\n",
      "6000/30000 PDE Loss: 0.68014, BC Loss: 72.94930, nn_loss: 98.426971, total loss: 73.62943, minimum loss: 73.62943\n",
      "the weight is 6.27050, 1.31981\n",
      "6500/30000 PDE Loss: 0.35058, BC Loss: 58.85827, nn_loss: 79.162910, total loss: 59.20885, minimum loss: 59.20885\n",
      "the weight is 7.17827, 1.34074\n",
      "7000/30000 PDE Loss: 0.19394, BC Loss: 44.92205, nn_loss: 60.364353, total loss: 45.11599, minimum loss: 45.11599\n",
      "the weight is 8.24368, 1.36205\n",
      "7500/30000 PDE Loss: 0.11687, BC Loss: 32.47641, nn_loss: 43.439911, total loss: 32.59328, minimum loss: 32.59328\n",
      "the weight is 9.49860, 1.38274\n",
      "8000/30000 PDE Loss: 0.06965, BC Loss: 21.97680, nn_loss: 28.838322, total loss: 22.04645, minimum loss: 22.04645\n",
      "the weight is 10.97306, 1.40184\n",
      "8500/30000 PDE Loss: 0.04344, BC Loss: 13.42572, nn_loss: 16.705479, total loss: 13.46916, minimum loss: 13.46916\n",
      "the weight is 12.70082, 1.41857\n",
      "9000/30000 PDE Loss: 0.02998, BC Loss: 6.89016, nn_loss: 7.259979, total loss: 6.92014, minimum loss: 6.92014\n",
      "the weight is 14.72030, 1.43203\n",
      "9500/30000 PDE Loss: 0.02084, BC Loss: 3.06720, nn_loss: 1.576129, total loss: 3.08804, minimum loss: 3.08804\n",
      "the weight is 17.07597, 1.44240\n",
      "10000/30000 PDE Loss: 0.01430, BC Loss: 1.11813, nn_loss: -1.453053, total loss: 1.13242, minimum loss: 1.13242\n",
      "the weight is 19.81992, 1.45083\n",
      "10500/30000 PDE Loss: 0.02888, BC Loss: 0.26756, nn_loss: -2.458625, total loss: 0.29644, minimum loss: 0.29644\n",
      "the weight is 23.01319, 1.45879\n",
      "11000/30000 PDE Loss: 0.00729, BC Loss: 0.07953, nn_loss: -3.357610, total loss: 0.08681, minimum loss: 0.08337\n",
      "the weight is 26.72745, 1.46761\n",
      "11500/30000 PDE Loss: 0.00393, BC Loss: 0.02018, nn_loss: -3.674559, total loss: 0.02410, minimum loss: 0.02409\n",
      "the weight is 31.04494, 1.47860\n",
      "12000/30000 PDE Loss: 0.00222, BC Loss: 0.01717, nn_loss: -3.879764, total loss: 0.01940, minimum loss: 0.00990\n",
      "the weight is 36.06352, 1.49269\n",
      "12500/30000 PDE Loss: 0.00104, BC Loss: 0.00339, nn_loss: -4.098750, total loss: 0.00443, minimum loss: 0.00443\n",
      "the weight is 41.89545, 1.51090\n",
      "13000/30000 PDE Loss: 0.00072, BC Loss: 0.00241, nn_loss: -4.274548, total loss: 0.00312, minimum loss: 0.00312\n",
      "the weight is 48.67388, 1.53455\n",
      "13500/30000 PDE Loss: 0.00058, BC Loss: 0.00190, nn_loss: -4.447155, total loss: 0.00248, minimum loss: 0.00248\n",
      "the weight is 56.54903, 1.56538\n",
      "14000/30000 PDE Loss: 0.00049, BC Loss: 0.00164, nn_loss: -4.623234, total loss: 0.00213, minimum loss: 0.00213\n",
      "the weight is 65.69833, 1.60558\n",
      "14500/30000 PDE Loss: 0.00042, BC Loss: 0.00136, nn_loss: -4.805962, total loss: 0.00178, minimum loss: 0.00178\n",
      "the weight is 76.32791, 1.65832\n",
      "15000/30000 PDE Loss: 0.00036, BC Loss: 0.00113, nn_loss: -4.997651, total loss: 0.00149, minimum loss: 0.00149\n",
      "the weight is 88.67731, 1.72738\n",
      "15500/30000 PDE Loss: 0.00032, BC Loss: 0.00092, nn_loss: -5.197582, total loss: 0.00124, minimum loss: 0.00124\n",
      "the weight is 103.02475, 1.81824\n",
      "16000/30000 PDE Loss: 0.00030, BC Loss: 0.00072, nn_loss: -5.408374, total loss: 0.00102, minimum loss: 0.00102\n",
      "the weight is 119.69353, 1.93709\n",
      "16500/30000 PDE Loss: 0.00028, BC Loss: 0.00055, nn_loss: -5.632994, total loss: 0.00083, minimum loss: 0.00083\n",
      "the weight is 139.05922, 2.09201\n",
      "17000/30000 PDE Loss: 0.00028, BC Loss: 0.00039, nn_loss: -5.868204, total loss: 0.00066, minimum loss: 0.00066\n",
      "the weight is 161.55814, 2.29274\n",
      "17500/30000 PDE Loss: 0.00026, BC Loss: 0.00027, nn_loss: -6.119356, total loss: 0.00053, minimum loss: 0.00053\n",
      "the weight is 187.69728, 2.54683\n",
      "18000/30000 PDE Loss: 0.00026, BC Loss: 0.00013, nn_loss: -6.380353, total loss: 0.00038, minimum loss: 0.00038\n",
      "the weight is 218.06554, 2.86434\n",
      "18500/30000 PDE Loss: 0.00026, BC Loss: 0.00007, nn_loss: -6.648856, total loss: 0.00032, minimum loss: 0.00032\n",
      "the weight is 253.34721, 3.25405\n",
      "19000/30000 PDE Loss: 0.00025, BC Loss: 0.00005, nn_loss: -6.924741, total loss: 0.00031, minimum loss: 0.00031\n",
      "the weight is 294.33725, 3.72578\n",
      "19500/30000 PDE Loss: 0.00025, BC Loss: 0.00003, nn_loss: -7.202940, total loss: 0.00029, minimum loss: 0.00029\n",
      "the weight is 341.95923, 4.28706\n",
      "20000/30000 PDE Loss: 0.00025, BC Loss: 0.00002, nn_loss: -7.483512, total loss: 0.00027, minimum loss: 0.00027\n",
      "the weight is 397.28616, 4.95056\n",
      "20500/30000 PDE Loss: 0.00025, BC Loss: 1.58779, nn_loss: 1.331369, total loss: 1.58804, minimum loss: 0.00027\n",
      "the weight is 461.56464, 5.73009\n",
      "21000/30000 PDE Loss: 0.00025, BC Loss: 0.00002, nn_loss: -8.043096, total loss: 0.00027, minimum loss: 0.00027\n",
      "the weight is 536.24298, 6.64356\n",
      "21500/30000 PDE Loss: 0.00025, BC Loss: 0.00002, nn_loss: -8.320003, total loss: 0.00027, minimum loss: 0.00026\n",
      "the weight is 623.00378, 7.70678\n",
      "22000/30000 PDE Loss: 0.00025, BC Loss: 0.00002, nn_loss: -8.593395, total loss: 0.00027, minimum loss: 0.00026\n",
      "the weight is 723.80206, 8.94555\n",
      "22500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -8.863626, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 840.90881, 10.38720\n",
      "23000/30000 PDE Loss: 0.00026, BC Loss: 0.00002, nn_loss: -9.118845, total loss: 0.00028, minimum loss: 0.00026\n",
      "the weight is 976.96271, 12.06587\n",
      "23500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -9.388258, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 1135.02942, 14.01447\n",
      "24000/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -9.642187, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 1318.67017, 16.27987\n",
      "24500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -9.888639, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 1532.02295, 18.91218\n",
      "25000/30000 PDE Loss: 0.00026, BC Loss: 0.17963, nn_loss: -6.157187, total loss: 0.17989, minimum loss: 0.00026\n",
      "the weight is 1779.89502, 21.97430\n",
      "25500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -10.348644, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 2067.87134, 25.52901\n",
      "26000/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -10.568140, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 2402.43994, 29.65944\n",
      "26500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -10.773207, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 2791.14038, 34.45816\n",
      "27000/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -10.963221, total loss: 0.00026, minimum loss: 0.00026\n",
      "the weight is 3243.16455, 40.03328\n",
      "27500/30000 PDE Loss: 0.00026, BC Loss: 0.00007, nn_loss: -11.082633, total loss: 0.00033, minimum loss: 0.00024\n",
      "the weight is 3768.78711, 46.51391\n",
      "28000/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -11.283766, total loss: 0.00026, minimum loss: 0.00024\n",
      "the weight is 4379.59766, 54.03958\n",
      "28500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -11.408447, total loss: 0.00026, minimum loss: 0.00024\n",
      "the weight is 5089.40332, 62.78287\n",
      "29000/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -11.506058, total loss: 0.00026, minimum loss: 0.00024\n",
      "the weight is 5914.24805, 72.94076\n",
      "29500/30000 PDE Loss: 0.00025, BC Loss: 0.00001, nn_loss: -11.570499, total loss: 0.00026, minimum loss: 0.00024\n",
      "the weight is 6872.77588, 84.74282\n",
      "run time: 128.9432578086853\n",
      "Adam done!\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "    utils.trainingData(K, \n",
    "                       r, \n",
    "                       sigma, \n",
    "                       T, \n",
    "                       S_range[-1], \n",
    "                       S_range, \n",
    "                       t_range, \n",
    "                       gs, \n",
    "                       samples['bc'], \n",
    "                       samples['fc'], \n",
    "                       samples['pde'], \n",
    "                       RNG_key=123)\n",
    "    # save training data points to tensor and send to device\n",
    "    n_st_train = torch.from_numpy(n_st_train).float().requires_grad_().to(device)\n",
    "    n_v_train = torch.from_numpy(n_v_train).float().to(device)\n",
    "    \n",
    "    bc_st_train = torch.from_numpy(bc_st_train).float().to(device)\n",
    "    bc_v_train = torch.from_numpy(bc_v_train).float().to(device)\n",
    "\n",
    "\n",
    "    # PDE Round\n",
    "    y1_hat = net(n_st_train)\n",
    "    grads = tgrad.grad(y1_hat, n_st_train, grad_outputs=torch.ones(y1_hat.shape).cuda(), retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), create_graph=True, only_inputs=True)[0]\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*y1_hat)\n",
    "    \n",
    "    # conditions Round\n",
    "    y21_hat = net(bc_st_train)\n",
    "    bc_loss = lossFunction(bc_v_train, y21_hat)\n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    optimizer.zero_grad()\n",
    "    combined_loss = torch.exp(-x_f_s.detach()) * pde_loss + torch.exp(-x_label_s.detach()) * bc_loss + x_f_s.detach() + x_label_s.detach()\n",
    "    combined_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # update the weight\n",
    "    optimizer_adam_weight.zero_grad()\n",
    "    loss = 1/(2*torch.exp(-x_f_s)) * pde_loss.detach() + 1/(2*torch.exp(-x_label_s)) * bc_loss.detach() + x_label_s + x_f_s\n",
    "    loss.backward()\n",
    "    optimizer_adam_weight.step()\n",
    "    \n",
    "    # record the loss\n",
    "    mse_loss = pde_loss + bc_loss\n",
    "    loss_hist.append(mse_loss.item())\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'{epoch}/{n_epochs} PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}, nn_loss: {combined_loss.item():5f}, total loss: {mse_loss.item():.5f}, minimum loss: {min(loss_hist):.5f}')\n",
    "        print(f'the weight is {torch.exp(-x_f_s.detach()).item():.5f}, {torch.exp(-x_label_s.detach()).item():.5f}')\n",
    "    pass\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('run time:', end_time - start_time)\n",
    "print('Adam done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
