{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import errno\n",
    "import utils\n",
    "\n",
    "import CGDs\n",
    "import importlib\n",
    "importlib.reload(CGDs)\n",
    "\n",
    "\n",
    "from pyDOE import lhs\n",
    "from torch import from_numpy\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as tgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\"pde\": 10000, \"bc\":5000, \"fc\":5000}\n",
    "\n",
    "K = 40.0\n",
    "r = 0.05\n",
    "sigma = 0.25\n",
    "T = 1.0\n",
    "S_range = [0.0, 130.0]\n",
    "t_range = [0.0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNeuralNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import networks\n",
    "# Create the model\n",
    "PINNCGD = networks.FeedforwardNeuralNetwork(2, 50, 1, 3)\n",
    "PINNCGD.to(device)\n",
    "print(PINNCGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (map): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D_CGD = networks.Discriminator(2, 25, 4)\n",
    "D_CGD.to(device)\n",
    "D_CGD.load_state_dict(D_CGD.state_dict()) # copy weights and stuff\n",
    "print(D_CGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 30000\n",
    "\n",
    "tol = 1e-7\n",
    "atol = 1e-20\n",
    "g_iter = 1000\n",
    "lr = 0.01\n",
    "track_cond = lambda x, y: True\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "# optimizer = CGDs.BCGD(max_params=D_CGD.parameters(), min_params=PINNCGD.parameters(), device = device,\n",
    "#                  lr_max=lr, lr_min=lr, tol=1e-10, collect_info=True)\n",
    "# optimizer = CGDs.ACGD(max_params=D_CGD.parameters(), min_params=PINNCGD.parameters(),\n",
    "#                  lr_max=lr, lr_min=lr, tol=1e-10, beta=0.99, eps=1e-8, collect_info=True)\n",
    "optimizer = CGDs.GACGD(x_params=D_CGD.parameters(), y_params = PINNCGD.parameters(), max_iter = g_iter,\n",
    "            lr_x=0.001, lr_y=0.01, tol=tol, atol = atol, eps=1e-8, beta=0.99, track_cond = track_cond)\n",
    "lossFunction = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\gmres_torch.py:124: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:2197.)\n",
      "  y, _ = torch.triangular_solve(beta[0:j + 1].unsqueeze(-1), H[0:j + 1, 0:j + 1])  # j x j\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/30000 mse loss: 9687.691406, \n",
      "              PDE Loss: 0.000028, BC Loss: 9687.691406, \n",
      "              nn loss: 245.78974915, \n",
      "              minloss: 9687.691406\n",
      "              \n",
      "50/30000 mse loss: 16.694838, \n",
      "              PDE Loss: 2.113338, BC Loss: 14.581500, \n",
      "              nn loss: 0.40101784, \n",
      "              minloss: 8.439303\n",
      "              \n",
      "100/30000 mse loss: 10.714383, \n",
      "              PDE Loss: 0.856960, BC Loss: 9.857423, \n",
      "              nn loss: 0.01971586, \n",
      "              minloss: 8.439303\n",
      "              \n",
      "150/30000 mse loss: 7.828498, \n",
      "              PDE Loss: 3.372201, BC Loss: 4.456296, \n",
      "              nn loss: -0.08646940, \n",
      "              minloss: 2.880805\n",
      "              \n",
      "200/30000 mse loss: 1.207664, \n",
      "              PDE Loss: 0.574182, BC Loss: 0.633482, \n",
      "              nn loss: -0.04367741, \n",
      "              minloss: 0.964447\n",
      "              \n",
      "250/30000 mse loss: 0.922177, \n",
      "              PDE Loss: 0.634012, BC Loss: 0.288165, \n",
      "              nn loss: -0.03758368, \n",
      "              minloss: 0.354790\n",
      "              \n",
      "300/30000 mse loss: 0.404008, \n",
      "              PDE Loss: 0.148211, BC Loss: 0.255797, \n",
      "              nn loss: -0.01669902, \n",
      "              minloss: 0.321479\n",
      "              \n",
      "350/30000 mse loss: 0.331753, \n",
      "              PDE Loss: 0.129330, BC Loss: 0.202423, \n",
      "              nn loss: -0.00091578, \n",
      "              minloss: 0.242400\n",
      "              \n",
      "400/30000 mse loss: 0.183953, \n",
      "              PDE Loss: 0.026969, BC Loss: 0.156984, \n",
      "              nn loss: -0.00347200, \n",
      "              minloss: 0.183953\n",
      "              \n",
      "450/30000 mse loss: 0.143908, \n",
      "              PDE Loss: 0.014126, BC Loss: 0.129782, \n",
      "              nn loss: -0.00070808, \n",
      "              minloss: 0.131319\n",
      "              \n",
      "500/30000 mse loss: 0.068951, \n",
      "              PDE Loss: 0.008653, BC Loss: 0.060298, \n",
      "              nn loss: -0.00461578, \n",
      "              minloss: 0.059779\n",
      "              \n",
      "550/30000 mse loss: 0.015115, \n",
      "              PDE Loss: 0.005210, BC Loss: 0.009905, \n",
      "              nn loss: -0.00167572, \n",
      "              minloss: 0.015115\n",
      "              \n",
      "600/30000 mse loss: 0.013499, \n",
      "              PDE Loss: 0.004349, BC Loss: 0.009150, \n",
      "              nn loss: 0.00018355, \n",
      "              minloss: 0.009727\n",
      "              \n",
      "650/30000 mse loss: 0.022634, \n",
      "              PDE Loss: 0.006885, BC Loss: 0.015749, \n",
      "              nn loss: -0.00002945, \n",
      "              minloss: 0.009727\n",
      "              \n",
      "700/30000 mse loss: 0.041071, \n",
      "              PDE Loss: 0.006698, BC Loss: 0.034373, \n",
      "              nn loss: -0.00061871, \n",
      "              minloss: 0.009727\n",
      "              \n",
      "750/30000 mse loss: 0.018248, \n",
      "              PDE Loss: 0.005333, BC Loss: 0.012915, \n",
      "              nn loss: -0.00110389, \n",
      "              minloss: 0.009727\n",
      "              \n",
      "800/30000 mse loss: 0.008778, \n",
      "              PDE Loss: 0.003131, BC Loss: 0.005646, \n",
      "              nn loss: -0.00138230, \n",
      "              minloss: 0.008095\n",
      "              \n",
      "850/30000 mse loss: 0.005232, \n",
      "              PDE Loss: 0.002988, BC Loss: 0.002244, \n",
      "              nn loss: -0.00183323, \n",
      "              minloss: 0.004923\n",
      "              \n",
      "900/30000 mse loss: 0.007274, \n",
      "              PDE Loss: 0.005040, BC Loss: 0.002234, \n",
      "              nn loss: -0.00220400, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "950/30000 mse loss: 0.024588, \n",
      "              PDE Loss: 0.018270, BC Loss: 0.006318, \n",
      "              nn loss: -0.00076002, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1000/30000 mse loss: 0.080904, \n",
      "              PDE Loss: 0.059425, BC Loss: 0.021479, \n",
      "              nn loss: -0.00283215, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1050/30000 mse loss: 0.011535, \n",
      "              PDE Loss: 0.009195, BC Loss: 0.002340, \n",
      "              nn loss: -0.00349574, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1100/30000 mse loss: 0.114005, \n",
      "              PDE Loss: 0.094675, BC Loss: 0.019330, \n",
      "              nn loss: -0.01681549, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1150/30000 mse loss: 0.034026, \n",
      "              PDE Loss: 0.019345, BC Loss: 0.014681, \n",
      "              nn loss: -0.00026189, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1200/30000 mse loss: 0.019617, \n",
      "              PDE Loss: 0.008849, BC Loss: 0.010768, \n",
      "              nn loss: -0.00417574, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1250/30000 mse loss: 0.014957, \n",
      "              PDE Loss: 0.003384, BC Loss: 0.011573, \n",
      "              nn loss: -0.00452144, \n",
      "              minloss: 0.004356\n",
      "              \n",
      "1300/30000 mse loss: 0.005891, \n",
      "              PDE Loss: 0.002512, BC Loss: 0.003380, \n",
      "              nn loss: -0.00643814, \n",
      "              minloss: 0.004181\n",
      "              \n",
      "1350/30000 mse loss: 0.005458, \n",
      "              PDE Loss: 0.002184, BC Loss: 0.003274, \n",
      "              nn loss: -0.01011466, \n",
      "              minloss: 0.004181\n",
      "              \n",
      "1400/30000 mse loss: 0.135106, \n",
      "              PDE Loss: 0.011521, BC Loss: 0.123584, \n",
      "              nn loss: -0.00421444, \n",
      "              minloss: 0.004181\n",
      "              \n",
      "1450/30000 mse loss: 0.006011, \n",
      "              PDE Loss: 0.001530, BC Loss: 0.004481, \n",
      "              nn loss: -0.00972420, \n",
      "              minloss: 0.004181\n",
      "              \n",
      "1500/30000 mse loss: 0.005714, \n",
      "              PDE Loss: 0.002077, BC Loss: 0.003637, \n",
      "              nn loss: -0.01474405, \n",
      "              minloss: 0.003233\n",
      "              \n",
      "1550/30000 mse loss: 0.005486, \n",
      "              PDE Loss: 0.001332, BC Loss: 0.004153, \n",
      "              nn loss: -0.01398692, \n",
      "              minloss: 0.003233\n",
      "              \n",
      "1600/30000 mse loss: 0.003062, \n",
      "              PDE Loss: 0.001254, BC Loss: 0.001808, \n",
      "              nn loss: -0.02283913, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1650/30000 mse loss: 0.004456, \n",
      "              PDE Loss: 0.001596, BC Loss: 0.002859, \n",
      "              nn loss: -0.03222713, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1700/30000 mse loss: 0.010126, \n",
      "              PDE Loss: 0.002110, BC Loss: 0.008017, \n",
      "              nn loss: -0.05816274, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1750/30000 mse loss: 0.033814, \n",
      "              PDE Loss: 0.002498, BC Loss: 0.031316, \n",
      "              nn loss: -0.04779321, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1800/30000 mse loss: 0.032353, \n",
      "              PDE Loss: 0.007949, BC Loss: 0.024404, \n",
      "              nn loss: -0.00693193, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1850/30000 mse loss: 0.009444, \n",
      "              PDE Loss: 0.004543, BC Loss: 0.004901, \n",
      "              nn loss: -0.03480609, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1900/30000 mse loss: 0.037773, \n",
      "              PDE Loss: 0.008916, BC Loss: 0.028857, \n",
      "              nn loss: -0.06660020, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "1950/30000 mse loss: 0.008280, \n",
      "              PDE Loss: 0.002871, BC Loss: 0.005409, \n",
      "              nn loss: -0.09996475, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2000/30000 mse loss: 0.007728, \n",
      "              PDE Loss: 0.002321, BC Loss: 0.005408, \n",
      "              nn loss: -0.19407471, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2050/30000 mse loss: 0.035698, \n",
      "              PDE Loss: 0.008507, BC Loss: 0.027191, \n",
      "              nn loss: -0.27636245, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2100/30000 mse loss: 0.047102, \n",
      "              PDE Loss: 0.006950, BC Loss: 0.040152, \n",
      "              nn loss: -0.20963757, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2150/30000 mse loss: 0.026911, \n",
      "              PDE Loss: 0.003360, BC Loss: 0.023551, \n",
      "              nn loss: -0.96835905, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2200/30000 mse loss: 0.034497, \n",
      "              PDE Loss: 0.002069, BC Loss: 0.032428, \n",
      "              nn loss: -1.44419765, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2250/30000 mse loss: 0.590960, \n",
      "              PDE Loss: 0.080379, BC Loss: 0.510582, \n",
      "              nn loss: -0.71513468, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2300/30000 mse loss: 0.577094, \n",
      "              PDE Loss: 0.039296, BC Loss: 0.537799, \n",
      "              nn loss: -1.32077682, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2350/30000 mse loss: 0.048167, \n",
      "              PDE Loss: 0.006511, BC Loss: 0.041656, \n",
      "              nn loss: -2.16364694, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2400/30000 mse loss: 0.023336, \n",
      "              PDE Loss: 0.003853, BC Loss: 0.019483, \n",
      "              nn loss: -2.64172363, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2450/30000 mse loss: 0.030866, \n",
      "              PDE Loss: 0.020761, BC Loss: 0.010106, \n",
      "              nn loss: -2.94233513, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2500/30000 mse loss: 0.443415, \n",
      "              PDE Loss: 0.057770, BC Loss: 0.385645, \n",
      "              nn loss: -3.43914080, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2550/30000 mse loss: 0.065803, \n",
      "              PDE Loss: 0.013224, BC Loss: 0.052579, \n",
      "              nn loss: -3.57252741, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2600/30000 mse loss: 0.035652, \n",
      "              PDE Loss: 0.022953, BC Loss: 0.012699, \n",
      "              nn loss: -4.15993977, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2650/30000 mse loss: 0.051153, \n",
      "              PDE Loss: 0.016459, BC Loss: 0.034695, \n",
      "              nn loss: -4.86265755, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2700/30000 mse loss: 0.182660, \n",
      "              PDE Loss: 0.031644, BC Loss: 0.151015, \n",
      "              nn loss: -4.49301100, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2750/30000 mse loss: 0.062219, \n",
      "              PDE Loss: 0.021919, BC Loss: 0.040300, \n",
      "              nn loss: -1.23246169, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2800/30000 mse loss: 0.413412, \n",
      "              PDE Loss: 0.156736, BC Loss: 0.256676, \n",
      "              nn loss: -5.82925081, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2850/30000 mse loss: 0.330411, \n",
      "              PDE Loss: 0.024042, BC Loss: 0.306369, \n",
      "              nn loss: -7.19196320, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2900/30000 mse loss: 0.009291, \n",
      "              PDE Loss: 0.004356, BC Loss: 0.004936, \n",
      "              nn loss: -7.92033815, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "2950/30000 mse loss: 0.114085, \n",
      "              PDE Loss: 0.025014, BC Loss: 0.089071, \n",
      "              nn loss: -8.56868362, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3000/30000 mse loss: 0.369718, \n",
      "              PDE Loss: 0.086573, BC Loss: 0.283145, \n",
      "              nn loss: -3.86684251, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3050/30000 mse loss: 0.696183, \n",
      "              PDE Loss: 0.075840, BC Loss: 0.620343, \n",
      "              nn loss: -7.03871918, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3100/30000 mse loss: 0.253696, \n",
      "              PDE Loss: 0.050133, BC Loss: 0.203563, \n",
      "              nn loss: -9.93852425, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3150/30000 mse loss: 1.121412, \n",
      "              PDE Loss: 0.229979, BC Loss: 0.891433, \n",
      "              nn loss: -0.61250252, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3200/30000 mse loss: 0.212793, \n",
      "              PDE Loss: 0.074351, BC Loss: 0.138441, \n",
      "              nn loss: -11.04290962, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3250/30000 mse loss: 45.259624, \n",
      "              PDE Loss: 0.093554, BC Loss: 45.166069, \n",
      "              nn loss: -12.89938354, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3300/30000 mse loss: 0.373018, \n",
      "              PDE Loss: 0.225994, BC Loss: 0.147024, \n",
      "              nn loss: -11.72257805, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3350/30000 mse loss: 0.275827, \n",
      "              PDE Loss: 0.128296, BC Loss: 0.147530, \n",
      "              nn loss: -11.03074455, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3400/30000 mse loss: 0.315393, \n",
      "              PDE Loss: 0.093785, BC Loss: 0.221608, \n",
      "              nn loss: -7.02730894, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3450/30000 mse loss: 0.535799, \n",
      "              PDE Loss: 0.175303, BC Loss: 0.360496, \n",
      "              nn loss: -12.21001816, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3500/30000 mse loss: 0.465731, \n",
      "              PDE Loss: 0.096689, BC Loss: 0.369042, \n",
      "              nn loss: -12.62838840, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3550/30000 mse loss: 0.212526, \n",
      "              PDE Loss: 0.107382, BC Loss: 0.105144, \n",
      "              nn loss: -14.85536098, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3600/30000 mse loss: 0.315922, \n",
      "              PDE Loss: 0.143714, BC Loss: 0.172208, \n",
      "              nn loss: -15.47813129, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3650/30000 mse loss: 0.237440, \n",
      "              PDE Loss: 0.102607, BC Loss: 0.134833, \n",
      "              nn loss: -16.32599831, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3700/30000 mse loss: 0.689406, \n",
      "              PDE Loss: 0.126648, BC Loss: 0.562757, \n",
      "              nn loss: -19.42947578, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3750/30000 mse loss: 13.078934, \n",
      "              PDE Loss: 0.524637, BC Loss: 12.554297, \n",
      "              nn loss: -0.27049279, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3800/30000 mse loss: 2.936286, \n",
      "              PDE Loss: 0.932122, BC Loss: 2.004164, \n",
      "              nn loss: -9.01504707, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3850/30000 mse loss: 1.582703, \n",
      "              PDE Loss: 0.143165, BC Loss: 1.439538, \n",
      "              nn loss: -17.36955261, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3900/30000 mse loss: 1.240233, \n",
      "              PDE Loss: 0.060515, BC Loss: 1.179718, \n",
      "              nn loss: -17.68544579, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "3950/30000 mse loss: 0.466269, \n",
      "              PDE Loss: 0.088253, BC Loss: 0.378016, \n",
      "              nn loss: -20.02430725, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4000/30000 mse loss: 6.193479, \n",
      "              PDE Loss: 0.278655, BC Loss: 5.914824, \n",
      "              nn loss: -6.64315081, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4050/30000 mse loss: 0.903419, \n",
      "              PDE Loss: 0.232250, BC Loss: 0.671169, \n",
      "              nn loss: -6.70071840, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4100/30000 mse loss: 140.900665, \n",
      "              PDE Loss: 12.874484, BC Loss: 128.026184, \n",
      "              nn loss: 25.46957016, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4150/30000 mse loss: 141.850143, \n",
      "              PDE Loss: 41.022694, BC Loss: 100.827454, \n",
      "              nn loss: -35.81357956, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4200/30000 mse loss: 186.814301, \n",
      "              PDE Loss: 1.825806, BC Loss: 184.988495, \n",
      "              nn loss: 1.73119807, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4250/30000 mse loss: 116.067184, \n",
      "              PDE Loss: 2.898771, BC Loss: 113.168411, \n",
      "              nn loss: -22.80933952, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4300/30000 mse loss: 44.556252, \n",
      "              PDE Loss: 1.300574, BC Loss: 43.255676, \n",
      "              nn loss: -37.01666641, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4350/30000 mse loss: 45.502460, \n",
      "              PDE Loss: 2.436664, BC Loss: 43.065796, \n",
      "              nn loss: -27.62155914, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4400/30000 mse loss: 222.642365, \n",
      "              PDE Loss: 12.738402, BC Loss: 209.903961, \n",
      "              nn loss: -5.98053646, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4450/30000 mse loss: 200.732376, \n",
      "              PDE Loss: 5.557166, BC Loss: 195.175217, \n",
      "              nn loss: 2.94427872, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4500/30000 mse loss: 149.950134, \n",
      "              PDE Loss: 9.214622, BC Loss: 140.735519, \n",
      "              nn loss: -43.75538635, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4550/30000 mse loss: 252.582001, \n",
      "              PDE Loss: 20.988716, BC Loss: 231.593292, \n",
      "              nn loss: 385.21850586, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4600/30000 mse loss: 115.973907, \n",
      "              PDE Loss: 1.686355, BC Loss: 114.287552, \n",
      "              nn loss: 6.02444458, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4650/30000 mse loss: 53.097218, \n",
      "              PDE Loss: 1.797261, BC Loss: 51.299957, \n",
      "              nn loss: 3.79000616, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4700/30000 mse loss: 93.241272, \n",
      "              PDE Loss: 4.601048, BC Loss: 88.640221, \n",
      "              nn loss: 11.28422928, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4750/30000 mse loss: 149.878006, \n",
      "              PDE Loss: 12.424188, BC Loss: 137.453812, \n",
      "              nn loss: 0.19692063, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4800/30000 mse loss: 84.264381, \n",
      "              PDE Loss: 3.633858, BC Loss: 80.630524, \n",
      "              nn loss: -30.31126213, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4850/30000 mse loss: 69.605553, \n",
      "              PDE Loss: 0.382229, BC Loss: 69.223320, \n",
      "              nn loss: 6.83732748, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4900/30000 mse loss: 23.961885, \n",
      "              PDE Loss: 4.004816, BC Loss: 19.957069, \n",
      "              nn loss: -11.06624031, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "4950/30000 mse loss: 10.149384, \n",
      "              PDE Loss: 0.282257, BC Loss: 9.867126, \n",
      "              nn loss: -9.29671288, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5000/30000 mse loss: 4.318560, \n",
      "              PDE Loss: 0.030988, BC Loss: 4.287572, \n",
      "              nn loss: -11.59373379, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5050/30000 mse loss: 0.824665, \n",
      "              PDE Loss: 0.155961, BC Loss: 0.668705, \n",
      "              nn loss: -9.93622017, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5100/30000 mse loss: 1.265768, \n",
      "              PDE Loss: 0.242204, BC Loss: 1.023564, \n",
      "              nn loss: -11.88494110, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5150/30000 mse loss: 11.237638, \n",
      "              PDE Loss: 0.412536, BC Loss: 10.825103, \n",
      "              nn loss: -5.07984209, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5200/30000 mse loss: 3.129216, \n",
      "              PDE Loss: 0.262135, BC Loss: 2.867080, \n",
      "              nn loss: -14.87384224, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5250/30000 mse loss: 2.685170, \n",
      "              PDE Loss: 0.261012, BC Loss: 2.424158, \n",
      "              nn loss: -17.28156471, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5300/30000 mse loss: 1.549863, \n",
      "              PDE Loss: 0.160615, BC Loss: 1.389249, \n",
      "              nn loss: -20.80904198, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5350/30000 mse loss: 1.647595, \n",
      "              PDE Loss: 0.208300, BC Loss: 1.439296, \n",
      "              nn loss: -24.90485573, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5400/30000 mse loss: 0.461949, \n",
      "              PDE Loss: 0.105235, BC Loss: 0.356714, \n",
      "              nn loss: -27.65488434, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5450/30000 mse loss: 0.458038, \n",
      "              PDE Loss: 0.100161, BC Loss: 0.357877, \n",
      "              nn loss: -32.89315796, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5500/30000 mse loss: 0.635766, \n",
      "              PDE Loss: 0.108255, BC Loss: 0.527511, \n",
      "              nn loss: -35.59470367, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5550/30000 mse loss: 0.872013, \n",
      "              PDE Loss: 0.199659, BC Loss: 0.672354, \n",
      "              nn loss: -30.56868172, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5600/30000 mse loss: 0.806577, \n",
      "              PDE Loss: 0.142295, BC Loss: 0.664282, \n",
      "              nn loss: -22.62108040, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5650/30000 mse loss: 1.043301, \n",
      "              PDE Loss: 0.112391, BC Loss: 0.930910, \n",
      "              nn loss: -65.36287689, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5700/30000 mse loss: 0.831502, \n",
      "              PDE Loss: 0.116381, BC Loss: 0.715121, \n",
      "              nn loss: -64.61590576, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5750/30000 mse loss: 0.581216, \n",
      "              PDE Loss: 0.175796, BC Loss: 0.405420, \n",
      "              nn loss: -81.77671051, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5800/30000 mse loss: 0.498996, \n",
      "              PDE Loss: 0.110671, BC Loss: 0.388325, \n",
      "              nn loss: -97.31285858, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5850/30000 mse loss: 0.395621, \n",
      "              PDE Loss: 0.089433, BC Loss: 0.306188, \n",
      "              nn loss: -119.90560913, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5900/30000 mse loss: 0.457625, \n",
      "              PDE Loss: 0.073087, BC Loss: 0.384538, \n",
      "              nn loss: -142.02815247, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "5950/30000 mse loss: 0.870681, \n",
      "              PDE Loss: 0.137684, BC Loss: 0.732997, \n",
      "              nn loss: -166.22058105, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6000/30000 mse loss: 0.859963, \n",
      "              PDE Loss: 0.104310, BC Loss: 0.755653, \n",
      "              nn loss: -94.80282593, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6050/30000 mse loss: 0.645073, \n",
      "              PDE Loss: 0.086422, BC Loss: 0.558651, \n",
      "              nn loss: -114.90523529, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6100/30000 mse loss: 0.305876, \n",
      "              PDE Loss: 0.073398, BC Loss: 0.232478, \n",
      "              nn loss: -176.91220093, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6150/30000 mse loss: 0.604591, \n",
      "              PDE Loss: 0.074941, BC Loss: 0.529650, \n",
      "              nn loss: -207.26445007, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6200/30000 mse loss: 0.510623, \n",
      "              PDE Loss: 0.072915, BC Loss: 0.437708, \n",
      "              nn loss: -253.56823730, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6250/30000 mse loss: 0.358430, \n",
      "              PDE Loss: 0.064380, BC Loss: 0.294050, \n",
      "              nn loss: -322.88363647, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6300/30000 mse loss: 0.432796, \n",
      "              PDE Loss: 0.069508, BC Loss: 0.363289, \n",
      "              nn loss: -400.21295166, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6350/30000 mse loss: 0.887720, \n",
      "              PDE Loss: 0.106795, BC Loss: 0.780925, \n",
      "              nn loss: -548.87841797, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6400/30000 mse loss: 0.508747, \n",
      "              PDE Loss: 0.069982, BC Loss: 0.438765, \n",
      "              nn loss: -716.29925537, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6450/30000 mse loss: 0.403213, \n",
      "              PDE Loss: 0.064534, BC Loss: 0.338678, \n",
      "              nn loss: -966.36950684, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6500/30000 mse loss: 0.584003, \n",
      "              PDE Loss: 0.087425, BC Loss: 0.496578, \n",
      "              nn loss: -1361.03918457, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6550/30000 mse loss: 0.607065, \n",
      "              PDE Loss: 0.079710, BC Loss: 0.527355, \n",
      "              nn loss: -1924.09655762, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6600/30000 mse loss: 0.301379, \n",
      "              PDE Loss: 0.068349, BC Loss: 0.233029, \n",
      "              nn loss: -2498.42871094, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6650/30000 mse loss: 0.244179, \n",
      "              PDE Loss: 0.065258, BC Loss: 0.178922, \n",
      "              nn loss: -3292.90478516, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6700/30000 mse loss: 0.232487, \n",
      "              PDE Loss: 0.063150, BC Loss: 0.169337, \n",
      "              nn loss: -4165.97607422, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6750/30000 mse loss: 0.256642, \n",
      "              PDE Loss: 0.071438, BC Loss: 0.185204, \n",
      "              nn loss: -5517.34375000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6800/30000 mse loss: 0.277539, \n",
      "              PDE Loss: 0.079609, BC Loss: 0.197930, \n",
      "              nn loss: -6873.80810547, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6850/30000 mse loss: 0.317019, \n",
      "              PDE Loss: 0.087877, BC Loss: 0.229143, \n",
      "              nn loss: -8433.36035156, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6900/30000 mse loss: 0.375778, \n",
      "              PDE Loss: 0.091282, BC Loss: 0.284496, \n",
      "              nn loss: -10622.74609375, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "6950/30000 mse loss: 0.443150, \n",
      "              PDE Loss: 0.091109, BC Loss: 0.352041, \n",
      "              nn loss: -12732.67675781, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7000/30000 mse loss: 0.560045, \n",
      "              PDE Loss: 0.094659, BC Loss: 0.465386, \n",
      "              nn loss: -15228.49218750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7050/30000 mse loss: 0.680254, \n",
      "              PDE Loss: 0.091262, BC Loss: 0.588992, \n",
      "              nn loss: -17894.88085938, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7100/30000 mse loss: 0.865417, \n",
      "              PDE Loss: 0.091650, BC Loss: 0.773766, \n",
      "              nn loss: -21292.86132812, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7150/30000 mse loss: 1.006016, \n",
      "              PDE Loss: 0.095142, BC Loss: 0.910874, \n",
      "              nn loss: -25081.93750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7200/30000 mse loss: 1.071354, \n",
      "              PDE Loss: 0.086037, BC Loss: 0.985317, \n",
      "              nn loss: -30135.30468750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7250/30000 mse loss: 1.092087, \n",
      "              PDE Loss: 0.091005, BC Loss: 1.001081, \n",
      "              nn loss: -36604.08203125, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7300/30000 mse loss: 1.078286, \n",
      "              PDE Loss: 0.086751, BC Loss: 0.991535, \n",
      "              nn loss: -44673.17578125, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7350/30000 mse loss: 1.068047, \n",
      "              PDE Loss: 0.094682, BC Loss: 0.973365, \n",
      "              nn loss: -53654.19140625, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7400/30000 mse loss: 1.185837, \n",
      "              PDE Loss: 0.103596, BC Loss: 1.082241, \n",
      "              nn loss: -60865.46484375, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7450/30000 mse loss: 1.434806, \n",
      "              PDE Loss: 0.123151, BC Loss: 1.311655, \n",
      "              nn loss: -69965.21093750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7500/30000 mse loss: 1.498112, \n",
      "              PDE Loss: 0.124918, BC Loss: 1.373194, \n",
      "              nn loss: -81078.42968750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7550/30000 mse loss: 1.429684, \n",
      "              PDE Loss: 0.125825, BC Loss: 1.303859, \n",
      "              nn loss: -95525.64843750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7600/30000 mse loss: 1.593907, \n",
      "              PDE Loss: 0.128678, BC Loss: 1.465229, \n",
      "              nn loss: -106090.89843750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7650/30000 mse loss: 1.597281, \n",
      "              PDE Loss: 0.145893, BC Loss: 1.451388, \n",
      "              nn loss: -114431.82031250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7700/30000 mse loss: 1.702384, \n",
      "              PDE Loss: 0.153435, BC Loss: 1.548949, \n",
      "              nn loss: -128646.67187500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7750/30000 mse loss: 1.730456, \n",
      "              PDE Loss: 0.142296, BC Loss: 1.588161, \n",
      "              nn loss: -145538.59375000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7800/30000 mse loss: 1.956100, \n",
      "              PDE Loss: 0.170086, BC Loss: 1.786014, \n",
      "              nn loss: -161069.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7850/30000 mse loss: 1.883735, \n",
      "              PDE Loss: 0.160657, BC Loss: 1.723078, \n",
      "              nn loss: -178281.73437500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7900/30000 mse loss: 2.207839, \n",
      "              PDE Loss: 0.180666, BC Loss: 2.027172, \n",
      "              nn loss: -202349.23437500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "7950/30000 mse loss: 2.069511, \n",
      "              PDE Loss: 0.226339, BC Loss: 1.843172, \n",
      "              nn loss: -220976.15625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8000/30000 mse loss: 2.197244, \n",
      "              PDE Loss: 0.204128, BC Loss: 1.993116, \n",
      "              nn loss: -253566.78125000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8050/30000 mse loss: 2.444111, \n",
      "              PDE Loss: 0.210766, BC Loss: 2.233345, \n",
      "              nn loss: -275482.12500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8100/30000 mse loss: 2.884169, \n",
      "              PDE Loss: 0.152146, BC Loss: 2.732023, \n",
      "              nn loss: -302967.40625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8150/30000 mse loss: 2.534540, \n",
      "              PDE Loss: 0.215751, BC Loss: 2.318788, \n",
      "              nn loss: -351947.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8200/30000 mse loss: 17.830879, \n",
      "              PDE Loss: 2.788259, BC Loss: 15.042622, \n",
      "              nn loss: -356729.28125000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8250/30000 mse loss: 34.492588, \n",
      "              PDE Loss: 7.685622, BC Loss: 26.806965, \n",
      "              nn loss: -231985.89062500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8300/30000 mse loss: 9.353922, \n",
      "              PDE Loss: 4.302690, BC Loss: 5.051233, \n",
      "              nn loss: -128403.30468750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8350/30000 mse loss: 7.994763, \n",
      "              PDE Loss: 3.698530, BC Loss: 4.296233, \n",
      "              nn loss: -473657.18750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8400/30000 mse loss: 9.147913, \n",
      "              PDE Loss: 3.510754, BC Loss: 5.637159, \n",
      "              nn loss: -444247.90625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8450/30000 mse loss: 20.080359, \n",
      "              PDE Loss: 1.573048, BC Loss: 18.507311, \n",
      "              nn loss: -415126.93750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8500/30000 mse loss: 24.846500, \n",
      "              PDE Loss: 1.152425, BC Loss: 23.694075, \n",
      "              nn loss: -282444.62500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8550/30000 mse loss: 35.448402, \n",
      "              PDE Loss: 1.870110, BC Loss: 33.578293, \n",
      "              nn loss: -225673.15625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8600/30000 mse loss: 184.287384, \n",
      "              PDE Loss: 12.112664, BC Loss: 172.174713, \n",
      "              nn loss: 1016924.43750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8650/30000 mse loss: 886.291443, \n",
      "              PDE Loss: 109.855423, BC Loss: 776.436035, \n",
      "              nn loss: 706.32812500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8700/30000 mse loss: 287.825500, \n",
      "              PDE Loss: 47.495281, BC Loss: 240.330231, \n",
      "              nn loss: -1537713.75000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8750/30000 mse loss: 94299.851562, \n",
      "              PDE Loss: 12.677965, BC Loss: 94287.171875, \n",
      "              nn loss: -1352388.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8800/30000 mse loss: 499.397003, \n",
      "              PDE Loss: 12.014781, BC Loss: 487.382233, \n",
      "              nn loss: 608621.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8850/30000 mse loss: 603.955261, \n",
      "              PDE Loss: 67.035324, BC Loss: 536.919922, \n",
      "              nn loss: 830358.93750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8900/30000 mse loss: 380.571259, \n",
      "              PDE Loss: 215.314743, BC Loss: 165.256516, \n",
      "              nn loss: 475405.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "8950/30000 mse loss: 100.175598, \n",
      "              PDE Loss: 48.604588, BC Loss: 51.571014, \n",
      "              nn loss: -367219.46875000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9000/30000 mse loss: 130.376160, \n",
      "              PDE Loss: 9.646392, BC Loss: 120.729774, \n",
      "              nn loss: 177317.40625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9050/30000 mse loss: 727.386047, \n",
      "              PDE Loss: 104.275551, BC Loss: 623.110474, \n",
      "              nn loss: -290541.93750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9100/30000 mse loss: 366.699982, \n",
      "              PDE Loss: 20.811939, BC Loss: 345.888031, \n",
      "              nn loss: 330050.90625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9150/30000 mse loss: 450.962769, \n",
      "              PDE Loss: 7.539397, BC Loss: 443.423370, \n",
      "              nn loss: -232372.09375000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9200/30000 mse loss: 560.175293, \n",
      "              PDE Loss: 12.200017, BC Loss: 547.975281, \n",
      "              nn loss: -191731.20312500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9250/30000 mse loss: 582.177795, \n",
      "              PDE Loss: 11.267681, BC Loss: 570.910095, \n",
      "              nn loss: -214728.03125000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9300/30000 mse loss: 487.520264, \n",
      "              PDE Loss: 6.647504, BC Loss: 480.872772, \n",
      "              nn loss: -282822.46875000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9350/30000 mse loss: 507.330231, \n",
      "              PDE Loss: 12.251741, BC Loss: 495.078491, \n",
      "              nn loss: -3204005.75000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9400/30000 mse loss: 412.964081, \n",
      "              PDE Loss: 13.989159, BC Loss: 398.974915, \n",
      "              nn loss: -528331.06250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9450/30000 mse loss: 658.235840, \n",
      "              PDE Loss: 133.570297, BC Loss: 524.665527, \n",
      "              nn loss: -620241.75000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9500/30000 mse loss: 1396.307617, \n",
      "              PDE Loss: 183.188614, BC Loss: 1213.119019, \n",
      "              nn loss: -140831.81250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9550/30000 mse loss: 818.974243, \n",
      "              PDE Loss: 18.238024, BC Loss: 800.736206, \n",
      "              nn loss: 427724.65625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9600/30000 mse loss: 15649.982422, \n",
      "              PDE Loss: 38.185913, BC Loss: 15611.796875, \n",
      "              nn loss: -1450482.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9650/30000 mse loss: 8085.169434, \n",
      "              PDE Loss: 28.052256, BC Loss: 8057.117188, \n",
      "              nn loss: 484265.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9700/30000 mse loss: 4506.529785, \n",
      "              PDE Loss: 19.971405, BC Loss: 4486.558594, \n",
      "              nn loss: -1611102.62500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9750/30000 mse loss: 5711.626953, \n",
      "              PDE Loss: 32.893360, BC Loss: 5678.733398, \n",
      "              nn loss: 1388344.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9800/30000 mse loss: 1808.731812, \n",
      "              PDE Loss: 50.758793, BC Loss: 1757.973022, \n",
      "              nn loss: 1890514.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9850/30000 mse loss: 47713.949219, \n",
      "              PDE Loss: 57.890316, BC Loss: 47656.058594, \n",
      "              nn loss: 799004.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9900/30000 mse loss: 37921.375000, \n",
      "              PDE Loss: 38.079487, BC Loss: 37883.296875, \n",
      "              nn loss: -1529485.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "9950/30000 mse loss: 10217.738281, \n",
      "              PDE Loss: 13.646809, BC Loss: 10204.091797, \n",
      "              nn loss: -542352.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10000/30000 mse loss: 2576.240234, \n",
      "              PDE Loss: 23.934381, BC Loss: 2552.305908, \n",
      "              nn loss: -768589.12500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10050/30000 mse loss: 1861.198975, \n",
      "              PDE Loss: 136.542755, BC Loss: 1724.656250, \n",
      "              nn loss: 1484128.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10100/30000 mse loss: 684.910095, \n",
      "              PDE Loss: 12.666271, BC Loss: 672.243835, \n",
      "              nn loss: -55740.42968750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10150/30000 mse loss: 1860.824707, \n",
      "              PDE Loss: 9.161289, BC Loss: 1851.663452, \n",
      "              nn loss: -305141.71875000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10200/30000 mse loss: 451.406403, \n",
      "              PDE Loss: 30.860819, BC Loss: 420.545593, \n",
      "              nn loss: -159443.40625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10250/30000 mse loss: 434.101837, \n",
      "              PDE Loss: 10.952559, BC Loss: 423.149292, \n",
      "              nn loss: 184318.54687500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10300/30000 mse loss: 516.119141, \n",
      "              PDE Loss: 17.044775, BC Loss: 499.074371, \n",
      "              nn loss: 79943.89062500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10350/30000 mse loss: 969.204468, \n",
      "              PDE Loss: 37.677601, BC Loss: 931.526855, \n",
      "              nn loss: -2046288.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10400/30000 mse loss: 279.810577, \n",
      "              PDE Loss: 78.015617, BC Loss: 201.794952, \n",
      "              nn loss: 436607.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10450/30000 mse loss: 2894.477295, \n",
      "              PDE Loss: 148.448898, BC Loss: 2746.028320, \n",
      "              nn loss: 226877.78125000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10500/30000 mse loss: 1364.172852, \n",
      "              PDE Loss: 44.655827, BC Loss: 1319.516968, \n",
      "              nn loss: 45534.71484375, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10550/30000 mse loss: 577.799194, \n",
      "              PDE Loss: 65.567383, BC Loss: 512.231812, \n",
      "              nn loss: 127454.22656250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10600/30000 mse loss: 1383.159424, \n",
      "              PDE Loss: 92.611244, BC Loss: 1290.548218, \n",
      "              nn loss: 298764.03125000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10650/30000 mse loss: 303.891815, \n",
      "              PDE Loss: 58.446980, BC Loss: 245.444824, \n",
      "              nn loss: 9558.71484375, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10700/30000 mse loss: 571.432373, \n",
      "              PDE Loss: 55.672211, BC Loss: 515.760193, \n",
      "              nn loss: -68790.44531250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10750/30000 mse loss: 1138.025024, \n",
      "              PDE Loss: 51.703293, BC Loss: 1086.321777, \n",
      "              nn loss: 94797.46875000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10800/30000 mse loss: 365.755615, \n",
      "              PDE Loss: 60.744648, BC Loss: 305.010956, \n",
      "              nn loss: -259938.81250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10850/30000 mse loss: 380.667542, \n",
      "              PDE Loss: 65.991646, BC Loss: 314.675903, \n",
      "              nn loss: 122293.32031250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10900/30000 mse loss: 709.980896, \n",
      "              PDE Loss: 123.192924, BC Loss: 586.787964, \n",
      "              nn loss: 239997.23437500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "10950/30000 mse loss: 10373.686523, \n",
      "              PDE Loss: 152.661743, BC Loss: 10221.024414, \n",
      "              nn loss: 334766.62500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11000/30000 mse loss: 1555.301025, \n",
      "              PDE Loss: 334.216370, BC Loss: 1221.084717, \n",
      "              nn loss: 617216.31250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11050/30000 mse loss: 2967.908691, \n",
      "              PDE Loss: 755.464478, BC Loss: 2212.444336, \n",
      "              nn loss: -81719.40625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11100/30000 mse loss: 2968.179688, \n",
      "              PDE Loss: 1948.060791, BC Loss: 1020.118896, \n",
      "              nn loss: 208906.56250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11150/30000 mse loss: 5648.492676, \n",
      "              PDE Loss: 4238.442871, BC Loss: 1410.049927, \n",
      "              nn loss: 834134.18750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11200/30000 mse loss: 12110.525391, \n",
      "              PDE Loss: 9274.294922, BC Loss: 2836.230713, \n",
      "              nn loss: -985976.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11250/30000 mse loss: 20262.921875, \n",
      "              PDE Loss: 17860.185547, BC Loss: 2402.735352, \n",
      "              nn loss: 291119.31250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11300/30000 mse loss: 1432.405640, \n",
      "              PDE Loss: 975.700562, BC Loss: 456.705078, \n",
      "              nn loss: -2834316.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11350/30000 mse loss: 6988.033203, \n",
      "              PDE Loss: 1745.951172, BC Loss: 5242.082031, \n",
      "              nn loss: -9238984.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11400/30000 mse loss: 10235.625977, \n",
      "              PDE Loss: 2090.228271, BC Loss: 8145.397949, \n",
      "              nn loss: 452627.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11450/30000 mse loss: 9067.760742, \n",
      "              PDE Loss: 1897.356812, BC Loss: 7170.403809, \n",
      "              nn loss: 1941160.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11500/30000 mse loss: 6883.610352, \n",
      "              PDE Loss: 2066.079834, BC Loss: 4817.530762, \n",
      "              nn loss: 1437015.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11550/30000 mse loss: 2929.246582, \n",
      "              PDE Loss: 1686.305176, BC Loss: 1242.941284, \n",
      "              nn loss: 1220105.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11600/30000 mse loss: 1127.479126, \n",
      "              PDE Loss: 824.504761, BC Loss: 302.974365, \n",
      "              nn loss: 200766.68750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11650/30000 mse loss: 3399.017090, \n",
      "              PDE Loss: 2151.248047, BC Loss: 1247.769043, \n",
      "              nn loss: 101670.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11700/30000 mse loss: 29709.501953, \n",
      "              PDE Loss: 25876.205078, BC Loss: 3833.296387, \n",
      "              nn loss: 1100852.12500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11750/30000 mse loss: 3594.672119, \n",
      "              PDE Loss: 3063.086426, BC Loss: 531.585693, \n",
      "              nn loss: 1436861.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11800/30000 mse loss: 3388.551758, \n",
      "              PDE Loss: 2868.927002, BC Loss: 519.624756, \n",
      "              nn loss: -1072695.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11850/30000 mse loss: 32593.386719, \n",
      "              PDE Loss: 24816.265625, BC Loss: 7777.121094, \n",
      "              nn loss: 649530.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11900/30000 mse loss: 131689.203125, \n",
      "              PDE Loss: 103150.132812, BC Loss: 28539.074219, \n",
      "              nn loss: -268233.56250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "11950/30000 mse loss: 41294.484375, \n",
      "              PDE Loss: 25784.173828, BC Loss: 15510.309570, \n",
      "              nn loss: -3643960.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12000/30000 mse loss: 15626.661133, \n",
      "              PDE Loss: 8746.496094, BC Loss: 6880.165039, \n",
      "              nn loss: 3241187.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12050/30000 mse loss: 3765.892578, \n",
      "              PDE Loss: 2433.713623, BC Loss: 1332.178955, \n",
      "              nn loss: 46456.42968750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12100/30000 mse loss: 6331.444336, \n",
      "              PDE Loss: 3615.665527, BC Loss: 2715.778564, \n",
      "              nn loss: 520963.65625000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12150/30000 mse loss: 423154.718750, \n",
      "              PDE Loss: 2383.494385, BC Loss: 420771.218750, \n",
      "              nn loss: 1449475.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12200/30000 mse loss: 8799.435547, \n",
      "              PDE Loss: 1959.440308, BC Loss: 6839.995117, \n",
      "              nn loss: 173115.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12250/30000 mse loss: 7213.592285, \n",
      "              PDE Loss: 1479.727539, BC Loss: 5733.864746, \n",
      "              nn loss: 104575.22656250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12300/30000 mse loss: 4970.534180, \n",
      "              PDE Loss: 1493.193726, BC Loss: 3477.340576, \n",
      "              nn loss: 131904.26562500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12350/30000 mse loss: 1937.618164, \n",
      "              PDE Loss: 804.522156, BC Loss: 1133.095947, \n",
      "              nn loss: 52963.44140625, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12400/30000 mse loss: 2050.384033, \n",
      "              PDE Loss: 1315.985718, BC Loss: 734.398376, \n",
      "              nn loss: 230443.82812500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12450/30000 mse loss: 6179.653809, \n",
      "              PDE Loss: 4723.221191, BC Loss: 1456.432495, \n",
      "              nn loss: -394482.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12500/30000 mse loss: 1705.149170, \n",
      "              PDE Loss: 1392.518188, BC Loss: 312.630920, \n",
      "              nn loss: 241379.43750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12550/30000 mse loss: 248.624908, \n",
      "              PDE Loss: 40.715919, BC Loss: 207.908981, \n",
      "              nn loss: 59478.20703125, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12600/30000 mse loss: 296.987610, \n",
      "              PDE Loss: 55.730442, BC Loss: 241.257172, \n",
      "              nn loss: 40422.74609375, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12650/30000 mse loss: 382.526031, \n",
      "              PDE Loss: 79.197945, BC Loss: 303.328094, \n",
      "              nn loss: -1440.09594727, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12700/30000 mse loss: 463.808563, \n",
      "              PDE Loss: 64.075684, BC Loss: 399.732880, \n",
      "              nn loss: -17098.56054688, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12750/30000 mse loss: 467.637848, \n",
      "              PDE Loss: 54.103024, BC Loss: 413.534821, \n",
      "              nn loss: 13441.43066406, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12800/30000 mse loss: 560.936890, \n",
      "              PDE Loss: 65.758423, BC Loss: 495.178467, \n",
      "              nn loss: 9299.62988281, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12850/30000 mse loss: 405.522034, \n",
      "              PDE Loss: 52.639210, BC Loss: 352.882812, \n",
      "              nn loss: -668.37823486, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12900/30000 mse loss: 228.937103, \n",
      "              PDE Loss: 43.481815, BC Loss: 185.455292, \n",
      "              nn loss: -36995.75390625, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "12950/30000 mse loss: 40694.898438, \n",
      "              PDE Loss: 74.290329, BC Loss: 40620.609375, \n",
      "              nn loss: 8791.98437500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13000/30000 mse loss: 2468.407227, \n",
      "              PDE Loss: 506.763245, BC Loss: 1961.644043, \n",
      "              nn loss: -82657.67187500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13050/30000 mse loss: 336.349670, \n",
      "              PDE Loss: 180.852676, BC Loss: 155.496979, \n",
      "              nn loss: 106114.92187500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13100/30000 mse loss: 5108.950684, \n",
      "              PDE Loss: 3878.477051, BC Loss: 1230.473511, \n",
      "              nn loss: -211299.56250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13150/30000 mse loss: 14613.581055, \n",
      "              PDE Loss: 4252.720703, BC Loss: 10360.860352, \n",
      "              nn loss: -790054.75000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13200/30000 mse loss: 554587.687500, \n",
      "              PDE Loss: 22228.937500, BC Loss: 532358.750000, \n",
      "              nn loss: -3520429.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13250/30000 mse loss: 104744.164062, \n",
      "              PDE Loss: 5666.686035, BC Loss: 99077.476562, \n",
      "              nn loss: -4862854.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13300/30000 mse loss: 30295.623047, \n",
      "              PDE Loss: 4583.806152, BC Loss: 25711.816406, \n",
      "              nn loss: 291030.03125000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13350/30000 mse loss: 8034.993652, \n",
      "              PDE Loss: 2721.312500, BC Loss: 5313.681152, \n",
      "              nn loss: -76265.62500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13400/30000 mse loss: 1784.269897, \n",
      "              PDE Loss: 1547.518921, BC Loss: 236.750946, \n",
      "              nn loss: -261840.57812500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13450/30000 mse loss: 3063.168945, \n",
      "              PDE Loss: 1446.752808, BC Loss: 1616.416260, \n",
      "              nn loss: 217157.96875000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13500/30000 mse loss: 4868.098145, \n",
      "              PDE Loss: 1256.428223, BC Loss: 3611.669922, \n",
      "              nn loss: 72749.07031250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13550/30000 mse loss: 2229.099121, \n",
      "              PDE Loss: 1156.586060, BC Loss: 1072.512939, \n",
      "              nn loss: -42754.46875000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13600/30000 mse loss: 851.533569, \n",
      "              PDE Loss: 672.231812, BC Loss: 179.301788, \n",
      "              nn loss: -76065.77343750, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13650/30000 mse loss: 2433.293701, \n",
      "              PDE Loss: 715.819031, BC Loss: 1717.474731, \n",
      "              nn loss: 81374.60937500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13700/30000 mse loss: 3162.123535, \n",
      "              PDE Loss: 705.032288, BC Loss: 2457.091309, \n",
      "              nn loss: 68194.82031250, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13750/30000 mse loss: 6214.916016, \n",
      "              PDE Loss: 1593.497803, BC Loss: 4621.417969, \n",
      "              nn loss: 188019.20312500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13800/30000 mse loss: 9695.167969, \n",
      "              PDE Loss: 4665.336426, BC Loss: 5029.832031, \n",
      "              nn loss: 667491.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13850/30000 mse loss: 16345.823242, \n",
      "              PDE Loss: 6473.407227, BC Loss: 9872.416016, \n",
      "              nn loss: 1617666.12500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13900/30000 mse loss: 61422.871094, \n",
      "              PDE Loss: 10594.473633, BC Loss: 50828.398438, \n",
      "              nn loss: -99353.48437500, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "13950/30000 mse loss: 90543.820312, \n",
      "              PDE Loss: 45781.957031, BC Loss: 44761.863281, \n",
      "              nn loss: 364948.81250000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14000/30000 mse loss: 615710.375000, \n",
      "              PDE Loss: 316225.437500, BC Loss: 299484.937500, \n",
      "              nn loss: 4448628.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14050/30000 mse loss: 355108.781250, \n",
      "              PDE Loss: 226817.781250, BC Loss: 128291.000000, \n",
      "              nn loss: -235661.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14100/30000 mse loss: 222901.656250, \n",
      "              PDE Loss: 74906.164062, BC Loss: 147995.484375, \n",
      "              nn loss: 1597934.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14150/30000 mse loss: 133955.984375, \n",
      "              PDE Loss: 27554.558594, BC Loss: 106401.429688, \n",
      "              nn loss: 1631320.50000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14200/30000 mse loss: 141197.406250, \n",
      "              PDE Loss: 73514.585938, BC Loss: 67682.820312, \n",
      "              nn loss: -1750831.37500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14250/30000 mse loss: 146779.421875, \n",
      "              PDE Loss: 71731.226562, BC Loss: 75048.195312, \n",
      "              nn loss: -697007.18750000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14300/30000 mse loss: 143624.968750, \n",
      "              PDE Loss: 64671.179688, BC Loss: 78953.796875, \n",
      "              nn loss: -2830926.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14350/30000 mse loss: 172461.218750, \n",
      "              PDE Loss: 59824.972656, BC Loss: 112636.250000, \n",
      "              nn loss: 1430754.12500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14400/30000 mse loss: 592778.375000, \n",
      "              PDE Loss: 153355.843750, BC Loss: 439422.562500, \n",
      "              nn loss: -1083307.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14450/30000 mse loss: 275248.937500, \n",
      "              PDE Loss: 46271.718750, BC Loss: 228977.234375, \n",
      "              nn loss: -2054196.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14500/30000 mse loss: 263430.312500, \n",
      "              PDE Loss: 97170.515625, BC Loss: 166259.796875, \n",
      "              nn loss: -6720111.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14550/30000 mse loss: 62973.949219, \n",
      "              PDE Loss: 11035.534180, BC Loss: 51938.414062, \n",
      "              nn loss: 1988209.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14600/30000 mse loss: 7545.559570, \n",
      "              PDE Loss: 3328.304199, BC Loss: 4217.255371, \n",
      "              nn loss: -1013880.62500000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14650/30000 mse loss: 188064.250000, \n",
      "              PDE Loss: 74154.835938, BC Loss: 113909.414062, \n",
      "              nn loss: 9395542.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14700/30000 mse loss: 197901.312500, \n",
      "              PDE Loss: 94142.468750, BC Loss: 103758.843750, \n",
      "              nn loss: -8331806.00000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14750/30000 mse loss: 28319.394531, \n",
      "              PDE Loss: 24408.876953, BC Loss: 3910.517822, \n",
      "              nn loss: -2579859.75000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14800/30000 mse loss: 79572.390625, \n",
      "              PDE Loss: 60044.625000, BC Loss: 19527.763672, \n",
      "              nn loss: 1253823.25000000, \n",
      "              minloss: 0.002715\n",
      "              \n",
      "14850/30000 mse loss: 69110.523438, \n",
      "              PDE Loss: 28333.289062, BC Loss: 40777.234375, \n",
      "              nn loss: -2006680.87500000, \n",
      "              minloss: 0.002715\n",
      "              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 91\u001b[0m\n\u001b[0;32m     86\u001b[0m pinn_loss \u001b[39m=\u001b[39m pde_loss \u001b[39m+\u001b[39m bc_loss\n\u001b[0;32m     90\u001b[0m \u001b[39m# Backpropagation and Update\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep(combined_loss, \u001b[39m-\u001b[39;49mcombined_loss)\n\u001b[0;32m     94\u001b[0m \u001b[39m# print information\u001b[39;00m\n\u001b[0;32m     95\u001b[0m loss_hist\u001b[39m.\u001b[39mappend(pinn_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\gmres_acgd.py:165\u001b[0m, in \u001b[0;36mGACGD.step\u001b[1;34m(self, loss_x, loss_y, trigger)\u001b[0m\n\u001b[0;32m    157\u001b[0m prev_x0 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    158\u001b[0m Avp \u001b[39m=\u001b[39m partial(MvProd,\n\u001b[0;32m    159\u001b[0m               grad_fy\u001b[39m=\u001b[39mgrad_fy_vec, grad_gx\u001b[39m=\u001b[39mgrad_gx_vec,\n\u001b[0;32m    160\u001b[0m               x_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_params, y_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m               x_reducer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_reducer, y_reducer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_reducer,\n\u001b[0;32m    164\u001b[0m               rebuild\u001b[39m=\u001b[39mshould_rebuild)\n\u001b[1;32m--> 165\u001b[0m soln, (num_iter, err_history) \u001b[39m=\u001b[39m GMRES(Avp\u001b[39m=\u001b[39;49mAvp, b\u001b[39m=\u001b[39;49mRHS, x0\u001b[39m=\u001b[39;49mprev_x0,\n\u001b[0;32m    166\u001b[0m                                       max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    167\u001b[0m                                       tol\u001b[39m=\u001b[39;49mtol, atol\u001b[39m=\u001b[39;49matol,\n\u001b[0;32m    168\u001b[0m                                       track\u001b[39m=\u001b[39;49mtrack_flag)\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[\u001b[39m'\u001b[39m\u001b[39mx0\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m soln\n\u001b[0;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mupdate(\n\u001b[0;32m    172\u001b[0m     {\n\u001b[0;32m    173\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msq_exp_avg_x\u001b[39m\u001b[39m'\u001b[39m: sq_avg_x,\n\u001b[0;32m    174\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msq_exp_avg_y\u001b[39m\u001b[39m'\u001b[39m: sq_avg_y\n\u001b[0;32m    175\u001b[0m     }\n\u001b[0;32m    176\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\gmres_torch.py:107\u001b[0m, in \u001b[0;36mGMRES\u001b[1;34m(Avp, b, x0, max_iter, tol, atol, track)\u001b[0m\n\u001b[0;32m    104\u001b[0m ss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(max_iter, device\u001b[39m=\u001b[39mb\u001b[39m.\u001b[39mdevice)  \u001b[39m# sine values at each step\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[1;32m--> 107\u001b[0m     p \u001b[39m=\u001b[39m Avp(V[j])\n\u001b[0;32m    108\u001b[0m     new_v \u001b[39m=\u001b[39m arnoldi(p, V, H, j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)  \u001b[39m# Arnoldi iteration to get the j+1 th ba\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[39m# sis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\gmres_acgd.py:48\u001b[0m, in \u001b[0;36mMvProd\u001b[1;34m(vec, grad_fy, grad_gx, x_params, y_params, lr_x, lr_y, trigger, x_reducer, y_reducer, rebuild)\u001b[0m\n\u001b[0;32m     43\u001b[0m h1 \u001b[39m=\u001b[39m Hvp_vec(grad_fy, x_params, v2,\n\u001b[0;32m     44\u001b[0m              retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, trigger\u001b[39m=\u001b[39mtrigger,\n\u001b[0;32m     45\u001b[0m              reducer\u001b[39m=\u001b[39mx_reducer,\n\u001b[0;32m     46\u001b[0m              rebuild\u001b[39m=\u001b[39mrebuild)\n\u001b[0;32m     47\u001b[0m p1 \u001b[39m=\u001b[39m v1 \u001b[39m+\u001b[39m lr_x \u001b[39m*\u001b[39m h1\n\u001b[1;32m---> 48\u001b[0m h2 \u001b[39m=\u001b[39m Hvp_vec(grad_gx, y_params, v1,\n\u001b[0;32m     49\u001b[0m              retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, trigger\u001b[39m=\u001b[39;49mtrigger,\n\u001b[0;32m     50\u001b[0m              reducer\u001b[39m=\u001b[39;49my_reducer,\n\u001b[0;32m     51\u001b[0m              rebuild\u001b[39m=\u001b[39;49mrebuild)\n\u001b[0;32m     52\u001b[0m p2 \u001b[39m=\u001b[39m v2 \u001b[39m+\u001b[39m lr_y \u001b[39m*\u001b[39m h2\n\u001b[0;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat([p1, p2])\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\CGDs\\cgd_utils.py:109\u001b[0m, in \u001b[0;36mHvp_vec\u001b[1;34m(grad_vec, params, vec, retain_graph, trigger, reducer, rebuild)\u001b[0m\n\u001b[0;32m    107\u001b[0m         reducer\u001b[39m.\u001b[39m_rebuild_buckets()\n\u001b[0;32m    108\u001b[0m     reducer\u001b[39m.\u001b[39mprepare_for_backward([])\n\u001b[1;32m--> 109\u001b[0m autograd\u001b[39m.\u001b[39;49mbackward(grad_vec \u001b[39m+\u001b[39;49m \u001b[39m0.0\u001b[39;49m \u001b[39m*\u001b[39;49m trigger, grad_tensors\u001b[39m=\u001b[39;49mvec,\n\u001b[0;32m    110\u001b[0m                   inputs\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    111\u001b[0m                   retain_graph\u001b[39m=\u001b[39;49mretain_graph)\n\u001b[0;32m    112\u001b[0m hvp \u001b[39m=\u001b[39m vectorize_grad(params)\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39misnan(hvp)\u001b[39m.\u001b[39many():\n",
      "File \u001b[1;32mc:\\Users\\hengr\\miniconda3\\envs\\honor\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loss_hist = []\n",
    "# dis_hist = []\n",
    "for epoch in range(max_iter):\n",
    "    \n",
    "    optimizer.zero_grad() # zeroes the gradient buffers of all parameters\n",
    "    \n",
    "    # normal condition / interior points\n",
    "    n_st_train = np.concatenate([np.random.uniform(*t_range, (samples['pde'], 1)), \n",
    "                      np.random.uniform(*S_range, (samples['pde'], 1))], axis=1)\n",
    "    n_v_train = np.zeros((samples['pde'], 1))\n",
    "    \n",
    "\n",
    "    # final condition (t = T, S is randomized)\n",
    "    f_st_train = np.concatenate([np.ones((samples['fc'], 1)),\n",
    "                    np.random.uniform(*S_range, (samples['fc'], 1))], axis=1)\n",
    "    f_v_train = gs(f_st_train[:, 1]).reshape(-1, 1)\n",
    "    \n",
    "    # lower boundary condition (S = 0, t is randomized)\n",
    "    lb_st = np.concatenate([np.random.uniform(*t_range, (samples['bc'], 1)),\n",
    "                        0 * np.ones((samples['bc'], 1))], axis=1)\n",
    "    lb_v = np.zeros((samples['bc'], 1))\n",
    "    \n",
    "    # upper boundary condition (S = Smax, t is randomized)\n",
    "    ub_st = np.concatenate([np.random.uniform(*t_range, (samples['bc'], 1)), \n",
    "                        S_range[-1] * np.ones((samples['bc'], 1))], axis=1)\n",
    "    ub_v = (S_range[-1] - K*np.exp(-r*(T-ub_st[:, 0].reshape(-1)))).reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # save training data points to tensor and send to device\n",
    "    n_st_train = torch.from_numpy(n_st_train).float().requires_grad_().to(device)\n",
    "    n_v_train = torch.from_numpy(f_v_train).float().to(device)\n",
    "    \n",
    "    f_st_train = torch.from_numpy(f_st_train).float().to(device)\n",
    "    f_v_train = torch.from_numpy(f_v_train).float().to(device)\n",
    "    \n",
    "    lb_st = torch.from_numpy(lb_st).float().to(device)\n",
    "    lb_v = torch.from_numpy(lb_v).float().to(device)\n",
    "    \n",
    "    ub_st = torch.from_numpy(ub_st).float().to(device)\n",
    "    ub_v = torch.from_numpy(ub_v).float().to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prediction\n",
    "    v1_hat = PINNCGD(n_st_train)\n",
    "    \n",
    "    grads = tgrad.grad(v1_hat, n_st_train, grad_outputs=torch.ones(v1_hat.shape).cuda(), \n",
    "                       retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "    dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "    grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(),\n",
    "                          create_graph=True, only_inputs=True)[0]\n",
    "    d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "    S1 = n_st_train[:, 1].view(-1, 1)\n",
    "    \n",
    "    f_hat = PINNCGD(f_st_train)\n",
    "    lb_hat = PINNCGD(lb_st)\n",
    "    ub_hat = PINNCGD(ub_st)\n",
    "    \n",
    "    \n",
    "    # combined loss\n",
    "    d1 = D_CGD(n_st_train)[:, [0]]\n",
    "    loss1 = ((d1) * (dVdt + 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*v1_hat))\n",
    "    \n",
    "    d2 = D_CGD(f_st_train)[:, [1]]\n",
    "    loss2 = ((d2) * (f_hat - f_v_train))\n",
    "    \n",
    "    d3 = D_CGD(lb_st)[:, [2]]\n",
    "    loss3 = ((d3) * (lb_hat - lb_v))\n",
    "    \n",
    "    d4 = D_CGD(ub_st)[:, [3]]\n",
    "    loss4 = ((d4) * (ub_hat - ub_v))\n",
    "    \n",
    "    combined_loss = (loss1.mean() + loss2.mean() + loss3.mean() + loss4.mean())\n",
    "    \n",
    "    \n",
    "    # boundary condition loss\n",
    "    pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*v1_hat)\n",
    "    \n",
    "    bc_loss = lossFunction(ub_v, ub_hat) + lossFunction(lb_v, lb_hat) + lossFunction(f_v_train, f_hat)\n",
    "    pinn_loss = pde_loss + bc_loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Backpropagation and Update\n",
    "    optimizer.step(combined_loss, -combined_loss)\n",
    "\n",
    "    \n",
    "    # print information\n",
    "    loss_hist.append(pinn_loss.item())\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'''{epoch}/{max_iter} mse loss: {pinn_loss.item():.6f}, \n",
    "              PDE Loss: {pde_loss.item():.6f}, BC Loss: {bc_loss.item():.6f}, \n",
    "              nn loss: {combined_loss.item():.8f}, \n",
    "              minloss: {min(loss_hist):.6f}\n",
    "              ''')\n",
    "        pass\n",
    "        \n",
    "end_time = time.time()\n",
    "print('run time:', end_time - start_time)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(range(30000), loss_hist, marker='o', linestyle='-', color='b', label='Data Points')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_title('Simple Python Plot')\n",
    "\n",
    "# Show legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
