{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import tqdm\n",
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 40\n",
    "r = 0.05\n",
    "sigma = 0.25\n",
    "T = 1\n",
    "S_range = [0, 130]\n",
    "t_range = [0, T]\n",
    "gs = lambda x: np.fmax(x-K, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveLinear(nn.Linear):\n",
    "    r\"\"\"Applies a linear transformation to the input data as follows\n",
    "    :math:`y = naxA^T + b`.\n",
    "    More details available in Jagtap, A. D. et al. Locally adaptive\n",
    "    activation functions with slope recovery for deep and\n",
    "    physics-informed neural networks, Proc. R. Soc. 2020.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_features : int\n",
    "        The size of each input sample\n",
    "    out_features : int \n",
    "        The size of each output sample\n",
    "    bias : bool, optional\n",
    "        If set to ``False``, the layer will not learn an additive bias\n",
    "    adaptive_rate : float, optional\n",
    "        Scalable adaptive rate parameter for activation function that\n",
    "        is added layer-wise for each neuron separately. It is treated\n",
    "        as learnable parameter and will be optimized using a optimizer\n",
    "        of choice \n",
    "        (self.A is the learnable parameter which is initialized by the \n",
    "        self.adaptive rate. To create a learnable parameter for each neuron, \n",
    "        it multiplies the self.adaptive rate to the number of input features.)\n",
    "    adaptive_rate_scaler : float, optional\n",
    "        Fixed, pre-defined, scaling factor for adaptive activation\n",
    "        functions\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True, adaptive_rate=None, adaptive_rate_scaler=None):\n",
    "        super(AdaptiveLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.adaptive_rate = adaptive_rate\n",
    "        self.adaptive_rate_scaler = adaptive_rate_scaler\n",
    "        if self.adaptive_rate:\n",
    "            self.A = nn.Parameter(self.adaptive_rate * torch.ones(self.in_features))\n",
    "            if not self.adaptive_rate_scaler:\n",
    "                self.adaptive_rate_scaler = 10.0\n",
    "            \n",
    "    def forward(self, input):\n",
    "        if self.adaptive_rate:\n",
    "            return nn.functional.linear(self.adaptive_rate_scaler * self.A * input, self.weight, self.bias)\n",
    "        return nn.functional.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}, '\n",
    "            f'adaptive_rate={self.adaptive_rate is not None}, adaptive_rate_scaler={self.adaptive_rate_scaler is not None}'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    r\"\"\"Neural approximator for the unknown function that is supposed\n",
    "    to be solved.\n",
    "\n",
    "    More details available in Raissi, M. et al. Physics-informed neural\n",
    "    networks: A deep learning framework for solving forward and inverse\n",
    "    problems involving nonlinear partial differential equations, J.\n",
    "    Comput. Phys. 2019.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sizes : list\n",
    "        Each element represents the number of neuron per layer\n",
    "    activation : callable \n",
    "        Activation function\n",
    "    dropout_rate : float, optional\n",
    "        Dropout rate for regulrization during training process and\n",
    "        uncertainty quantification by means of Monte Carlo dropout\n",
    "        procedure while performing evaluation\n",
    "    adaptive_rate : float, optional\n",
    "        Scalable adaptive rate parameter for activation function that\n",
    "        is added layer-wise for each neuron separately. It is treated\n",
    "        as learnable parameter and will be optimized using a optimizer\n",
    "        of choice\n",
    "    adaptive_rate_scaler : float, optional\n",
    "        Fixed, pre-defined, scaling factor for adaptive activation\n",
    "        functions\n",
    "    \"\"\"\n",
    "    def __init__(self, sizes, activation, dropout_rate=0.0, adaptive_rate=None, adaptive_rate_scaler=None):\n",
    "        super(Net, self).__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            *[Net.linear_block(in_features, out_features, activation, dropout_rate, adaptive_rate, adaptive_rate_scaler)\n",
    "            for in_features, out_features in zip(sizes[:-1], sizes[1:-1])],     \n",
    "            AdaptiveLinear(sizes[-2], sizes[-1]) # output layer is regular linear transformation\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.regressor(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_block(in_features, out_features, activation, dropout_rate, adaptive_rate, adaptive_rate_scaler):\n",
    "        activation_dispatcher = nn.ModuleDict([\n",
    "            ['lrelu', nn.LeakyReLU()],\n",
    "            ['relu', nn.ReLU()],\n",
    "            ['tanh', nn.Tanh()],\n",
    "            ['sigmoid', nn.Sigmoid()],\n",
    "            # ['swish', Swish()]\n",
    "        ])\n",
    "        return nn.Sequential(\n",
    "            AdaptiveLinear(in_features, out_features, adaptive_rate=adaptive_rate, adaptive_rate_scaler=adaptive_rate_scaler),\n",
    "            activation_dispatcher[activation],\n",
    "            nn.Dropout(dropout_rate),\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPINN = Net(\n",
    "    sizes=[2, 50, 50, 50, 1], activation='relu', dropout_rate=0, adaptive_rate=0.1, adaptive_rate_scaler=5.0\n",
    "    )\n",
    "IPINN.cuda()\n",
    "\n",
    "samples = {\"pde\": 50000, \"bc\":25000, \"fc\":25000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 60000\n",
    "adaptive_rate = 0.1\n",
    "lossFunction = nn.MSELoss()\n",
    "lr = 0.00002\n",
    "optimizer = optim.Adam(IPINN.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linspace: space the batch of data linearly, otherwise random, type=float\n",
    "- domain: Boundaries of the solution domain, type=float\n",
    "- batch_size: The number of adata points for optimization per epoch, type=float\n",
    "- rhs: right-hand-side forcing function, type=float\n",
    "- boundary_conditions: boundaru conditions on boundaries of the domain, type=float\n",
    "- adaptive rate: add additional adaptive rate parameter to activation function, type=float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/60000 mse loss: 5986.035156, PDE Loss: 0.00005, BC Loss: 4122.45947, fc loss: 1863.57568, reg_loss:  0.904837, min loss: 5986.03516\n",
      "500/60000 mse loss: 5444.014648, PDE Loss: 0.00001, BC Loss: 3767.08472, fc loss: 1676.92993, reg_loss:  0.899445, min loss: 5444.01465\n",
      "1000/60000 mse loss: 3877.694580, PDE Loss: 0.00002, BC Loss: 2729.64209, fc loss: 1148.05249, reg_loss:  0.890947, min loss: 3877.69458\n",
      "1500/60000 mse loss: 1163.464355, PDE Loss: 0.00031, BC Loss: 853.10199, fc loss: 310.36206, reg_loss:  0.880583, min loss: 1163.46436\n",
      "2000/60000 mse loss: 228.302948, PDE Loss: 0.00446, BC Loss: 67.56517, fc loss: 160.73332, reg_loss:  0.874489, min loss: 228.30295\n",
      "2500/60000 mse loss: 207.226227, PDE Loss: 0.04340, BC Loss: 28.78441, fc loss: 178.39842, reg_loss:  0.869827, min loss: 207.22623\n",
      "3000/60000 mse loss: 196.138489, PDE Loss: 0.24985, BC Loss: 26.35988, fc loss: 169.52876, reg_loss:  0.863586, min loss: 196.13849\n",
      "3500/60000 mse loss: 173.930588, PDE Loss: 1.35067, BC Loss: 24.32064, fc loss: 148.25928, reg_loss:  0.857531, min loss: 173.93059\n",
      "4000/60000 mse loss: 140.792664, PDE Loss: 6.90940, BC Loss: 16.91094, fc loss: 116.97233, reg_loss:  0.852342, min loss: 140.79266\n",
      "4500/60000 mse loss: 119.977760, PDE Loss: 14.33434, BC Loss: 12.51133, fc loss: 93.13209, reg_loss:  0.848644, min loss: 119.97776\n",
      "5000/60000 mse loss: 104.581650, PDE Loss: 22.38088, BC Loss: 9.23760, fc loss: 72.96317, reg_loss:  0.846115, min loss: 104.58165\n",
      "5500/60000 mse loss: 92.378555, PDE Loss: 26.56516, BC Loss: 7.17528, fc loss: 58.63811, reg_loss:  0.845267, min loss: 92.37856\n",
      "6000/60000 mse loss: 79.616821, PDE Loss: 26.25505, BC Loss: 5.75052, fc loss: 47.61124, reg_loss:  0.845741, min loss: 79.61682\n",
      "6500/60000 mse loss: 65.621124, PDE Loss: 24.00568, BC Loss: 4.46049, fc loss: 37.15495, reg_loss:  0.846619, min loss: 65.62112\n",
      "7000/60000 mse loss: 51.025387, PDE Loss: 20.63723, BC Loss: 3.25410, fc loss: 27.13406, reg_loss:  0.847466, min loss: 51.02539\n",
      "7500/60000 mse loss: 36.741684, PDE Loss: 16.36734, BC Loss: 2.19032, fc loss: 18.18403, reg_loss:  0.848163, min loss: 36.74168\n",
      "8000/60000 mse loss: 23.908997, PDE Loss: 11.68153, BC Loss: 1.32190, fc loss: 10.90556, reg_loss:  0.848680, min loss: 23.90900\n",
      "8500/60000 mse loss: 13.568752, PDE Loss: 7.26198, BC Loss: 0.67936, fc loss: 5.62741, reg_loss:  0.848998, min loss: 13.56875\n",
      "9000/60000 mse loss: 6.455086, PDE Loss: 3.78770, BC Loss: 0.28882, fc loss: 2.37857, reg_loss:  0.849168, min loss: 6.45509\n",
      "9500/60000 mse loss: 2.461365, PDE Loss: 1.58102, BC Loss: 0.09594, fc loss: 0.78440, reg_loss:  0.849254, min loss: 2.46136\n",
      "10000/60000 mse loss: 0.718088, PDE Loss: 0.49985, BC Loss: 0.02319, fc loss: 0.19504, reg_loss:  0.849294, min loss: 0.71809\n",
      "10500/60000 mse loss: 0.154169, PDE Loss: 0.11389, BC Loss: 0.00465, fc loss: 0.03562, reg_loss:  0.849302, min loss: 0.15417\n",
      "11000/60000 mse loss: 0.026081, PDE Loss: 0.01847, BC Loss: 0.00090, fc loss: 0.00671, reg_loss:  0.849290, min loss: 0.02485\n",
      "11500/60000 mse loss: 0.004642, PDE Loss: 0.00356, BC Loss: 0.00013, fc loss: 0.00095, reg_loss:  0.849278, min loss: 0.00429\n",
      "12000/60000 mse loss: 0.002404, PDE Loss: 0.00210, BC Loss: 0.00002, fc loss: 0.00029, reg_loss:  0.849278, min loss: 0.00240\n",
      "12500/60000 mse loss: 0.002240, PDE Loss: 0.00196, BC Loss: 0.00002, fc loss: 0.00027, reg_loss:  0.849291, min loss: 0.00224\n",
      "13000/60000 mse loss: 0.002158, PDE Loss: 0.00189, BC Loss: 0.00001, fc loss: 0.00026, reg_loss:  0.849308, min loss: 0.00216\n",
      "13500/60000 mse loss: 0.002350, PDE Loss: 0.00190, BC Loss: 0.00018, fc loss: 0.00026, reg_loss:  0.849327, min loss: 0.00210\n",
      "14000/60000 mse loss: 0.002055, PDE Loss: 0.00181, BC Loss: 0.00001, fc loss: 0.00023, reg_loss:  0.849345, min loss: 0.00206\n",
      "14500/60000 mse loss: 0.002007, PDE Loss: 0.00178, BC Loss: 0.00001, fc loss: 0.00022, reg_loss:  0.849360, min loss: 0.00201\n",
      "15000/60000 mse loss: 0.001959, PDE Loss: 0.00174, BC Loss: 0.00001, fc loss: 0.00020, reg_loss:  0.849373, min loss: 0.00196\n",
      "15500/60000 mse loss: 0.001905, PDE Loss: 0.00171, BC Loss: 0.00001, fc loss: 0.00018, reg_loss:  0.849383, min loss: 0.00190\n",
      "16000/60000 mse loss: 0.001862, PDE Loss: 0.00168, BC Loss: 0.00001, fc loss: 0.00017, reg_loss:  0.849397, min loss: 0.00186\n",
      "16500/60000 mse loss: 0.001827, PDE Loss: 0.00166, BC Loss: 0.00001, fc loss: 0.00016, reg_loss:  0.849415, min loss: 0.00183\n",
      "17000/60000 mse loss: 0.001794, PDE Loss: 0.00164, BC Loss: 0.00001, fc loss: 0.00014, reg_loss:  0.849437, min loss: 0.00179\n",
      "17500/60000 mse loss: 0.001754, PDE Loss: 0.00162, BC Loss: 0.00001, fc loss: 0.00013, reg_loss:  0.849464, min loss: 0.00175\n",
      "18000/60000 mse loss: 0.001703, PDE Loss: 0.00159, BC Loss: 0.00001, fc loss: 0.00010, reg_loss:  0.849497, min loss: 0.00170\n",
      "18500/60000 mse loss: 0.001688, PDE Loss: 0.00158, BC Loss: 0.00001, fc loss: 0.00009, reg_loss:  0.849525, min loss: 0.00169\n",
      "19000/60000 mse loss: 0.001661, PDE Loss: 0.00157, BC Loss: 0.00001, fc loss: 0.00008, reg_loss:  0.849555, min loss: 0.00166\n",
      "19500/60000 mse loss: 0.001629, PDE Loss: 0.00155, BC Loss: 0.00001, fc loss: 0.00007, reg_loss:  0.849589, min loss: 0.00163\n",
      "20000/60000 mse loss: 0.001596, PDE Loss: 0.00153, BC Loss: 0.00001, fc loss: 0.00006, reg_loss:  0.849626, min loss: 0.00160\n",
      "20500/60000 mse loss: 0.001554, PDE Loss: 0.00150, BC Loss: 0.00001, fc loss: 0.00005, reg_loss:  0.849667, min loss: 0.00155\n",
      "21000/60000 mse loss: 0.001538, PDE Loss: 0.00149, BC Loss: 0.00001, fc loss: 0.00004, reg_loss:  0.849698, min loss: 0.00154\n",
      "21500/60000 mse loss: 0.001521, PDE Loss: 0.00147, BC Loss: 0.00001, fc loss: 0.00004, reg_loss:  0.849717, min loss: 0.00152\n",
      "22000/60000 mse loss: 0.001505, PDE Loss: 0.00146, BC Loss: 0.00001, fc loss: 0.00003, reg_loss:  0.849740, min loss: 0.00150\n",
      "22500/60000 mse loss: 0.001484, PDE Loss: 0.00144, BC Loss: 0.00001, fc loss: 0.00003, reg_loss:  0.849766, min loss: 0.00148\n",
      "23000/60000 mse loss: 0.001459, PDE Loss: 0.00142, BC Loss: 0.00001, fc loss: 0.00003, reg_loss:  0.849796, min loss: 0.00146\n",
      "23500/60000 mse loss: 0.001429, PDE Loss: 0.00139, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849837, min loss: 0.00143\n",
      "24000/60000 mse loss: 0.001407, PDE Loss: 0.00137, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849877, min loss: 0.00141\n",
      "24500/60000 mse loss: 0.001394, PDE Loss: 0.00136, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849897, min loss: 0.00139\n",
      "25000/60000 mse loss: 0.001380, PDE Loss: 0.00135, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849920, min loss: 0.00138\n",
      "25500/60000 mse loss: 0.001359, PDE Loss: 0.00133, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849943, min loss: 0.00136\n",
      "26000/60000 mse loss: 0.001337, PDE Loss: 0.00131, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849970, min loss: 0.00134\n",
      "26500/60000 mse loss: 0.001310, PDE Loss: 0.00128, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.849999, min loss: 0.00131\n",
      "27000/60000 mse loss: 0.001277, PDE Loss: 0.00125, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.850033, min loss: 0.00128\n",
      "27500/60000 mse loss: 0.001266, PDE Loss: 0.00124, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.850051, min loss: 0.00127\n",
      "28000/60000 mse loss: 0.001252, PDE Loss: 0.00123, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.850053, min loss: 0.00125\n",
      "28500/60000 mse loss: 0.001237, PDE Loss: 0.00121, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.850054, min loss: 0.00124\n",
      "29000/60000 mse loss: 0.001223, PDE Loss: 0.00120, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.850055, min loss: 0.00122\n",
      "29500/60000 mse loss: 0.001200, PDE Loss: 0.00118, BC Loss: 0.00001, fc loss: 0.00002, reg_loss:  0.850056, min loss: 0.00120\n",
      "30000/60000 mse loss: 0.001179, PDE Loss: 0.00116, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850059, min loss: 0.00118\n",
      "30500/60000 mse loss: 0.001155, PDE Loss: 0.00113, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850060, min loss: 0.00116\n",
      "31000/60000 mse loss: 0.001123, PDE Loss: 0.00110, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850061, min loss: 0.00112\n",
      "31500/60000 mse loss: 0.001118, PDE Loss: 0.00109, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850054, min loss: 0.00112\n",
      "32000/60000 mse loss: 0.001109, PDE Loss: 0.00109, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850034, min loss: 0.00111\n",
      "32500/60000 mse loss: 0.001100, PDE Loss: 0.00108, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850012, min loss: 0.00110\n",
      "33000/60000 mse loss: 0.001091, PDE Loss: 0.00107, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849990, min loss: 0.00109\n",
      "33500/60000 mse loss: 0.001078, PDE Loss: 0.00106, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849969, min loss: 0.00108\n",
      "34000/60000 mse loss: 0.001065, PDE Loss: 0.00104, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849953, min loss: 0.00106\n",
      "34500/60000 mse loss: 0.001046, PDE Loss: 0.00103, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849943, min loss: 0.00105\n",
      "35000/60000 mse loss: 0.001026, PDE Loss: 0.00101, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849946, min loss: 0.00103\n",
      "35500/60000 mse loss: 0.001027, PDE Loss: 0.00100, BC Loss: 0.00002, fc loss: 0.00002, reg_loss:  0.849962, min loss: 0.00101\n",
      "36000/60000 mse loss: 0.001005, PDE Loss: 0.00099, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849966, min loss: 0.00101\n",
      "36500/60000 mse loss: 0.001000, PDE Loss: 0.00098, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849968, min loss: 0.00100\n",
      "37000/60000 mse loss: 0.000995, PDE Loss: 0.00097, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849973, min loss: 0.00099\n",
      "37500/60000 mse loss: 0.000983, PDE Loss: 0.00096, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849979, min loss: 0.00098\n",
      "38000/60000 mse loss: 0.000971, PDE Loss: 0.00095, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849988, min loss: 0.00097\n",
      "38500/60000 mse loss: 0.000957, PDE Loss: 0.00094, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.849999, min loss: 0.00096\n",
      "39000/60000 mse loss: 0.000943, PDE Loss: 0.00092, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850012, min loss: 0.00094\n",
      "39500/60000 mse loss: 0.019476, PDE Loss: 0.00117, BC Loss: 0.01601, fc loss: 0.00229, reg_loss:  0.850022, min loss: 0.00093\n",
      "40000/60000 mse loss: 0.000925, PDE Loss: 0.00091, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850033, min loss: 0.00093\n",
      "40500/60000 mse loss: 0.000921, PDE Loss: 0.00090, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850037, min loss: 0.00092\n",
      "41000/60000 mse loss: 0.000917, PDE Loss: 0.00090, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850042, min loss: 0.00092\n",
      "41500/60000 mse loss: 0.000911, PDE Loss: 0.00089, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850048, min loss: 0.00091\n",
      "42000/60000 mse loss: 0.000905, PDE Loss: 0.00089, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850055, min loss: 0.00090\n",
      "42500/60000 mse loss: 0.000895, PDE Loss: 0.00088, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850065, min loss: 0.00089\n",
      "43000/60000 mse loss: 0.000882, PDE Loss: 0.00086, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850075, min loss: 0.00088\n",
      "43500/60000 mse loss: 0.000871, PDE Loss: 0.00085, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850088, min loss: 0.00087\n",
      "44000/60000 mse loss: 0.001008, PDE Loss: 0.00088, BC Loss: 0.00008, fc loss: 0.00005, reg_loss:  0.850094, min loss: 0.00086\n",
      "44500/60000 mse loss: 0.000857, PDE Loss: 0.00084, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850108, min loss: 0.00086\n",
      "45000/60000 mse loss: 0.000854, PDE Loss: 0.00084, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850112, min loss: 0.00085\n",
      "45500/60000 mse loss: 0.000849, PDE Loss: 0.00083, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850116, min loss: 0.00085\n",
      "46000/60000 mse loss: 0.000844, PDE Loss: 0.00083, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850122, min loss: 0.00084\n",
      "46500/60000 mse loss: 0.000838, PDE Loss: 0.00082, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850129, min loss: 0.00084\n",
      "47000/60000 mse loss: 0.000831, PDE Loss: 0.00081, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850139, min loss: 0.00083\n",
      "47500/60000 mse loss: 0.000820, PDE Loss: 0.00080, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850150, min loss: 0.00082\n",
      "48000/60000 mse loss: 0.007766, PDE Loss: 0.00107, BC Loss: 0.00666, fc loss: 0.00003, reg_loss:  0.850159, min loss: 0.00081\n",
      "48500/60000 mse loss: 0.000811, PDE Loss: 0.00079, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850169, min loss: 0.00081\n",
      "49000/60000 mse loss: 0.000808, PDE Loss: 0.00079, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850170, min loss: 0.00081\n",
      "49500/60000 mse loss: 0.000806, PDE Loss: 0.00079, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850173, min loss: 0.00081\n",
      "50000/60000 mse loss: 0.000803, PDE Loss: 0.00079, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850176, min loss: 0.00080\n",
      "50500/60000 mse loss: 0.000800, PDE Loss: 0.00078, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850179, min loss: 0.00080\n",
      "51000/60000 mse loss: 0.000795, PDE Loss: 0.00078, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850184, min loss: 0.00080\n",
      "51500/60000 mse loss: 0.000790, PDE Loss: 0.00077, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850189, min loss: 0.00079\n",
      "52000/60000 mse loss: 0.000783, PDE Loss: 0.00077, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850195, min loss: 0.00078\n",
      "52500/60000 mse loss: 0.002939, PDE Loss: 0.00100, BC Loss: 0.00070, fc loss: 0.00125, reg_loss:  0.850178, min loss: 0.00077\n",
      "53000/60000 mse loss: 0.000776, PDE Loss: 0.00076, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850208, min loss: 0.00077\n",
      "53500/60000 mse loss: 0.000774, PDE Loss: 0.00076, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850210, min loss: 0.00077\n",
      "54000/60000 mse loss: 0.000772, PDE Loss: 0.00076, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850211, min loss: 0.00077\n",
      "54500/60000 mse loss: 0.000769, PDE Loss: 0.00075, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850213, min loss: 0.00077\n",
      "55000/60000 mse loss: 0.000767, PDE Loss: 0.00075, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850215, min loss: 0.00077\n",
      "55500/60000 mse loss: 0.000764, PDE Loss: 0.00075, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850218, min loss: 0.00076\n",
      "56000/60000 mse loss: 0.000757, PDE Loss: 0.00074, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850221, min loss: 0.00076\n",
      "56500/60000 mse loss: 0.000749, PDE Loss: 0.00073, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850225, min loss: 0.00075\n",
      "57000/60000 mse loss: 0.001301, PDE Loss: 0.00087, BC Loss: 0.00024, fc loss: 0.00019, reg_loss:  0.850206, min loss: 0.00074\n",
      "57500/60000 mse loss: 0.000744, PDE Loss: 0.00073, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850235, min loss: 0.00074\n",
      "58000/60000 mse loss: 0.000743, PDE Loss: 0.00073, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850236, min loss: 0.00074\n",
      "58500/60000 mse loss: 0.000741, PDE Loss: 0.00073, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850237, min loss: 0.00074\n",
      "59000/60000 mse loss: 0.000739, PDE Loss: 0.00072, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850237, min loss: 0.00074\n",
      "59500/60000 mse loss: 0.000737, PDE Loss: 0.00072, BC Loss: 0.00001, fc loss: 0.00001, reg_loss:  0.850238, min loss: 0.00074\n",
      "run time: 440.9373109340668\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.autograd as tgrad\n",
    "\n",
    "loss_hist = []\n",
    "start_time = time.time()\n",
    "\n",
    "# tqdm.tqdm(range(n_epochs), desc='[Training procedure]', ascii=True, total=n_epochs)\n",
    "\n",
    "for _ in range(n_epochs):\n",
    "        def closure():\n",
    "            i_st_train, i_v_train, bc_st_train, bc_v_train, n_st_train, n_v_train = \\\n",
    "            utils.trainingData3(K, \n",
    "                            r, \n",
    "                            sigma, \n",
    "                            T, \n",
    "                            S_range[-1], \n",
    "                            S_range, \n",
    "                            t_range, \n",
    "                            gs, \n",
    "                            samples['bc'], \n",
    "                            samples['fc'], \n",
    "                            samples['pde'], \n",
    "                            RNG_key=123)\n",
    "            \n",
    "            # save training data points to tensor and send to device\n",
    "            i_st_train = torch.from_numpy(i_st_train).float().requires_grad_().to(device)\n",
    "            i_v_train = torch.from_numpy(i_v_train).float().to(device)\n",
    "            \n",
    "            n_st_train = torch.from_numpy(n_st_train).float().requires_grad_().to(device)\n",
    "            n_v_train = torch.from_numpy(n_v_train).float().to(device)\n",
    "            \n",
    "            bc_st_train = torch.from_numpy(bc_st_train).float().to(device)\n",
    "            bc_v_train = torch.from_numpy(bc_v_train).float().to(device)\n",
    "            \n",
    "            \n",
    "            # PDE Round\n",
    "            y1_hat = IPINN(n_st_train)\n",
    "            \n",
    "            grads = tgrad.grad(y1_hat, n_st_train, grad_outputs=torch.ones(y1_hat.shape).cuda(), retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "            # print(grads)\n",
    "            dVdt, dVdS = grads[:, 0].view(-1, 1), grads[:, 1].view(-1, 1)\n",
    "            grads2nd = tgrad.grad(dVdS, n_st_train, grad_outputs=torch.ones(dVdS.shape).cuda(), create_graph=True, only_inputs=True)[0]\n",
    "            # print(grads2nd)\n",
    "            d2VdS2 = grads2nd[:, 1].view(-1, 1)\n",
    "            S1 = n_st_train[:, 1].view(-1, 1)\n",
    "            pde_loss = lossFunction(-dVdt, 0.5*((sigma*S1)**2)*d2VdS2 + r*S1*dVdS - r*y1_hat)\n",
    "            \n",
    "            \n",
    "            # BC Round\n",
    "            y21_hat = IPINN(bc_st_train)\n",
    "            bc_loss = lossFunction(bc_v_train, y21_hat)\n",
    "            \n",
    "            # final condition loss\n",
    "            fc_hat = IPINN(i_st_train)\n",
    "            fc_loss = lossFunction(i_v_train, fc_hat)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if adaptive_rate:\n",
    "                local_recovery_terms = torch.tensor([torch.mean(IPINN.regressor[layer][0].A.data) for layer in range(len(IPINN.regressor) - 1)])\n",
    "                slope_recovery_term = 1 / torch.mean(torch.exp(local_recovery_terms))\n",
    "                loss = pde_loss + bc_loss + fc_loss + slope_recovery_term\n",
    "            else:\n",
    "                loss = pde_loss + bc_loss + fc_loss\n",
    "                \n",
    "                \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            mse_loss = pde_loss + bc_loss + fc_loss\n",
    "            loss_hist.append(mse_loss.item())\n",
    "            \n",
    "            if _ % 500 == 0:\n",
    "                print(f'{_}/{n_epochs} mse loss: {mse_loss.item():5f}, PDE Loss: {pde_loss.item():.5f}, BC Loss: {bc_loss.item():.5f}, fc loss: {fc_loss.item():.5f}, reg_loss: {slope_recovery_term.item(): 5f}, min loss: {min(loss_hist):.5f}')\n",
    "            \n",
    "            return loss\n",
    "        \n",
    "        optimizer.step(closure)\n",
    "elapsed = timer() - start_time\n",
    "end_time = time.time()\n",
    "print('run time:', end_time - start_time)\n",
    "logging.info(f'Training finished. Elapsed time: {elapsed} s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'IPINN')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAPxCAYAAABQHTbsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmhklEQVR4nO3de5yWdZ0//vecGYSZkdMAikqSB8xDauHkKZOkot1ttU2L0i3NtcUtoVWzXHNtN/zpWml56LAb7ndrTWu1kjyQJqbiiaIQFU8Upg54ggE5zeH6/cHcF0wDw0DIfV33/Xw+HvMI7vua+/7ccEm8eL8/709FkiRJAAAAALlUWewFAAAAANtPsAcAAIAcE+wBAAAgxwR7AAAAyDHBHgAAAHJMsAcAAIAcE+wBAAAgxwR7AAAAyDHBHgAAAHJMsAcAAIAcE+wBgB5mzpwZFRUV8eijj0ZExMUXXxwVFRXp18CBA2P8+PFx4YUXRltb2xa/b9PvbW5ujtWrV/d6r7322is++MEP9nis8D5XXHHFVtcGAAj2AEA/XXvttfH//t//i6997Wux3377xb//+7/H+973vkiSZKvfu2zZsrj22mu36f0uv/zyzf5jAADQk2APAPTLhz/84fj4xz8eZ511Vvzf//1fnHjiiTF37tx48MEHt/q9hxxySFx++eWxZs2afr3XIYccEkuXLo3rrrvuL102AJQ8wR4A2C7vec97IiJi8eLFW732oosuiqVLl/a7an/kkUfGe97znrjsssv6/Y8BAFCuBHsAYLs8++yzERExdOjQrV579NFHb3NQv/jii7fpHwMAoFwJ9gBAv7z22mvxyiuvxB/+8If4zne+E9dcc000NzfH0Ucf3a/v//KXv7xN7fVHH310HHfccdvUwg8A5UiwBwD6Zd99943hw4fH2LFj4x/+4R9i3LhxMWvWrBg4cGC/vv+YY46J4447bpur9q2trfbaA0AfBHsAoF9+8pOfxOzZs+Oee+6JZ555Jh577LE47LDDtuk1tjWob88/BgBAuRHsAYB+OeaYY2LixIlx7LHHxt57773dr/Hud797m4L6l7/85WhtbY1vf/vb2/WeAFDqBHsAYKcqVO37G9SPPfbYePe73x3/3//3/6naA8BmCPYAwE61aVBfu3Ztv76n8I8B3/nOd97k1QFA/gj2AMBOV2ivX7p0ab+uP/bYY+PYY4+N+fPnv7kLA4AcEuwBgJ3u3e9+dxx77LHb9D0XX3zxm7MYAMi5iiRJkmIvAgAAANg+KvYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5Fh1sReQB11dXfHiiy/G4MGDo6KiotjLAQAAoMQlSRIrV66M0aNHR2Vl3zV5wb4fXnzxxRgzZkyxlwEAAECZef7552P33Xfv8xrBvh8GDx4cERt+QRsaGoq8GgAAAEpdW1tbjBkzJs2jfRHs+6HQft/Q0CDYAwAAsNP0Zzu44XkAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY0UP9i+88EJ8/OMfj6FDh0Z9fX0ceOCB8eijj6bPJ0kSF110UYwaNSrq6+tj4sSJ8fTTT/d4jddeey2mTJkSDQ0N0dTUFKeffnqsWrWqxzW///3v4+ijj44BAwbEmDFj4rLLLtspnw8AAADeTEUN9q+//noceeSRUVNTE7fddls8/vjjccUVV8Suu+6aXnPZZZfFVVddFdddd1089NBDscsuu8SkSZNi7dq16TVTpkyJhQsXxuzZs+PWW2+Ne++9N84888z0+ba2tjjhhBNizz33jHnz5sXll18eF198cXznO9/ZqZ8XAAAAdrSKJEmSYr35F77whbj//vvj17/+9WafT5IkRo8eHZ///Ofjn//5nyMiYsWKFdHc3BwzZ86MU045JZ544okYP358PPLII3H44YdHRMTtt98eH/jAB+JPf/pTjB49Oq699tr40pe+FK2trVFbW5u+9y233BJPPvnkVtfZ1tYWjY2NsWLFimhoaNhBnx4AAAA2b1tyaFEr9j/72c/i8MMPj7/7u7+LESNGxNvf/vb47ne/mz6/ePHiaG1tjYkTJ6aPNTY2xoQJE2Lu3LkRETF37txoampKQ31ExMSJE6OysjIeeuih9JpjjjkmDfUREZMmTYpFixbF66+/3mtd69ati7a2th5fAAAAkEVFDfbPPfdcXHvttfHWt7417rjjjvjMZz4Tn/3sZ+P666+PiIjW1taIiGhubu7xfc3Nzelzra2tMWLEiB7PV1dXx5AhQ3pcs7nX2PQ9NjVjxoxobGxMv8aMGbMDPu2bb2nb2rhzYWvMffbVYi8FAACAnaSowb6rqysOPfTQ+OpXvxpvf/vb48wzz4xPf/rTcd111xVzWXHBBRfEihUr0q/nn3++qOvprzsfXxpn/r958Z/3PVfspQAAALCTFDXYjxo1KsaPH9/jsf333z+WLFkSEREjR46MiIilS5f2uGbp0qXpcyNHjoxly5b1eL6joyNee+21Htds7jU2fY9N1dXVRUNDQ4+vPNhzyMCIiPjjq6uLvBIAAAB2lqIG+yOPPDIWLVrU47Gnnnoq9txzz4iIGDt2bIwcOTLuuuuu9Pm2trZ46KGHoqWlJSIiWlpaYvny5TFv3rz0mrvvvju6urpiwoQJ6TX33ntvtLe3p9fMnj079t133x4T+PNuz6Ebgv2S11ZHV1fRZiICAACwExU12E+bNi0efPDB+OpXvxrPPPNM/PCHP4zvfOc7MXXq1IiIqKioiHPOOSf+7d/+LX72s5/FggUL4tRTT43Ro0fHhz70oYjYUOF/3/veF5/+9Kfj4Ycfjvvvvz/OPvvsOOWUU2L06NEREfGxj30samtr4/TTT4+FCxfGj370o7jyyitj+vTpxfrob4rRTfVRVVkR6zq64uVV64q9HAAAAHaC6mK++Tve8Y64+eab44ILLohLLrkkxo4dG9/4xjdiypQp6TXnnXdevPHGG3HmmWfG8uXL46ijjorbb789BgwYkF7zgx/8IM4+++w4/vjjo7KyMk466aS46qqr0ucbGxvjzjvvjKlTp8Zhhx0Ww4YNi4suuqjHWfeloKaqMnZrqo8lr62OP766OpobBmz9mwAAAMi1op5jnxd5Osf+4997KO575pW4/MMHxd8dno9p/gAAAPSUm3Ps2fH22GSfPQAAAKVPsC8xJuMDAACUF8G+xBQm4/9RxR4AAKAsCPYlZo8hu0RExPOCPQAAQFkQ7EtMYY/9a2+sj5Vr24u8GgAAAN5sgn2JGVRXHUN2qY0IA/QAAADKgWBfgnZrqo+IiBeXry3ySgAAAHizCfYlaGOwX1PklQAAAPBmE+xL0OjuYP+CYA8AAFDyBPsStNuugj0AAEC5EOxL0G5NAyIi4oXXBXsAAIBSJ9iXoN2aNhx5Z489AABA6RPsS9Do7or9spXrYl1HZ5FXAwAAwJtJsC9BQ3apjQE1G35rW1c48g4AAKCUCfYlqKKiYuNkfPvsAQAASppgX6JGNW5ox1+6UsUeAACglAn2Jap5cHewb1tX5JUAAADwZhLsS9SIhkKwV7EHAAAoZYJ9iWpuqIuIiGUq9gAAACVNsC9RzSr2AAAAZUGwL1GFir3heQAAAKVNsC9RIzYZnpckSZFXAwAAwJtFsC9RI7or9us7umLFmvYirwYAAIA3i2Bfouqqq2LXgTUR4cg7AACAUibYlzAD9AAAAEqfYF/CnGUPAABQ+gT7EjZicPdZ9iu14gMAAJQqwb6EFY68W6ZiDwAAULIE+xK26ZF3AAAAlCbBvoQNHVQbERGvvbG+yCsBAADgzSLYl7Chu2xoxX/1DRV7AACAUiXYl7Bh3RX7V1XsAQAASpZgX8KGDtpQsV++uj3aO7uKvBoAAADeDIJ9CWuqr4nKig0/fl3VHgAAoCQJ9iWssrIihuyiHR8AAKCUCfYlLh2gt0qwBwAAKEWCfYkbmg7QMxkfAACgFAn2JS5txVexBwAAKEmCfYkbNshZ9gAAAKVMsC9xQ1XsAQAASppgX+KGphV7wR4AAKAUCfYlbuMee634AAAApUiwL3HDBjnHHgAAoJQJ9iVu1+6K/euCPQAAQEkS7EtcU31NRES0re2Izq6kyKsBAABgRxPsS1xjd7CPiGhb017ElQAAAPBmEOxLXHVVZQyuq46IiOWCPQAAQMkR7MtA48ANVfvlq+2zBwAAKDWCfRloKgR7FXsAAICSI9iXgab6DZPxV6wW7AEAAEqNYF8GtOIDAACULsG+DBSOvNOKDwAAUHoE+zKQ7rHXig8AAFByBPsykO6xV7EHAAAoOYJ9GbDHHgAAoHQJ9mXAHnsAAIDSJdiXgaaBjrsDAAAoVYJ9GUiH56nYAwAAlBzBvgykrfir10dXV1Lk1QAAALAjCfZloKE72HclEavWdxR5NQAAAOxIgn0ZGFBTFQNqNvxW22cPAABQWgT7MtHYXbV3lj0AAEBpEezLxOABG4J921rBHgAAoJQI9mVi8IDqiIhYudYeewAAgFIi2JeJQsVesAcAACgtgn2Z2Fix14oPAABQSgT7MtGgFR8AAKAkCfZlYmMrvoo9AABAKRHsy8TgOhV7AACAUiTYl4mGesPzAAAASpFgXyYKw/OcYw8AAFBaBPsy4bg7AACA0iTYlwnH3QEAAJQmwb5MDHbcHQAAQEkS7MtEQ3crvj32AAAApUWwLxOFiv3a9q5o7+wq8moAAADYUQT7MjGo+xz7CO34AAAApUSwLxPVVZUxsLYqIgzQAwAAKCWCfRkxQA8AAKD0CPZlZLABegAAACVHsC8jKvYAAAClR7AvI4UBem+sE+wBAABKhWBfRnap7Q726zuLvBIAAAB2FMG+jOyiYg8AAFByBPsyskvdhuPuVgv2AAAAJUOwLyOFiv2qdVrxAQAASoVgX0Z2qe2u2K9XsQcAACgVgn0Z2VixF+wBAABKhWBfRgpT8Vebig8AAFAyBPsyMrB7eJ6KPQAAQOkQ7MtIoRXfHnsAAIDSIdiXkUIr/hum4gMAAJQMwb6MFM6xf0MrPgAAQMkQ7MvIxoq9YA8AAFAqBPsyku6xb++Mrq6kyKsBAABgRxDsy0ihFT9JIta022cPAABQCgT7MlJfUxUVFRt+/IbJ+AAAACVBsC8jFRUVJuMDAACUGMG+zJiMDwAAUFoE+zJjMj4AAEBpEezLTDoZf71WfAAAgFIg2JeZgbUbWvFXqdgDAACUBMG+zAxKK/aCPQAAQCkQ7MvMwO5gv8pUfAAAgJIg2JeZgTUbWvHXtgv2AAAApUCwLzP13Xvs1xieBwAAUBIE+zIzoLtibyo+AABAaRDsy0xhKv4arfgAAAAlQbAvM/X22AMAAJQUwb7MDKgttOI77g4AAKAUCPZlpjAVf017V5FXAgAAwI4g2JeZwlT8tYbnAQAAlATBvswUgv3qdq34AAAApUCwLzOF4XnOsQcAACgNgn2Z2TgV3x57AACAUiDYl5mBpuIDAACUFMG+zAxIp+JrxQcAACgFgn2ZSafit3dFV1dS5NUAAADwlxLsy0yhFT8iYm2Hqj0AAEDeCfZlZkD1xmBvMj4AAED+CfZlprKyIuqqN/y2rxbsAQAAck+wL0MD0332gj0AAEDeCfZlqN5kfAAAgJIh2JehAelZ9oI9AABA3gn2ZajQiq9iDwAAkH+CfRkqtOKvVbEHAADIPcG+DA2o0YoPAABQKgT7MqQVHwAAoHQI9mUobcUX7AEAAHKvqMH+4osvjoqKih5f++23X/r82rVrY+rUqTF06NAYNGhQnHTSSbF06dIer7FkyZKYPHlyDBw4MEaMGBHnnntudHR09LjmnnvuiUMPPTTq6upi3LhxMXPmzJ3x8TKr3lR8AACAklH0iv0BBxwQL730Uvp13333pc9NmzYtfv7zn8dNN90Uc+bMiRdffDFOPPHE9PnOzs6YPHlyrF+/Ph544IG4/vrrY+bMmXHRRRel1yxevDgmT54cxx13XMyfPz/OOeecOOOMM+KOO+7YqZ8zS+prqiNCKz4AAEApqC76AqqrY+TIkb0eX7FiRfznf/5n/PCHP4z3vOc9ERHx/e9/P/bff/948MEH44gjjog777wzHn/88fjlL38Zzc3Nccghh8RXvvKVOP/88+Piiy+O2trauO6662Ls2LFxxRVXRETE/vvvH/fdd198/etfj0mTJu3Uz5oVA2o2/HvOGhV7AACA3Ct6xf7pp5+O0aNHx1ve8paYMmVKLFmyJCIi5s2bF+3t7TFx4sT02v322y/22GOPmDt3bkREzJ07Nw488MBobm5Or5k0aVK0tbXFwoUL02s2fY3CNYXX2Jx169ZFW1tbj69SUpiKv66jq8grAQAA4C9V1GA/YcKEmDlzZtx+++1x7bXXxuLFi+Poo4+OlStXRmtra9TW1kZTU1OP72lubo7W1taIiGhtbe0R6gvPF57r65q2trZYs2bNZtc1Y8aMaGxsTL/GjBmzIz5uZhQq9uu04gMAAOReUVvx3//+96c/Puigg2LChAmx5557xo033hj19fVFW9cFF1wQ06dPT3/e1tZWUuG+rrp7Kn6HYA8AAJB3RW/F31RTU1Pss88+8cwzz8TIkSNj/fr1sXz58h7XLF26NN2TP3LkyF5T8gs/39o1DQ0NW/zHg7q6umhoaOjxVUo2Vuy14gMAAORdpoL9qlWr4tlnn41Ro0bFYYcdFjU1NXHXXXelzy9atCiWLFkSLS0tERHR0tISCxYsiGXLlqXXzJ49OxoaGmL8+PHpNZu+RuGawmuUo8IeexV7AACA/CtqsP/nf/7nmDNnTvzhD3+IBx54IP72b/82qqqq4qMf/Wg0NjbG6aefHtOnT49f/epXMW/evPjkJz8ZLS0tccQRR0RExAknnBDjx4+PT3ziE/G73/0u7rjjjrjwwgtj6tSpUVdXFxERZ511Vjz33HNx3nnnxZNPPhnXXHNN3HjjjTFt2rRifvSiqqtWsQcAACgVRd1j/6c//Sk++tGPxquvvhrDhw+Po446Kh588MEYPnx4RER8/etfj8rKyjjppJNi3bp1MWnSpLjmmmvS76+qqopbb701PvOZz0RLS0vssssucdppp8Ull1ySXjN27NiYNWtWTJs2La688srYfffd43vf+17ZHnUXEVGnYg8AAFAyKpIkSYq9iKxra2uLxsbGWLFiRUnst3/g2VfiY999KMaNGBS/nH5ssZcDAADAn9mWHJqpPfbsHBvPsVexBwAAyDvBvgwNKBx3Z489AABA7gn2Zaiu+7i7te0q9gAAAHkn2Jehja34KvYAAAB5J9iXoQHdx92t7+iKri6zEwEAAPJMsC9DhePuIlTtAQAA8k6wL0OFin2EyfgAAAB5J9iXoeqqyqiurIgIk/EBAADyTrAvU3XdVXsVewAAgHwT7MtUYTK+ij0AAEC+CfZlqlCxd5Y9AABAvgn2ZcpZ9gAAAKVBsC9TdWkrvoo9AABAngn2ZUorPgAAQGkQ7MvUgJrCVHyt+AAAAHkm2JepAVrxAQAASoJgX6Y2nmOvYg8AAJBngn2ZUrEHAAAoDYJ9mVKxBwAAKA2CfZlKz7FXsQcAAMg1wb5Mpa34KvYAAAC5JtiXKefYAwAAlAbBvkxtbMVXsQcAAMgzwb5MpRX7DhV7AACAPBPsy1Sdij0AAEBJEOzLlIo9AABAaRDsy1Qh2K83FR8AACDXBPsyJdgDAACUBsG+TNUWgn2nYA8AAJBngn2Zqq3aMDxPxR4AACDfBPsyVasVHwAAoCQI9mWqEOzXCfYAAAC5JtiXqTrBHgAAoCQI9mVqYyu+c+wBAADyTLAvU7VVpuIDAACUAsG+TG3aip8kSZFXAwAAwPYS7MtUoRU/SSI6ugR7AACAvBLsy1RddVX6Y0feAQAA5JdgX6YKFfsIwR4AACDPBPsyVVVZEVWVFRFhgB4AAECeCfZlrDAZf127YA8AAJBXgn0Zq6spHHnnLHsAAIC8EuzLWFqxt8ceAAAgtwT7MlYYoGd4HgAAQH4J9mVMsAcAAMg/wb6MacUHAADIP8G+jNXVVEWEij0AAECeCfZlrK6qMBVfsAcAAMgrwb6M2WMPAACQf4J9GRPsAQAA8k+wL2Mbh+d1FnklAAAAbC/BvozV1ZiKDwAAkHeCfRmrNTwPAAAg9wT7MmaPPQAAQP4J9mVMsAcAAMg/wb6MFYK9PfYAAAD5JdiXsbrqqohQsQcAAMgzwb6M1WnFBwAAyD3BvoyZig8AAJB/gn0ZMzwPAAAg/wT7MrZxeF5nkVcCAADA9hLsy1idqfgAAAC5J9iXMa34AAAA+SfYlzHD8wAAAPJPsC9jKvYAAAD5J9iXsVp77AEAAHJPsC9jddVVEaFiDwAAkGeCfRmr04oPAACQe4J9GavpHp7XbngeAABAbgn2ZSwdnifYAwAA5JZgX8ZqqioiQsUeAAAgzwT7MlabtuInRV4JAAAA20uwL2OFPfadXUl0dgn3AAAAeSTYl7Ga6o2//drxAQAA8kmwL2OFPfYRBugBAADklWBfxmoqN6nYO8seAAAglwT7MlZZWRHVlYXJ+PbYAwAA5JFgX+YKZ9nbYw8AAJBPgn2ZK0zGt8ceAAAgnwT7MldTpWIPAACQZ4J9mavtnozf3mGPPQAAQB4J9mWucJa9VnwAAIB8EuzLXLrH3nF3AAAAuSTYlzl77AEAAPJNsC9z6R57wR4AACCXBPsy5xx7AACAfBPsy9zGc+xNxQcAAMgjwb7MpXvsDc8DAADIJcG+zBmeBwAAkG+CfZmrrd4wPM859gAAAPkk2Jc559gDAADkm2Bf5ja24hueBwAAkEeCfZmzxx4AACDfBPsyV+ccewAAgFwT7MtcTZXheQAAAHkm2Je5jefY22MPAACQR4J9mbPHHgAAIN8E+zJXW+24OwAAgDwT7MtcYY+9ij0AAEA+CfZlrtCKb3geAABAPgn2Zc4eewAAgHwT7MtcbXqOvan4AAAAeSTYl7laFXsAAIBcE+zLXLrH3lR8AACAXBLsy5yp+AAAAPkm2Je5mmpT8QEAAPJMsC9z6R77DsPzAAAA8kiwL3OOuwMAAMg3wb7MFfbYa8UHAADIJ8G+zG08x16wBwAAyCPBvsxtPMfeHnsAAIA8EuzLXLrH3jn2AAAAuSTYlznH3QEAAOSbYF/mNh2elyTa8QEAAPJGsC9zhT32SRLR2SXYAwAA5I1gX+YKe+wjDNADAADII8G+zG0a7O2zBwAAyB/BvswV9thHOMseAAAgjwT7MldRUbHJWfaCPQAAQN4I9qRV+/YOe+wBAADyRrDHWfYAAAA5JtiTDtBb3yHYAwAA5I1gT9RUbmjF7+gS7AEAAPJGsCdtxTc8DwAAIH8Ee6K6u2Lf3ml4HgAAQN4I9qR77DsEewAAgNwR7InqwnF39tgDAADkjmBPWrFvNxUfAAAgdwR7oqayuxW/Sys+AABA3gj2bGzFNxUfAAAgdzIT7C+99NKoqKiIc845J31s7dq1MXXq1Bg6dGgMGjQoTjrppFi6dGmP71uyZElMnjw5Bg4cGCNGjIhzzz03Ojo6elxzzz33xKGHHhp1dXUxbty4mDlz5k74RPlRbXgeAABAbmUi2D/yyCPx7W9/Ow466KAej0+bNi1+/vOfx0033RRz5syJF198MU488cT0+c7Ozpg8eXKsX78+Hnjggbj++utj5syZcdFFF6XXLF68OCZPnhzHHXdczJ8/P84555w444wz4o477thpny/ralXsAQAAcqvowX7VqlUxZcqU+O53vxu77rpr+viKFSviP//zP+NrX/tavOc974nDDjssvv/978cDDzwQDz74YERE3HnnnfH444/H//zP/8QhhxwS73//++MrX/lKXH311bF+/fqIiLjuuuti7NixccUVV8T+++8fZ599dnz4wx+Or3/961tc07p166Ktra3HVymr7t5j326PPQAAQO4UPdhPnTo1Jk+eHBMnTuzx+Lx586K9vb3H4/vtt1/sscceMXfu3IiImDt3bhx44IHR3NycXjNp0qRoa2uLhQsXptf8+WtPmjQpfY3NmTFjRjQ2NqZfY8aM+Ys/Z5YV9th3qNgDAADkTlGD/Q033BC/+c1vYsaMGb2ea21tjdra2mhqaurxeHNzc7S2tqbXbBrqC88Xnuvrmra2tlizZs1m13XBBRfEihUr0q/nn39+uz5fXtQWjrsT7AEAAHKnulhv/Pzzz8fnPve5mD17dgwYMKBYy9isurq6qKurK/YydpqNU/G14gMAAORN0Sr28+bNi2XLlsWhhx4a1dXVUV1dHXPmzImrrroqqquro7m5OdavXx/Lly/v8X1Lly6NkSNHRkTEyJEje03JL/x8a9c0NDREfX39m/Tp8sVUfAAAgPwqWrA//vjjY8GCBTF//vz06/DDD48pU6akP66pqYm77ror/Z5FixbFkiVLoqWlJSIiWlpaYsGCBbFs2bL0mtmzZ0dDQ0OMHz8+vWbT1yhcU3gNImoqu/fYd2nFBwAAyJuiteIPHjw43va2t/V4bJdddomhQ4emj59++ukxffr0GDJkSDQ0NMQ//dM/RUtLSxxxxBEREXHCCSfE+PHj4xOf+ERcdtll0draGhdeeGFMnTo1baU/66yz4lvf+lacd9558alPfSruvvvuuPHGG2PWrFk79wNnWE13xX69PfYAAAC5U7Rg3x9f//rXo7KyMk466aRYt25dTJo0Ka655pr0+aqqqrj11lvjM5/5TLS0tMQuu+wSp512WlxyySXpNWPHjo1Zs2bFtGnT4sorr4zdd989vve978WkSZOK8ZEySSs+AABAflUkSSLNbUVbW1s0NjbGihUroqGhodjL2eGuuHNRfPPuZ+K0lj3jX//mbVv/BgAAAN5U25JDi36OPcVXaMVv7/JvPAAAAHkj2LPxuLsOe+wBAADyRrAnaiq799ir2AMAAOSOYM/Gir2p+AAAALkj2LNxj71gDwAAkDuCPVHTXbF33B0AAED+CPZEdaWp+AAAAHkl2JPuse/Qig8AAJA7gj1Ra489AABAbgn2RHUa7LXiAwAA5I1gz8ZW/C4VewAAgLwR7NnYit+hYg8AAJA3gj1RXbmhYt+uYg8AAJA7gj3pHnvn2AMAAOSPYE/UOO4OAAAgtwR7oqa7Yr9exR4AACB3BHs2VuztsQcAAMgdwZ6orrTHHgAAIK8Ee6Kmuvu4O3vsAQAAckewJ2oKx90J9gAAALkj2JMed9eVRHR1accHAADIE8GeqO4enhcR0W6AHgAAQK4I9kRt1cbboN0APQAAgFwR7Inqyo0V+w777AEAAHJFsCeqNgn2KvYAAAD5ItgTFRUVUdO9z77DHnsAAIBcEeyJiIia7n327R0q9gAAAHki2BMRG/fZm4oPAACQL4I9EbGxYt9hjz0AAECuCPZExCat+KbiAwAA5IpgT0REVHcPzxPsAQAA8kWwJyI2acXv0ooPAACQJ4I9EbHJ8DwVewAAgFwR7ImITffYq9gDAADkiWBPRETUdO+x71CxBwAAyBXBnoiIqFaxBwAAyCXBnojYuMe+o0vFHgAAIE8EeyIiorbaOfYAAAB5JNgTEZtOxdeKDwAAkCeCPRGxcY99h2APAACQK4I9ERFRW6UVHwAAII8EeyIiorqq0Iov2AMAAOSJYE9ERFRXdrfid2nFBwAAyBPBnoiIqOmu2Heo2AMAAOSKYE9ERNR077Ffb3geAABArgj2RMTGPfYq9gAAAPki2BMRGyv29tgDAADki2BPRGzcY28qPgAAQL4I9kTExqn4gj0AAEC+CPZExKZT8bXiAwAA5IlgT0REVFcVKvaCPQAAQJ4I9kTExuF5WvEBAADyRbAnIja24neaig8AAJArgj0REVFVaSo+AABAHgn2RERETaVz7AEAAPJIsCciIqqdYw8AAJBLgj0RsXEqvj32AAAA+SLYExER1ZXOsQcAAMgjwZ6I2Bjs27u04gMAAOSJYE9EbDzHXsUeAAAgXwR7ImLj8DxT8QEAAPJFsCciNp5j32EqPgAAQK4I9kTEJq34KvYAAAC5ItgTEZsMz1OxBwAAyBXBnojYWLF3jj0AAEC+CPZExMY99u2m4gMAAOSKYE9ERNSkU/G14gMAAOSJYE9ERFRXOsceAAAgjwR7ImLTc+xV7AEAAPJEsCciVOwBAADySrAnIjat2CeRJMI9AABAXgj2RERETeXGW6HDkXcAAAC5IdgTERsr9hHOsgcAAMgTwZ6I2HiOfUREe6cBegAAAHkh2BMRETVVm7TiG6AHAACQG4I9EbGhYl/RXbRvd+QdAABAbgj2pAoD9OyxBwAAyA/BnlRhn71WfAAAgPwQ7EkVJuMbngcAAJAfgj2pwgA959gDAADkh2BPqlorPgAAQO4I9qTSYG8qPgAAQG4I9qSqu1vx21XsAQAAckOwJ1UYntdheB4AAEBuCPakCufYG54HAACQH4I9qfQce8EeAAAgNwR7UjVa8QEAAHJHsCdleB4AAED+CPakHHcHAACQP4I9qcJU/E577AEAAHJDsCdVXakVHwAAIG8Ee1KG5wEAAOSPYE8qrdhrxQcAAMgNwZ5UVWGPvYo9AABAbgj2pGrSqfgq9gAAAHkh2JNyjj0AAED+CPakDM8DAADIH8GeVJVWfAAAgNwR7EkVpuJ3dKnYAwAA5IVgT2pjK76KPQAAQF4I9qQMzwMAAMgfwZ5Udfce+06t+AAAALkh2JMq7LFvNzwPAAAgNwR7UtWOuwMAAMgdwZ6U4XkAAAD5I9iTqkqPuxPsAQAA8kKwJ5VW7A3PAwAAyA3BnlQ6PE8rPgAAQG4I9qQMzwMAAMgfwZ5U4Rx7e+wBAADyQ7AnVV3VPTxPKz4AAEBuCPakaioNzwMAAMgbwZ5UoWJveB4AAEB+CPakCnvsO+2xBwAAyA3BnlRhKn67qfgAAAC5IdiTKpxjbyo+AABAfgj2pGqcYw8AAJA7gj2pKufYAwAA5I5gT6rGOfYAAAC5I9iTKgzPc449AABAfgj2pArD85xjDwAAkB+CPSnn2AMAAOSPYE/KOfYAAAD5I9iTSofnqdgDAADkhmBPatNW/CQR7gEAAPJgu4L99ddfH7NmzUp/ft5550VTU1O8613vij/+8Y87bHHsXIXheRGq9gAAAHmxXcH+q1/9atTX10dExNy5c+Pqq6+Oyy67LIYNGxbTpk3boQtk5ynssY9wlj0AAEBeVG/PNz3//PMxbty4iIi45ZZb4qSTToozzzwzjjzyyHj3u9+9I9fHTrRpsG/v6or6qCriagAAAOiP7arYDxo0KF599dWIiLjzzjvjve99b0REDBgwINasWbPjVsdOVbNpK76KPQAAQC5sV7B/73vfG2eccUacccYZ8dRTT8UHPvCBiIhYuHBh7LXXXv1+nWuvvTYOOuigaGhoiIaGhmhpaYnbbrstfX7t2rUxderUGDp0aAwaNChOOumkWLp0aY/XWLJkSUyePDkGDhwYI0aMiHPPPTc6Ojp6XHPPPffEoYceGnV1dTFu3LiYOXPm9nzskldZWREV3UX7ji5H3gEAAOTBdgX7q6++OlpaWuLll1+On/zkJzF06NCIiJg3b1589KMf7ffr7L777nHppZfGvHnz4tFHH433vOc98Td/8zexcOHCiIiYNm1a/PznP4+bbrop5syZEy+++GKceOKJ6fd3dnbG5MmTY/369fHAAw/E9ddfHzNnzoyLLroovWbx4sUxefLkOO6442L+/PlxzjnnxBlnnBF33HHH9nz0kleo2qvYAwAA5ENFkrFzzYYMGRKXX355fPjDH47hw4fHD3/4w/jwhz8cERFPPvlk7L///jF37tw44ogj4rbbbosPfvCD8eKLL0Zzc3NERFx33XVx/vnnx8svvxy1tbVx/vnnx6xZs+Kxxx5L3+OUU06J5cuXx+23396vNbW1tUVjY2OsWLEiGhoadvyHzpDxF90eq9d3xr3nHhd7DB1Y7OUAAACUpW3JodtVsb/99tvjvvvuS39+9dVXxyGHHBIf+9jH4vXXX9+el4zOzs644YYb4o033oiWlpaYN29etLe3x8SJE9Nr9ttvv9hjjz1i7ty5EbFhIv+BBx6YhvqIiEmTJkVbW1ta9Z87d26P1yhcU3iNzVm3bl20tbX1+CoXhbPs27XiAwAA5MJ2Bftzzz03DbsLFiyIz3/+8/GBD3wgFi9eHNOnT9+m11qwYEEMGjQo6urq4qyzzoqbb745xo8fH62trVFbWxtNTU09rm9ubo7W1taIiGhtbe0R6gvPF57r65q2trYtDvqbMWNGNDY2pl9jxozZps+UZ9VVG26JTufYAwAA5MJ2HXe3ePHiGD9+fERE/OQnP4kPfvCD8dWvfjV+85vfpIP0+mvfffeN+fPnx4oVK+LHP/5xnHbaaTFnzpztWdYOc8EFF/T4B4q2trayCfdpxb5TxR4AACAPtivY19bWxurVqyMi4pe//GWceuqpEbFhf/y2tq3X1tbGuHHjIiLisMMOi0ceeSSuvPLKOPnkk2P9+vWxfPnyHlX7pUuXxsiRIyMiYuTIkfHwww/3eL3C1PxNr/nzSfpLly6NhoaGqK+v3+ya6urqoq6ubps+R6moqTI8DwAAIE+2qxX/qKOOiunTp8dXvvKVePjhh2Py5MkREfHUU0/F7rvv/hctqKurK9atWxeHHXZY1NTUxF133ZU+t2jRoliyZEm0tLRERERLS0ssWLAgli1bll4ze/bsaGhoSDsKWlpaerxG4ZrCa9BTddWGir3j7gAAAPJhu4L9t771raiuro4f//jHce2118Zuu+0WERG33XZbvO997+v361xwwQVx7733xh/+8IdYsGBBXHDBBXHPPffElClTorGxMU4//fSYPn16/OpXv4p58+bFJz/5yWhpaYkjjjgiIiJOOOGEGD9+fHziE5+I3/3ud3HHHXfEhRdeGFOnTk0r7meddVY899xzcd5558WTTz4Z11xzTdx4440xbdq07fnoJa+quxVfxR4AACAftqsVf4899ohbb7211+Nf//rXt+l1li1bFqeeemq89NJL0djYGAcddFDccccd8d73vjd9vcrKyjjppJNi3bp1MWnSpLjmmmvS76+qqopbb701PvOZz0RLS0vssssucdppp8Ull1ySXjN27NiYNWtWTJs2La688srYfffd43vf+15MmjRpez56yUvPsTc8DwAAIBe2+xz7zs7OuOWWW+KJJ56IiIgDDjgg/vqv/zqqqqp26AKzoJzOsZ981a9j4YttMfOT74h37zui2MsBAAAoS9uSQ7erYv/MM8/EBz7wgXjhhRdi3333jYgNR8SNGTMmZs2aFXvvvff2vCwZUG14HgAAQK5s1x77z372s7H33nvH888/H7/5zW/iN7/5TSxZsiTGjh0bn/3sZ3f0GtmJCsfdacUHAADIh+2q2M+ZMycefPDBGDJkSPrY0KFD49JLL40jjzxyhy2OnW9jsDcVHwAAIA+2q2JfV1cXK1eu7PX4qlWrora29i9eFMXjHHsAAIB82a5g/8EPfjDOPPPMeOihhyJJkkiSJB588ME466yz4q//+q939BrZiQrn2Ld3qtgDAADkwXYF+6uuuir23nvvaGlpiQEDBsSAAQPiXe96V4wbNy6+8Y1v7OAlsjMVWvE77bEHAADIhe3aY9/U1BQ//elP45lnnkmPu9t///1j3LhxO3Rx7HzV3efYtwv2AAAAudDvYD99+vQ+n//Vr36V/vhrX/va9q+Ioiq04ndoxQcAAMiFfgf73/72t/26rqKiYrsXQ/EZngcAAJAv/Q72m1bkKV1VzrEHAADIle0ankfpqtGKDwAAkCuCPT0YngcAAJAvgj09GJ4HAACQL4I9PTjHHgAAIF8Ee3qo7p6K324qPgAAQC4I9vRQk07F14oPAACQB4I9PRQq9o67AwAAyAfBnh7Sc+wNzwMAAMgFwZ4eNp5jr2IPAACQB4I9PRTOsdeKDwAAkA+CPT2k59gbngcAAJALgj09FCr2jrsDAADIB8GeHgoV+06t+AAAALkg2NNDdfdU/HZT8QEAAHJBsKeH9Bx7rfgAAAC5INjTQ02l4XkAAAB5ItjTQ1Ua7FXsAQAA8kCwp4carfgAAAC5ItjTQ2EqvuF5AAAA+SDY00OhFd9xdwAAAPkg2NND2oov2AMAAOSCYE8PzrEHAADIF8GeHqorN9wSWvEBAADyQbCnh43D8wR7AACAPBDs6aGmqnCOvVZ8AACAPBDs6aGq0IqvYg8AAJALgj09pMPzVOwBAAByQbCnh/S4OxV7AACAXBDs6aGqsrDHPokkEe4BAACyTrCnh8LwvAhH3gEAAOSBYE8P1VUbb4kOwR4AACDzBHt6KAzPixDsAQAA8kCwp4cewb7TZHwAAICsE+zpoWqTYN9uMj4AAEDmCfb0UFFRkQ7QMzwPAAAg+wR7eilU7du14gMAAGSeYE8vNZUbbgvD8wAAALJPsKeX6rQVX8UeAAAg6wR7eqnqrtgbngcAAJB9gj29FIbndQj2AAAAmSfY00uhFb9DKz4AAEDmCfb0Um14HgAAQG4I9vRS7bg7AACA3BDs6aW6qrtib489AABA5gn29FKo2HdqxQcAAMg8wZ5eCsPztOIDAABkn2BPLzWG5wEAAOSGYE8vVZWF4+4EewAAgKwT7OklPcdeKz4AAEDmCfb0UmMqPgAAQG4I9vSiFR8AACA/BHt6qSm04ndpxQcAAMg6wZ5eqrun4rdrxQcAAMg8wZ5eqrtb8TtV7AEAADJPsKeXwlR8FXsAAIDsE+zppdpUfAAAgNwQ7OlFKz4AAEB+CPb0kg7Pc9wdAABA5gn29JIed9epYg8AAJB1gj29VFUWzrFXsQcAAMg6wZ5eDM8DAADID8GeXmrSir1WfAAAgKwT7OlFxR4AACA/BHt6qbbHHgAAIDcEe3qp7p6K324qPgAAQOYJ9vRSaMXvVLEHAADIPMGeXgqt+O322AMAAGSeYE8v1abiAwAA5IZgTy81WvEBAAByQ7Cnl6pKw/MAAADyQrCnl5ruqfjOsQcAAMg+wZ5eqis33BbtWvEBAAAyT7Cnl6ruin2n4XkAAACZJ9jTS013xV4rPgAAQPYJ9vRSXWV4HgAAQF4I9vRSOMfecXcAAADZJ9jTS3X3OfbtWvEBAAAyT7Cnl0LFvsPwPAAAgMwT7OmlukorPgAAQF4I9vSSnmOvFR8AACDzBHt6qemu2HeYig8AAJB5gj29VKV77FXsAQAAsk6wp5ea7qn4gj0AAED2Cfb0suk59kki3AMAAGSZYE8vheF5Ear2AAAAWSfY00vhuLuIiA6T8QEAADJNsKeXTYN9e5fJ+AAAAFkm2NPLpq34nSr2AAAAmSbY00tVZUVUdBftVewBAACyTbBns2q6q/b22AMAAGSbYM9mFfbZd5qKDwAAkGmCPZtV1X2WfXunVnwAAIAsE+zZrJqq7lZ8FXsAAIBME+zZrOruir099gAAANkm2LNZabA3FR8AACDTBHs2q7q7Fb9dxR4AACDTBHs2y1R8AACAfBDs2ayNe+y14gMAAGSZYM9mVVd2t+Kr2AMAAGSaYM9m1VSp2AMAAOSBYM9mVaVT8VXsAQAAskywZ7MKU/GdYw8AAJBtgj2blbbiO8ceAAAg0wR7NquqUsUeAAAgDwR7NqumUsUeAAAgDwR7Nqu6uxW/XcUeAAAg0wR7Nqtwjn2nqfgAAACZJtizWRsr9lrxAQAAskywZ7MKFXvn2AMAAGSbYM9mVXcPz9OKDwAAkG2CPZulFR8AACAfBHs2q6bKOfYAAAB5INizWVXpOfaCPQAAQJYJ9mxWoRW/Qys+AABApgn2bFaNqfgAAAC5INizWRtb8VXsAQAAskywZ7Nq0lZ8FXsAAIAsE+zZrOruqfjtgj0AAECmCfZsVnV3K36nVnwAAIBMK2qwnzFjRrzjHe+IwYMHx4gRI+JDH/pQLFq0qMc1a9eujalTp8bQoUNj0KBBcdJJJ8XSpUt7XLNkyZKYPHlyDBw4MEaMGBHnnntudHR09LjmnnvuiUMPPTTq6upi3LhxMXPmzDf74+VaIdi3G54HAACQaUUN9nPmzImpU6fGgw8+GLNnz4729vY44YQT4o033kivmTZtWvz85z+Pm266KebMmRMvvvhinHjiienznZ2dMXny5Fi/fn088MADcf3118fMmTPjoosuSq9ZvHhxTJ48OY477riYP39+nHPOOXHGGWfEHXfcsVM/b54UWvEddwcAAJBtFUmSZKYk+/LLL8eIESNizpw5ccwxx8SKFSti+PDh8cMf/jA+/OEPR0TEk08+Gfvvv3/MnTs3jjjiiLjtttvigx/8YLz44ovR3NwcERHXXXddnH/++fHyyy9HbW1tnH/++TFr1qx47LHH0vc65ZRTYvny5XH77bdvdV1tbW3R2NgYK1asiIaGhjfnw2fMjx5ZEuf/ZEFM3H9EfO+0dxR7OQAAAGVlW3JopvbYr1ixIiIihgwZEhER8+bNi/b29pg4cWJ6zX777Rd77LFHzJ07NyIi5s6dGwceeGAa6iMiJk2aFG1tbbFw4cL0mk1fo3BN4TX+3Lp166Ktra3HV7mpqjQ8DwAAIA8yE+y7urrinHPOiSOPPDLe9ra3RUREa2tr1NbWRlNTU49rm5ubo7W1Nb1m01BfeL7wXF/XtLW1xZo1a3qtZcaMGdHY2Jh+jRkzZod8xjxJj7szPA8AACDTMhPsp06dGo899ljccMMNxV5KXHDBBbFixYr06/nnny/2kna66srCHnsVewAAgCyrLvYCIiLOPvvsuPXWW+Pee++N3XffPX185MiRsX79+li+fHmPqv3SpUtj5MiR6TUPP/xwj9crTM3f9Jo/n6S/dOnSaGhoiPr6+l7rqauri7q6uh3y2fKqqrJQsRfsAQAAsqyoFfskSeLss8+Om2++Oe6+++4YO3Zsj+cPO+ywqKmpibvuuit9bNGiRbFkyZJoaWmJiIiWlpZYsGBBLFu2LL1m9uzZ0dDQEOPHj0+v2fQ1CtcUXoPe0lZ8U/EBAAAyragV+6lTp8YPf/jD+OlPfxqDBw9O98Q3NjZGfX19NDY2xumnnx7Tp0+PIUOGRENDQ/zTP/1TtLS0xBFHHBERESeccEKMHz8+PvGJT8Rll10Wra2tceGFF8bUqVPTqvtZZ50V3/rWt+K8886LT33qU3H33XfHjTfeGLNmzSraZ8+6wnF3hucBAABkW1Er9tdee22sWLEi3v3ud8eoUaPSrx/96EfpNV//+tfjgx/8YJx00klxzDHHxMiRI+P//u//0uerqqri1ltvjaqqqmhpaYmPf/zjceqpp8Yll1ySXjN27NiYNWtWzJ49Ow4++OC44oor4nvf+15MmjRpp37ePKnubsXv1IoPAACQaZk6xz6ryvEc+4eeezVO/s6D8Zbhu8Tdn393sZcDAABQVnJ7jj3ZUWjFNxUfAAAg2wR7NksrPgAAQD4I9mxWdfdU/HZT8QEAADJNsGezagqt+Cr2AAAAmSbYs1lVlc6xBwAAyAPBns2qqVSxBwAAyAPBns0q7LE3FR8AACDbBHs2qzAVv6NLKz4AAECWCfZsVuEc+64koks7PgAAQGYJ9mxWoRU/IqJd1R4AACCzBHs2q9CKHxHRqWIPAACQWYI9m1VdufHWaDdADwAAILMEezZr04q9s+wBAACyS7BnsyorK6KQ7bXiAwAAZJdgzxYVJuO3C/YAAACZJdizRTWFs+y14gMAAGSWYM8WFSr2HSr2AAAAmSXYs0XVacVesAcAAMgqwZ4tqq7aEOzbteIDAABklmDPFhXOsjcVHwAAILsEe7aoULHv6FKxBwAAyCrBni0q7LFvt8ceAAAgswR7tqimSis+AABA1gn2bFFVpeF5AAAAWSfYs0XpOfZa8QEAADJLsGeLagrn2GvFBwAAyCzBni2qqjQVHwAAIOsEe7aoRis+AABA5gn2bFHhHHvD8wAAALJLsGeLCufYO+4OAAAguwR7tqi6csPt0S7YAwAAZJZgzxYVWvE7tOIDAABklmDPFmnFBwAAyD7Bni2q7p6K324qPgAAQGYJ9mxRjVZ8AACAzBPs2aKq7lb8Dq34AAAAmSXYs0WFqfgdXSr2AAAAWSXYs0UbW/FV7AEAALJKsGeLqtKKvWAPAACQVYI9W2R4HgAAQPYJ9mxRYY99u4o9AABAZgn2bFF1d8W+0x57AACAzBLs2aLq7uPu2k3FBwAAyCzBni2qruoenqdiDwAAkFmCPVtUGJ7XaY89AABAZgn2bFFVoRXfVHwAAIDMEuzZohrn2AMAAGSeYM8WFabiC/YAAADZJdizRYVW/A6t+AAAAJkl2LNFNabiAwAAZJ5gzxYVzrHvcI49AABAZgn2bJE99gAAANkn2LNF1d1T8du14gMAAGSWYM8WFSr2nVrxAQAAMkuwZ4sKFXvD8wAAALJLsGeLChX7dhV7AACAzBLs2aIaFXsAAIDME+zZoqpKU/EBAACyTrBni2oKx911asUHAADIKsGeLaqu0ooPAACQdYI9W1StFR8AACDzBHu2qDAVv8NUfAAAgMwS7Nmiwjn27Z1JJImqPQAAQBYJ9mxRoRU/IkI3PgAAQDYJ9mxRoRU/IqLdZHwAAIBMEuzZopqqjbeHAXoAAADZJNizRVWbtOJ3OvIOAAAgkwR7tmjTPfbtJuMDAABkkmDPFlVUVGw8y17FHgAAIJMEe/pUaMd3lj0AAEA2Cfb0qTBAT8UeAAAgmwR7+lQ48k7FHgAAIJsEe/pUXdldsXfcHQAAQCYJ9vTJ8DwAAIBsE+zpU6EVv71TKz4AAEAWCfb0qTA8r1MrPgAAQCYJ9vSpcNxdu1Z8AACATBLs6VO1c+wBAAAyTbCnT+k59lrxAQAAMkmwp09VpuIDAABkmmBPn2qqCsFeKz4AAEAWCfb0qbpSKz4AAECWCfb0qXCOveF5AAAA2STY06dqx90BAABkmmBPn6oLU/EFewAAgEwS7OlToWLfqRUfAAAgkwR7+lSo2GvFBwAAyCbBnj7VVBqeBwAAkGWCPX2qSoO9ij0AAEAWCfb0yfA8AACAbBPs6VNN4Rz7Tq34AAAAWSTY0yet+AAAANkm2NOnmkIrvmAPAACQSYI9fSqcY9+uFR8AACCTBHv6VAj2nSr2AAAAmSTY06fCVPx2U/EBAAAySbCnT9Wm4gMAAGSaYE+ftOIDAABkm2BPn6oru1vxBXsAAIBMEuzpU41WfAAAgEwT7OlTtXPsAQAAMk2wp09VlSr2AAAAWSbY06e0FV/FHgAAIJMEe/pUGJ7X4Rx7AACATBLs6VPhuLuOLq34AAAAWSTY06fC8Lx2FXsAAIBMEuzpU3X3HvtOe+wBAAAySbCnT4VW/HZT8QEAADJJsKdP6fA8FXsAAIBMEuzpU41WfAAAgEwT7OlTlVZ8AACATBPs6VNNlXPsAQAAskywp0+FqfjOsQcAAMgmwZ4+FabiG54HAACQTYI9fUqn4mvFBwAAyCTBnj7VVG+4RQzPAwAAyCbBnj4Vjrtb39kVSaJqDwAAkDWCPX2q7Z6KnyTOsgcAAMgiwZ4+1VZvvEXa7bMHAADIHMGePhXOsY+IWN9hnz0AAEDWCPb0qXDcXcSGffYAAABki2BPnyoqKtJ2fJPxAQAAskewZ6sKA/S04gMAAGSPYM9WFY68U7EHAADIHsGerSq04ttjDwAAkD2CPVtVoxUfAAAgswR7tqqwx9459gAAANkj2LNVpuIDAABkl2DPVmnFBwAAyC7Bnq0qTMU3PA8AACB7ihrs77333virv/qrGD16dFRUVMQtt9zS4/kkSeKiiy6KUaNGRX19fUycODGefvrpHte89tprMWXKlGhoaIimpqY4/fTTY9WqVT2u+f3vfx9HH310DBgwIMaMGROXXXbZm/3RSopWfAAAgOwqarB/44034uCDD46rr756s89fdtllcdVVV8V1110XDz30UOyyyy4xadKkWLt2bXrNlClTYuHChTF79uy49dZb4957740zzzwzfb6trS1OOOGE2HPPPWPevHlx+eWXx8UXXxzf+c533vTPVyq04gMAAGRXdTHf/P3vf3+8//3v3+xzSZLEN77xjbjwwgvjb/7mbyIi4r//+7+jubk5brnlljjllFPiiSeeiNtvvz0eeeSROPzwwyMi4pvf/GZ84AMfiP/4j/+I0aNHxw9+8INYv359/Nd//VfU1tbGAQccEPPnz4+vfe1rPf4BYFPr1q2LdevWpT9va2vbwZ88XzZOxRfsAQAAsiaze+wXL14cra2tMXHixPSxxsbGmDBhQsydOzciIubOnRtNTU1pqI+ImDhxYlRWVsZDDz2UXnPMMcdEbW1tes2kSZNi0aJF8frrr2/2vWfMmBGNjY3p15gxY96Mj5gbhVb89Y67AwAAyJzMBvvW1taIiGhubu7xeHNzc/pca2trjBgxosfz1dXVMWTIkB7XbO41Nn2PP3fBBRfEihUr0q/nn3/+L/9AOaYVHwAAILuK2oqfVXV1dVFXV1fsZWRGjVZ8AACAzMpsxX7kyJEREbF06dIejy9dujR9buTIkbFs2bIez3d0dMRrr73W45rNvcam70Hf0qn4KvYAAACZk9lgP3bs2Bg5cmTcdddd6WNtbW3x0EMPRUtLS0REtLS0xPLly2PevHnpNXfffXd0dXXFhAkT0mvuvffeaG9vT6+ZPXt27LvvvrHrrrvupE+Tb7XOsQcAAMisogb7VatWxfz582P+/PkRsWFg3vz582PJkiVRUVER55xzTvzbv/1b/OxnP4sFCxbEqaeeGqNHj44PfehDERGx//77x/ve97749Kc/HQ8//HDcf//9cfbZZ8cpp5wSo0ePjoiIj33sY1FbWxunn356LFy4MH70ox/FlVdeGdOnTy/Sp86fdI+9YA8AAJA5Rd1j/+ijj8Zxxx2X/rwQtk877bSYOXNmnHfeefHGG2/EmWeeGcuXL4+jjjoqbr/99hgwYED6PT/4wQ/i7LPPjuOPPz4qKyvjpJNOiquuuip9vrGxMe68886YOnVqHHbYYTFs2LC46KKLtnjUHb1tbMU3FR8AACBrKpIkkda2oq2tLRobG2PFihXR0NBQ7OXsdF+f/VRcedfT8fEj9oh/+9CBxV4OAABAyduWHJrZPfZkh4o9AABAdgn2bFWt4+4AAAAyS7Bnq2q6p+KvE+wBAAAyR7Bnq2qcYw8AAJBZgj1bpRUfAAAguwR7tqowPM859gAAANkj2LNVNVWm4gMAAGSVYM9WFVrxVewBAACyR7BnqwrD89YbngcAAJA5gj1bVTjuzvA8AACA7BHs2aq6alPxAQAAskqwZ6sKw/O04gMAAGSPYM9WpcG+01R8AACArBHs2aparfgAAACZJdizVbVa8QEAADJLsGerCq34KvYAAADZI9izVYVW/I6uJLq67LMHAADIEsGerSoE+4iI9ar2AAAAmSLYs1V1mwT7de2CPQAAQJYI9mxVdWVFVFZs+PG6js7iLgYAAIAeBHu2qqKiIuqqqyIiYp3J+AAAAJki2NMvdTUbbhUVewAAgGwR7OmXwj77tfbYAwAAZIpgT78MqNGKDwAAkEWCPf1SqNhrxQcAAMgWwZ5+MTwPAAAgmwR7+iWt2Ler2AMAAGSJYE+/bJyKr2IPAACQJYI9/ZK24puKDwAAkCmCPf1ieB4AAEA2Cfb0y8Zgr2IPAACQJYI9/eIcewAAgGwS7OkXU/EBAACySbCnX+q6K/ZrVewBAAAyRbCnX1TsAQAAskmwp18MzwMAAMgmwZ5+Sc+xF+wBAAAyRbCnX+pqnGMPAACQRYI9/TKgULFvV7EHAADIEsGeftlYsRfsAQAAskSwp18Kw/PWmooPAACQKYI9/WJ4HgAAQDYJ9vTLxuPuVOwBAACyRLCnX+yxBwAAyCbBnn6pMxUfAAAgkwR7+iUdnqcVHwAAIFMEe/plQM2Gir2p+AAAANki2NMvA2sLwb4rurqSIq8GAACAAsGefqnvDvYREWtU7QEAADJDsKdfBlRvDPar1wv2AAAAWSHY0y+VlRVR373Pfo1gDwAAkBmCPf1W2Ge/ur2jyCsBAACgQLCn3wr77FXsAQAAskOwp98GCvYAAACZI9jTb4U99obnAQAAZIdgT7/Vp3vsBXsAAICsEOzpt4G11RERsWa94XkAAABZIdjTb2nFXis+AABAZgj29NtAe+wBAAAyR7Cn30zFBwAAyB7Bnn4bUAj2hucBAABkhmBPvw2s2TA8Tys+AABAdgj29NvGVnxT8QEAALJCsKffTMUHAADIHsGefhtojz0AAEDmCPb0WyHYv7FOKz4AAEBWCPb026C6moiIeGOdij0AAEBWCPb02+ABG6bir1zbXuSVAAAAUCDY028bg71WfAAAgKwQ7Om3wQM2tOKvWt8RXV1JkVcDAABAhGDPNihU7JNkQ7gHAACg+AR7+q2uujJqqioiQjs+AABAVgj29FtFRUXajm+AHgAAQDYI9myTQjv+KhV7AACATBDs2SYm4wMAAGSLYM82GVy3oRW/TSs+AABAJgj2bBMVewAAgGwR7NkmG4fnCfYAAABZINizTQoVe634AAAA2SDYs012HVgbERHLV68v8koAAACIEOzZRkMGbQj2r64S7AEAALJAsGebDN1lQ7B/7Q3BHgAAIAsEe7bJEMEeAAAgUwR7tkmhYv+qYA8AAJAJgj3bpFCxX7GmPdo7u4q8GgAAAAR7tknTwNqoqNjw49dNxgcAACg6wZ5tUlVZkR55ZzI+AABA8Qn2bLNh3UfevbxyXZFXAgAAgGDPNhvdVB8RES8uX1PklQAAACDYs8126w72Lwj2AAAARSfYs81GC/YAAACZIdizzXbfVSs+AABAVgj2bLNCxf5Prwv2AAAAxSbYs832HDowIja04q9Z31nk1QAAAJQ3wZ5tNnxQXQzZpTaSJOLpZSuLvRwAAICyJtizzSoqKmLf5sEREbGoVbAHAAAoJsGe7bLvyA3B/vGX2oq8EgAAgPIm2LNdDttz14iImPvsq0VeCQAAQHkT7NkuR44bFhERT7aujKVta4u8GgAAgPIl2LNdhuxSG4fu0RQRET+e96fiLgYAAKCMCfZstykT9oyIiO/9+rl4eeW6Iq8GAACgPAn2bLe/PmR07DdycLy+uj1O/vbcuG3BS/HGuo5iLwsAAKCsVCRJkhR7EVnX1tYWjY2NsWLFimhoaCj2cjLluZdXxce++1C0du+zr6yIeMvwQXHA6IYYP6ohDhjdGONHN8SQXWqLvFIAAID82JYcKtj3g2Dft9ffWB/fvve5+PnvXowXlq/Z7DUjGwbE23ZriMP2HBIT3jIkDtytMWqqNIwAAABsjmC/gwn2/bds5dpY+EJbPP5SWzz+YlssfHFF/OHV1b2uq6+pisP32jXes9+ImHTAyBjdVF+E1QIAAGSTYL+DCfZ/mVXrOuLJl9pi/vPL4+HFr8XDf3gtlq9u73HNwWOa4h+OeUu8/20jo6KiokgrBQAAyAbBfgcT7Hesrq4knl62Kn799Mtxx8LWePSPr0fhLpwwdkhcOHl8HLh7Y3EXCQAAUESC/Q4m2L+5Xl65Lv7fg3+Mb895NtZ1dEVExMeP2CMunDw+BtRUFXl1AAAAO9+25FDTyyi64YPrYvp794m7//nd8bdv3y0iIv7nwSXxd9fNjedf670/HwAAgI0EezJjt6b6+PrJh8R/f+qdsevAmljwwor44Dfvi7ufXFrspQEAAGSWYE/mHLPP8Jj12aPjkDFNsWJNe3xq5qMx4xdPxKp1HcVeGgAAQOYI9mTS6Kb6uPEfWuK0lj0jIuLb9z4Xx1z2q/j2nGdj5dr2rXw3AABA+TA8rx8MzyuuOxa2xv9325Px3CtvRETEoLrqOOUdY+KTR42N3Zrqi7w6AACAHc9U/B1MsC++js6u+L/fvhDfufe5eGbZqoiIqKqsiA8cOCqmTNgjJowdEhUVFUVeJQAAwI4h2O9ggn12dHUlMeepl+O7v34uHnj21fTxvYYOjI+8Y0x8+NDdY0TDgCKuEAAA4C8n2O9ggn02LXxxRfzPg0viZ/NfiDfWd0ZERGVFxISxQ+MDB46MSW8bGSMGC/kAAED+CPY7mGCfbW+s64hZC16KGx5eEr9Zsjx9vKIi4u1jmuLotw6PY/YZFgfv3hTVVeZFAgAA2SfY72CCfX48/9rquO2xl+IXC1pj/vPLezw3uK46jth7aLxr76HRsvfQ2GfE4KistC8fAADIHsF+BxPs8+nF5Wvi3qdejl8//Urc/+wrsXx1z2PyhuxSG0e8ZUi0vGVotOw9LPYevosBfAAAQCYI9juYYJ9/nV1JPPbCirj/2Vdi7rOvxqN/eD3WtHf2uGb44LrukD80Wt4yNPYcOlDQBwAAikKw38EE+9KzvqMrfven5TH32Vdj7rOvxrwlr8f6jq4e14xqHJCG/Ja9h8buuw4s0moBAIByI9jvYIJ96Vvb3hm/XbI85j73asx99pWY//zyaO/s+Z/GmCH10fKWofGuvYfFkeOGxfDBdUVaLQAAUOoE+x1MsC8/q9d3xLw/vr6hov/cq/H7P62Izq6e/6mMH9UQx+yzYeL+4XsOidpqE/cBAIAdQ7DfwQR7Vq3riEf+8FrMffbVuO/pV+Lxl9p6PD+wtiqOeMvQOOatw+KYfYbH2GEG8QEAANtPsN/BBHv+3Msr18V9z7wc9z71Svz66ZfjlVXrezy/+671cfRbh8ex+wyLd40bFg0Daoq0UgAAII8E+x1MsKcvXV1JPNHaFvc+9Urc+9TL8egfX+uxP7+qsiLePqYpjn7rhrb9g3ZviqpK1XwAAGDLBPsdTLBnW6xe3xEPPvdqGvSfe+WNHs83DayJI8cNi2PfOjyO3mdYjGqsL9JKAQCArBLsdzDBnr/E86+tjl8/vSHk3//sK7FybUeP5986YlD3EL7hMWHskBhQU1WklQIAAFkh2O9ggj07SkdnV/zuT8tjTnc1//d/Wh6bDtuvra6MCWOHxJHjhsUhY5ribbs1xqC66uItGAAAKArBfguuvvrquPzyy6O1tTUOPvjg+OY3vxnvfOc7t/p9gj1vluWr18f9z7wa9z71ctz79Mvx0oq1PZ6vqIjYe/igOGj3xjhot8bYb1RDjBsxKIbuUmvqPgAAlDDBfjN+9KMfxamnnhrXXXddTJgwIb7xjW/ETTfdFIsWLYoRI0b0+b2CPTtDkiTx7MurYs5Tr8TDi1+NBX9aES/+WdAvaKyvib2H7xLjRgyK3XcdGKMaB8TopvoY1TggRjXWR32tdn4AAMgzwX4zJkyYEO94xzviW9/6VkREdHV1xZgxY+Kf/umf4gtf+EKf3yvYUywvr1wXC15YHr97fkUseGFFPL1sZfzp9TWxtf9q62uqorG+JpoG1qT/u0tddQyoqYq66sqoq97wv4Wf11RXRmVFRGVFRVRWRFRUVKQ/rqyoiIr0uQ0/LoZy6U/Y2X8g7+z/B0h28ifc+Z9v5yvl/xtfvb4zvnjzgrjog+NjZMOA7X6d7f0V2t5f2u29z3//pxVx39OvxGePH7dN770t77atn2lbPsu2vPY19zwbb9+jKY5567Dtfo0doTj/zRbhPXfiJ+3sSuILP1kQ/3T8uBg7dJc+1rRlff0abemz9P09fb3X9v3abOnbbnhkSezTPDjetffQfl0fseN/Lbb2fVt/z23/NUmSiO8/8Ic4YXxz7D18y7/vWZP1Y6kF+z+zfv36GDhwYPz4xz+OD33oQ+njp512Wixfvjx++tOf9rh+3bp1sW7duvTnbW1tMWbMGMGeTFjb3hnPvfxGPPvyqnj25VXx4vI18dKKtRu+lq+JN9Z3FnuJAACQeXecc0zsO3JwsZexRdsS7MtiKtcrr7wSnZ2d0dzc3OPx5ubmePLJJ3tdP2PGjPjXf/3XnbU82CYDaqpi/OiGGD+693/cSZLEynUdsWJ1eyxf3R7L16zf8L+r18fq9Z2xtr0r1nV0xrqO7v9t74p1HV2xvqMrkkiiK9nwGl3Jhn9x70qSSJKIrmTDj7u6ivCBY+dXeXu8dxI7vUuhYmf3J5T225X+718U4TPupPf70+tr4o+vro6IiMP33PUvet/t/n3Zid/20OLXIiJi/KiGGFhbtU2fd5s+3zYublsu78+au5KIh7s/6zv22rXHc2/2n7lv6n+fb9JLv5n/ub0Zv9Ztazri8ZfaIqLv/263+HvRx5q29NS2vscWr/8LXydJIu575pWI2LZ7e2f8WvT1Ptv667G511q9viN+s2R5RGz4fc+L+hI6jaosgv22uuCCC2L69OnpzwsVe8i6ioqKaBhQEw0DamLMkGKvBgAA2BnKItgPGzYsqqqqYunSpT0eX7p0aYwcObLX9XV1dVFXV7ezlgcAAADbrbLYC9gZamtr47DDDou77rorfayrqyvuuuuuaGlpKeLKAAAA4C9TFhX7iIjp06fHaaedFocffni8853vjG984xvxxhtvxCc/+cliLw0AAAC2W9kE+5NPPjlefvnluOiii6K1tTUOOeSQuP3223sN1AMAAIA8KYvj7v5SzrEHAABgZ9qWHFoWe+wBAACgVAn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGOCPQAAAOSYYA8AAAA5JtgDAABAjgn2AAAAkGPVxV5AHiRJEhERbW1tRV4JAAAA5aCQPwt5tC+CfT+sXLkyIiLGjBlT5JUAAABQTlauXBmNjY19XlOR9Cf+l7murq548cUXY/DgwVFRUVHs5fSpra0txowZE88//3w0NDQUeznkgHuGbeF+YVu5Z9hW7hm2lXuGbZWXeyZJkli5cmWMHj06Kiv73kWvYt8PlZWVsfvuuxd7GdukoaEh0zcp2eOeYVu4X9hW7hm2lXuGbeWeYVvl4Z7ZWqW+wPA8AAAAyDHBHgAAAHJMsC8xdXV18eUvfznq6uqKvRRywj3DtnC/sK3cM2wr9wzbyj3DtirFe8bwPAAAAMgxFXsAAADIMcEeAAAAckywBwAAgBwT7AEAACDHBPsScvXVV8dee+0VAwYMiAkTJsTDDz9c7CXxJrj33nvjr/7qr2L06NFRUVERt9xyS4/nkySJiy66KEaNGhX19fUxceLEePrpp3tc89prr8WUKVOioaEhmpqa4vTTT49Vq1b1uOb3v/99HH300TFgwIAYM2ZMXHbZZb3WctNNN8V+++0XAwYMiAMPPDB+8Ytf7PDPy19uxowZ8Y53vCMGDx4cI0aMiA996EOxaNGiHtesXbs2pk6dGkOHDo1BgwbFSSedFEuXLu1xzZIlS2Ly5MkxcODAGDFiRJx77rnR0dHR45p77rknDj300Kirq4tx48bFzJkze63Hn1XZd+2118ZBBx0UDQ0N0dDQEC0tLXHbbbelz7tf6Mull14aFRUVcc4556SPuWfY1MUXXxwVFRU9vvbbb7/0efcLm/PCCy/Exz/+8Rg6dGjU19fHgQceGI8++mj6fNn/HTihJNxwww1JbW1t8l//9V/JwoULk09/+tNJU1NTsnTp0mIvjR3sF7/4RfKlL30p+b//+78kIpKbb765x/OXXnpp0tjYmNxyyy3J7373u+Sv//qvk7FjxyZr1qxJr3nf+96XHHzwwcmDDz6Y/PrXv07GjRuXfPSjH02fX7FiRdLc3JxMmTIleeyxx5L//d//Terr65Nvf/vb6TX3339/UlVVlVx22WXJ448/nlx44YVJTU1NsmDBgjf914BtM2nSpOT73/9+8thjjyXz589PPvCBDyR77LFHsmrVqvSas846KxkzZkxy1113JY8++mhyxBFHJO9617vS5zs6OpK3ve1tycSJE5Pf/va3yS9+8Ytk2LBhyQUXXJBe89xzzyUDBw5Mpk+fnjz++OPJN7/5zaSqqiq5/fbb02v8WZUPP/vZz5JZs2YlTz31VLJo0aLki1/8YlJTU5M89thjSZK4X9iyhx9+ONlrr72Sgw46KPnc5z6XPu6eYVNf/vKXkwMOOCB56aWX0q+XX345fd79wp977bXXkj333DP5+7//++Shhx5KnnvuueSOO+5InnnmmfSacv87sGBfIt75zncmU6dOTX/e2dmZjB49OpkxY0YRV8Wb7c+DfVdXVzJy5Mjk8ssvTx9bvnx5UldXl/zv//5vkiRJ8vjjjycRkTzyyCPpNbfddltSUVGRvPDCC0mSJMk111yT7Lrrrsm6devSa84///xk3333TX/+kY98JJk8eXKP9UyYMCH5h3/4hx36Gdnxli1blkREMmfOnCRJNtwjNTU1yU033ZRe88QTTyQRkcydOzdJkg3/oFRZWZm0tram11x77bVJQ0NDep+cd955yQEHHNDjvU4++eRk0qRJ6c/9WZVfu+66a/K9733P/cIWrVy5MnnrW9+azJ49Ozn22GPTYO+e4c99+ctfTg4++ODNPud+YXPOP//85Kijjtri8/4OnCRa8UvA+vXrY968eTFx4sT0scrKypg4cWLMnTu3iCtjZ1u8eHG0trb2uBcaGxtjwoQJ6b0wd+7caGpqisMPPzy9ZuLEiVFZWRkPPfRQes0xxxwTtbW16TWTJk2KRYsWxeuvv55es+n7FK5xz2XfihUrIiJiyJAhERExb968aG9v7/H7ud9++8Uee+zR47458MADo7m5Ob1m0qRJ0dbWFgsXLkyv6eue8GdVPnV2dsYNN9wQb7zxRrS0tLhf2KKpU6fG5MmTe/2+umfYnKeffjpGjx4db3nLW2LKlCmxZMmSiHC/sHk/+9nP4vDDD4+/+7u/ixEjRsTb3/72+O53v5s+7+/A9tiXhFdeeSU6Ozt7/OEWEdHc3Bytra1FWhXFUPj97uteaG1tjREjRvR4vrq6OoYMGdLjms29xqbvsaVr3HPZ1tXVFeecc04ceeSR8ba3vS0iNvxe1tbWRlNTU49r//y+2d57oq2tLdasWePPqpxZsGBBDBo0KOrq6uKss86Km2++OcaPH+9+YbNuuOGG+M1vfhMzZszo9Zx7hj83YcKEmDlzZtx+++1x7bXXxuLFi+Poo4+OlStXul/YrOeeey6uvfbaeOtb3xp33HFHfOYzn4nPfvazcf3110eEvwNHRFQX9d0B2KmmTp0ajz32WNx3333FXgoZt++++8b8+fNjxYoV8eMf/zhOO+20mDNnTrGXRQY9//zz8bnPfS5mz54dAwYMKPZyyIH3v//96Y8POuigmDBhQuy5555x4403Rn19fRFXRlZ1dXXF4YcfHl/96lcjIuLtb397PPbYY3HdddfFaaedVuTVZYOKfQkYNmxYVFVV9ZoWunTp0hg5cmSRVkUxFH6/+7oXRo4cGcuWLevxfEdHR7z22ms9rtnca2z6Hlu6xj2XXWeffXbceuut8atf/Sp233339PGRI0fG+vXrY/ny5T2u//P7ZnvviYaGhqivr/dnVc7U1tbGuHHj4rDDDosZM2bEwQcfHFdeeaX7hV7mzZsXy5Yti0MPPTSqq6ujuro65syZE1dddVVUV1dHc3Oze4Y+NTU1xT777BPPPPOMP2PYrFGjRsX48eN7PLb//vunWzj8HViwLwm1tbVx2GGHxV133ZU+1tXVFXfddVe0tLQUcWXsbGPHjo2RI0f2uBfa2trioYceSu+FlpaWWL58ecybNy+95u67746urq6YMGFCes29994b7e3t6TWzZ8+OfffdN3bdddf0mk3fp3CNey57kiSJs88+O26++ea4++67Y+zYsT2eP+yww6KmpqbH7+eiRYtiyZIlPe6bBQsW9Pg/xNmzZ0dDQ0P6f7Rbuyf8WZVvXV1dsW7dOvcLvRx//PGxYMGCmD9/fvp1+OGHx5QpU9Ifu2foy6pVq+LZZ5+NUaNG+TOGzTryyCN7HdX71FNPxZ577hkR/g4cEY67KxU33HBDUldXl8ycOTN5/PHHkzPPPDNpamrqMS2U0rBy5crkt7/9bfLb3/42iYjka1/7WvLb3/42+eMf/5gkyYajPpqampKf/vSnye9///vkb/7mbzZ71Mfb3/725KGHHkruu+++5K1vfWuPoz6WL1+eNDc3J5/4xCeSxx57LLnhhhuSgQMH9jrqo7q6OvmP//iP5Iknnki+/OUvZ+KoD3r7zGc+kzQ2Nib33HNPj6OFVq9enV5z1llnJXvssUdy9913J48++mjS0tKStLS0pM8XjhY64YQTkvnz5ye33357Mnz48M0eLXTuuecmTzzxRHL11Vdv9mghf1Zl3xe+8IVkzpw5yeLFi5Pf//73yRe+8IWkoqIiufPOO5Mkcb+wdZtOxU8S9ww9ff7zn0/uueeeZPHixcn999+fTJw4MRk2bFiybNmyJEncL/T28MMPJ9XV1cm///u/J08//XTygx/8IBk4cGDyP//zP+k15f53YMG+hHzzm99M9thjj6S2tjZ55zvfmTz44IPFXhJvgl/96ldJRPT6Ou2005Ik2XDcx7/8y78kzc3NSV1dXXL88ccnixYt6vEar776avLRj340GTRoUNLQ0JB88pOfTFauXNnjmt/97nfJUUcdldTV1SW77bZbcumll/Zay4033pjss88+SW1tbXLAAQcks2bNetM+N9tvc/dLRCTf//7302vWrFmT/OM//mOy6667JgMHDkz+9m//NnnppZd6vM4f/vCH5P3vf39SX1+fDBs2LPn85z+ftLe397jmV7/6VXLIIYcktbW1yVve8pYe71Hgz6rs+9SnPpXsueeeSW1tbTJ8+PDk+OOPT0N9krhf2Lo/D/buGTZ18sknJ6NGjUpqa2uT3XbbLTn55JN7nEfufmFzfv7znydve9vbkrq6umS//fZLvvOd7/R4vtz/DlyRJElSnF4BAAAA4C9ljz0AAADkmGAPAAAAOSbYAwAAQI4J9gAAAJBjgj0AAADkmGAPAAAAOSbYAwAAQI4J9gAAAJBjgj0AUHT33HNPVFRUxPLly4u9FADIHcEeAAAAckywBwAAgBwT7AGA6OrqihkzZsTYsWOjvr4+Dj744Pjxj38cERvb5GfNmhUHHXRQDBgwII444oh47LHHerzGT37ykzjggAOirq4u9tprr7jiiit6PL9u3bo4//zzY8yYMVFXVxfjxo2L//zP/+xxzbx58+Lwww+PgQMHxrve9a5YtGhR+tzvfve7OO6442Lw4MHR0NAQhx12WDz66KNv0q8IAOSHYA8AxIwZM+K///u/47rrrouFCxfGtGnT4uMf/3jMmTMnvebcc8+NK664Ih555JEYPnx4/NVf/VW0t7dHxIZA/pGPfCROOeWUWLBgQVx88cXxL//yLzFz5sz0+0899dT43//937jqqqviiSeeiG9/+9sxaNCgHuv40pe+FFdccUU8+uijUV1dHZ/61KfS56ZMmRK77757PPLIIzFv3rz4whe+EDU1NW/uLwwA5EBFkiRJsRcBABTPunXrYsiQIfHLX/4yWlpa0sfPOOOMWL16dZx55plx3HHHxQ033BAnn3xyRES89tprsfvuu8fMmTPjIx/5SEyZMiVefvnluPPOO9PvP++882LWrFmxcOHCeOqpp2LfffeN2bNnx8SJE3ut4Z577onjjjsufvnLX8bxxx8fERG/+MUvYvLkybFmzZoYMGBANDQ0xDe/+c047bTT3uRfEQDIFxV7AChzzzzzTKxevTre+973xqBBg9Kv//7v/45nn302vW7T0D9kyJDYd99944knnoiIiCeeeCKOPPLIHq975JFHxtNPPx2dnZ0xf/78qKqqimOPPbbPtRx00EHpj0eNGhUREcuWLYuIiOnTp8cZZ5wREydOjEsvvbTH2gCgnAn2AFDmVq1aFRERs2bNivnz56dfjz/+eLrP/i9VX1/fr+s2ba2vqKiIiA37/yMiLr744li4cGFMnjw57r777hg/fnzcfPPNO2R9AJBngj0AlLnx48dHXV1dLFmyJMaNG9fja8yYMel1Dz74YPrj119/PZ566qnYf//9IyJi//33j/vvv7/H695///2xzz77RFVVVRx44IHR1dXVY8/+9thnn31i2rRpceedd8aJJ54Y3//+9/+i1wOAUlBd7AUAAMU1ePDg+Od//ueYNm1adHV1xVFHHRUrVqyI+++/PxoaGmLPPfeMiIhLLrkkhg4dGs3NzfGlL30phg0bFh/60IciIuLzn/98vOMd74ivfOUrcfLJJ8fcuXPjW9/6VlxzzTUREbHXXnvFaaedFp/61KfiqquuioMPPjj++Mc/xrJly+IjH/nIVte4Zs2aOPfcc+PDH/5wjB07Nv70pz/FI488EieddNKb9usCAHkh2AMA8ZWvfCWGDx8eM2bMiOeeey6ampri0EMPjS9+8YtpK/yll14an/vc5+Lpp5+OQw45JH7+859HbW1tREQceuihceONN8ZFF10UX/nKV2LUqFFxySWXxN///d+n73HttdfGF7/4xfjHf/zHePXVV2OPPfaIL37xi/1aX1VVVbz66qtx6qmnxtKlS2PYsGFx4oknxr/+67/u8F8LAMgbU/EBgD4VJta//vrr0dTUVOzlAAB/xh57AAAAyDHBHgAAAHJMKz4AAADkmIo9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY4I9AAAA5JhgDwAAADkm2AMAAECOCfYAAACQY/8/uCC/vIpIz5kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def eval_and_viz(\n",
    "#         device, domain, boundary_conditions, rhs,\n",
    "#         net, loss_list,\n",
    "#         apply_mcdropout,\n",
    "#         save_fig\n",
    "#         ):\n",
    "#     r\"\"\"Evaluate and visualize.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     device : str\n",
    "#         Specifiy `cuda` if CUDA-enabled GPU is available, otherwise\n",
    "#         specify `cpu`\n",
    "#     domain : tuple or list\n",
    "#         Boundaries of the solution domain\n",
    "#     boundary_conditions : tuple or list\n",
    "#         Boundary conditions\n",
    "#     rhs : float\n",
    "#         Value of the scalar right hand side function\n",
    "#     net : Net\n",
    "#         Trained function approximator\n",
    "#     loss_list : list\n",
    "#         Loss values during training process\n",
    "#     apply_mcdropout : bool\n",
    "#         Apply Monte Carlo dropout for uncertainty quantification if set\n",
    "#         to `True`\n",
    "#     save_fig : bool\n",
    "#         Save figure\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     None\n",
    "#     \"\"\"\n",
    "#     x = torch.linspace(*domain, 101, device=device).unsqueeze(-1)\n",
    "#     rhs = rhs(x).cpu().detach().numpy().ravel()\n",
    "#     if apply_mcdropout:\n",
    "#         y_pred_mc = np.empty((1000, x.shape[0]))\n",
    "#         for i in range(1000):\n",
    "#             y_pred = net(x)\n",
    "#             y_pred_mc[i, :] = y_pred.cpu().detach().numpy().ravel()\n",
    "#         net.eval()\n",
    "#         y_pred = np.mean(y_pred_mc, axis=0)\n",
    "#         y_ci = np.std(y_pred_mc, axis=0)\n",
    "#     else:\n",
    "#         net.eval() \n",
    "#         y_pred = net(x)\n",
    "#         y_pred = y_pred.cpu().detach().numpy().ravel()\n",
    "#     x = x.cpu().detach().numpy().ravel()\n",
    "#     y = solve_poisson(x, rhs, boundary_conditions)\n",
    "#     rmse_val = np.sqrt(np.mean((y - y_pred)**2))\n",
    "\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "#     ax[0].plot(x, y, 'k-', linewidth=2, label='Analytic solution')\n",
    "#     ax[0].plot(x, y_pred, 'r--', dashes=(3, 4), linewidth=3, label='PINN solution')\n",
    "#     if apply_mcdropout:\n",
    "#         ax[0].fill_between(x, y_pred + 2*y_ci, y_pred - 2*y_ci, color='r', alpha=0.1, label='95% CI')\n",
    "#     ax[0].set_xlabel('x')\n",
    "#     ax[0].set_ylabel('y')\n",
    "#     ax[0].set_title(f'RMSE = {rmse_val:.6f}')\n",
    "#     ax[0].legend()\n",
    "#     ax[1].plot(loss_list, 'r-')\n",
    "#     ax[1].set_yscale('log')\n",
    "#     ax[1].set_xlabel('training epoch')\n",
    "#     ax[1].set_ylabel('loss value')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     if save_fig:\n",
    "#         fig.savefig(os.path.join('figs', f'{save_fig}.png'), format='png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "# print(loss_hist)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.plot(range(n_epochs), loss_hist)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('IPINN')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
